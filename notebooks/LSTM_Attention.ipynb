{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import io\n",
    "import nltk\n",
    "import json\n",
    "import gzip\n",
    "import torch\n",
    "import string\n",
    "import random\n",
    "import operator\n",
    "import jsonlines\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from torch.utils.data import Dataset, RandomSampler, SequentialSampler, DataLoader\n",
    "from sklearn.metrics import precision_recall_fscore_support, multilabel_confusion_matrix\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpus = torch.cuda.device_count()\n",
    "if num_gpus > 0:\n",
    "    current_device = 'cuda'\n",
    "else:\n",
    "    current_device = 'cpu'\n",
    "\n",
    "FloatTensor = torch.cuda.FloatTensor if current_device == 'cuda' else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if current_device == 'cuda' else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if current_device == 'cuda' else torch.ByteTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convCategories(categories, category_to_index):\n",
    "    return [category_to_index[category] for category in categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate_test_split(df, train_percent=.8, validate_percent=.1, seed=1):\n",
    "    np.random.seed(seed)\n",
    "    perm = np.random.permutation(df.index)\n",
    "    m = len(df.index)\n",
    "    train_end = int(train_percent * m)\n",
    "    validate_end = int(validate_percent * m) + train_end\n",
    "    train = df.iloc[perm[:train_end]]\n",
    "    validate = df.iloc[perm[train_end:validate_end]]\n",
    "    test = df.iloc[perm[validate_end:]]\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_dataset(dataset, word_to_index):\n",
    "    _current_dictified = []\n",
    "    for l in tqdm(dataset['tokens']):\n",
    "        encoded_l = [word_to_index[i] if i in word_to_index else word_to_index['<UNK>'] for i in l]\n",
    "        _current_dictified.append(encoded_l)\n",
    "    return _current_dictified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensoredDataset(Dataset):\n",
    "    def __init__(self, list_of_lists_of_tokens, labels):\n",
    "        self.input_tensors = []\n",
    "        self.target_tensors = []\n",
    "        \n",
    "        for i in range(0, len(list_of_lists_of_tokens)):\n",
    "            self.input_tensors.append(torch.tensor(list_of_lists_of_tokens[i], dtype=torch.long))\n",
    "            self.target_tensors.append(torch.tensor(labels[i], dtype=torch.long))\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.input_tensors)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # return a (input, target) tuple\n",
    "        return (self.input_tensors[idx], self.target_tensors[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_list_of_tensors(list_of_tensors, pad_token):\n",
    "    max_length = max([t.size(-1) for t in list_of_tensors])\n",
    "    padded_list = []\n",
    "    \n",
    "    for t in list_of_tensors:\n",
    "        #print(t.reshape(1, -1).shape)\n",
    "        #print(torch.tensor([[pad_token]*(max_length - t.size(-1))])[0].shape)\n",
    "        padded_tensor = torch.cat([t.reshape(1, -1), torch.tensor([[pad_token]*(max_length - t.size(-1))], dtype=torch.long)], dim = -1)\n",
    "        padded_list.append(padded_tensor)\n",
    "    padded_tensor = torch.cat(padded_list, dim=0)\n",
    "    return padded_tensor\n",
    "\n",
    "def transform_labels(target_list):\n",
    "    padded_list = []\n",
    "    for t in target_list:\n",
    "        labels = t.unsqueeze(0)\n",
    "        target = torch.zeros(labels.size(0), len(category_to_index)).scatter_(1, labels, 1)\n",
    "        padded_list.append(target)\n",
    "    padded_tensor = torch.cat(padded_list, dim=0)\n",
    "    return padded_tensor\n",
    "\n",
    "def pad_collate_fn(batch):\n",
    "    # batch is a list of sample tuples\n",
    "    input_list = [s[0] for s in batch]\n",
    "    target_list = [s[1] for s in batch]\n",
    "    \n",
    "    #pad_token = persona_dict.get_id('<pad>')\n",
    "    pad_token = word_to_index['<PAD>']\n",
    "    \n",
    "    input_tensor = pad_list_of_tensors(input_list, pad_token)\n",
    "    #target_tensor = pad_list_of_tensors(target_list, pad_token)\n",
    "    target_tensor = transform_labels(target_list)\n",
    "    \n",
    "    return input_tensor, target_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTModel(nn.Module):\n",
    "    \"\"\"\n",
    "    This model combines embedding, rnn and projection layer into a single model\n",
    "    \"\"\"\n",
    "    def __init__(self, options):\n",
    "        super().__init__()\n",
    "        \n",
    "        # create each LM part here \n",
    "        self.lookup = nn.Embedding(num_embeddings=options['num_embeddings'], embedding_dim=options['embedding_dim'], padding_idx=options['padding_idx']).from_pretrained(weights_matrix)\n",
    "        self.lstm = nn.LSTM(options['input_size'], options['hidden_size'], options['num_layers'], batch_first=True)\n",
    "        self.projection = nn.Linear(options['hidden_size']*options['num_layers'], options['num_labels'])\n",
    "        \n",
    "    def forward(self, encoded_input_sequence):\n",
    "        \"\"\"\n",
    "        Forward method process the input from token ids to logits\n",
    "        \"\"\"\n",
    "        embeddings = self.lookup(encoded_input_sequence)\n",
    "        lstm_outputs, (hn, cn) = self.lstm(embeddings)\n",
    "        logits = self.projection(hn[-1])\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StructuredSelfAttention(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    The class is an implementation of the paper A Structured Self-Attentive Sentence Embedding including regularization\n",
    "    and without pruning. Slight modifications have been done for speedup\n",
    "    \"\"\"\n",
    "   \n",
    "    def __init__(self,batch_size,lstm_hid_dim,d_a,r,emb_dim=100,vocab_size=None,use_pretrained_embeddings = False,embeddings=None,n_classes = 1):\n",
    "        \"\"\"\n",
    "        Initializes parameters suggested in paper\n",
    " \n",
    "        Args:\n",
    "            batch_size  : {int} batch_size used for training\n",
    "            lstm_hid_dim: {int} hidden dimension for lstm\n",
    "            d_a         : {int} hidden dimension for the dense layer\n",
    "            r           : {int} attention-hops or attention heads\n",
    "            max_len     : {int} number of lstm timesteps\n",
    "            emb_dim     : {int} embeddings dimension\n",
    "            vocab_size  : {int} size of the vocabulary\n",
    "            use_pretrained_embeddings: {bool} use or train your own embeddings\n",
    "            embeddings  : {torch.FloatTensor} loaded pretrained embeddings\n",
    "            type        : [0,1] 0-->binary_classification 1-->multiclass classification\n",
    "            n_classes   : {int} number of classes\n",
    " \n",
    "        Returns:\n",
    "            self\n",
    " \n",
    "        Raises:\n",
    "            Exception\n",
    "        \"\"\"\n",
    "        super(StructuredSelfAttention,self).__init__()\n",
    "       \n",
    "        self.embeddings,emb_dim = self._load_embeddings(use_pretrained_embeddings,embeddings,vocab_size,emb_dim)\n",
    "        self.lstm = torch.nn.LSTM(emb_dim,lstm_hid_dim,1,batch_first=True)\n",
    "        self.linear_first = torch.nn.Linear(lstm_hid_dim,d_a)\n",
    "        self.linear_first.bias.data.fill_(0)\n",
    "        self.linear_second = torch.nn.Linear(d_a,r)\n",
    "        self.linear_second.bias.data.fill_(0)\n",
    "        self.n_classes = n_classes\n",
    "        self.linear_final = torch.nn.Linear(lstm_hid_dim,self.n_classes)\n",
    "        self.batch_size = batch_size       \n",
    "        self.lstm_hid_dim = lstm_hid_dim\n",
    "        self.hidden_state = self.init_hidden()\n",
    "        self.r = r\n",
    "                 \n",
    "    def _load_embeddings(self,use_pretrained_embeddings,embeddings,vocab_size,emb_dim):\n",
    "        \"\"\"Load the embeddings based on flag\"\"\"\n",
    "       \n",
    "        if use_pretrained_embeddings is True and embeddings is None:\n",
    "            raise Exception(\"Send a pretrained word embedding as an argument\")\n",
    "           \n",
    "        if not use_pretrained_embeddings and vocab_size is None:\n",
    "            raise Exception(\"Vocab size cannot be empty\")\n",
    "   \n",
    "        if not use_pretrained_embeddings:\n",
    "            word_embeddings = torch.nn.Embedding(vocab_size,emb_dim,padding_idx=0)\n",
    "            \n",
    "        elif use_pretrained_embeddings:\n",
    "            word_embeddings = torch.nn.Embedding(embeddings.size(0), embeddings.size(1))\n",
    "            word_embeddings.weight = torch.nn.Parameter(embeddings)\n",
    "            emb_dim = embeddings.size(1)\n",
    "            \n",
    "        return word_embeddings,emb_dim\n",
    "       \n",
    "        \n",
    "    def softmax(self,input, axis=1):\n",
    "        \"\"\"\n",
    "        Softmax applied to axis=n\n",
    " \n",
    "        Args:\n",
    "           input: {Tensor,Variable} input on which softmax is to be applied\n",
    "           axis : {int} axis on which softmax is to be applied\n",
    " \n",
    "        Returns:\n",
    "            softmaxed tensors\n",
    " \n",
    "       \n",
    "        \"\"\"\n",
    " \n",
    "        input_size = input.size()\n",
    "        trans_input = input.transpose(axis, len(input_size)-1)\n",
    "        trans_size = trans_input.size()\n",
    "        input_2d = trans_input.contiguous().view(-1, trans_size[-1])\n",
    "        soft_max_2d = F.softmax(input_2d)\n",
    "        soft_max_nd = soft_max_2d.view(*trans_size)\n",
    "        return soft_max_nd.transpose(axis, len(input_size)-1)\n",
    "       \n",
    "        \n",
    "    def init_hidden(self):\n",
    "        return (Variable(torch.zeros(1,self.batch_size,self.lstm_hid_dim)),Variable(torch.zeros(1,self.batch_size,self.lstm_hid_dim)))\n",
    "       \n",
    "        \n",
    "    def forward(self,x):\n",
    "        embeddings = self.embeddings(x)       \n",
    "        outputs, self.hidden_state = self.lstm(embeddings)       \n",
    "        x = F.tanh(self.linear_first(outputs))       \n",
    "        x = self.linear_second(x)       \n",
    "        x = self.softmax(x,1)       \n",
    "        attention = x.transpose(1,2)       \n",
    "        sentence_embeddings = attention@outputs       \n",
    "        avg_sentence_embeddings = torch.sum(sentence_embeddings,1)/self.r\n",
    "       \n",
    "        output = self.linear_final(avg_sentence_embeddings)\n",
    "        return output, attention\n",
    "       \n",
    "\t   \n",
    "\t#Regularization\n",
    "    def l2_matrix_norm(self,m):\n",
    "        \"\"\"\n",
    "        Frobenius norm calculation\n",
    " \n",
    "        Args:\n",
    "           m: {Variable} ||AAT - I||\n",
    " \n",
    "        Returns:\n",
    "            regularized value\n",
    " \n",
    "       \n",
    "        \"\"\"\n",
    "        return torch.sum(torch.sum(torch.sum(m**2,1),1)**0.5).type(torch.DoubleTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FILE = '/scratch/sa5154/Capstone/Models/wikitext_tokenized.p'\n",
    "wiki_df =  pkl.load(open(OUTPUT_FILE, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = []\n",
    "for i in list(wiki_df['mid_level_categories']):\n",
    "    categories.extend(i)\n",
    "categories = sorted(list(set(categories)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_to_index = {categories[i]:i for i in range(0, len(categories))}\n",
    "index_to_category = {v:k for k, v in category_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_df['category_tokens'] = wiki_df.apply(lambda row: convCategories(row['mid_level_categories'], category_to_index), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_df = wiki_df[wiki_df.astype(str)['category_tokens'] != '[]']\n",
    "wiki_df = wiki_df[wiki_df.astype(str)['tokens'] != '[]']\n",
    "wiki_df = wiki_df.reset_index().drop('index', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_train, wiki_valid, wiki_test = train_validate_test_split(wiki_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = list(wiki_train['category_tokens'])\n",
    "y_val = list(wiki_valid['category_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set([y for x in list(wiki_train['tokens']) for y in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "595516"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index = {\"<PAD>\":0, \"<UNK>\":1}\n",
    "for word in vocab:\n",
    "    if(word not in word_to_index):\n",
    "        word_to_index[word]=len(word_to_index)\n",
    "index_to_word = {v:k for k, v in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79968/79968 [00:08<00:00, 8942.88it/s] \n"
     ]
    }
   ],
   "source": [
    "wiki_tokenized_train = tokenize_dataset(wiki_train, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9996/9996 [00:01<00:00, 9028.84it/s]\n"
     ]
    }
   ],
   "source": [
    "wiki_tokenized_val = tokenize_dataset(wiki_valid, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_tokenized_datasets = {}\n",
    "wiki_tokenized_datasets['train'] = wiki_tokenized_train\n",
    "wiki_tokenized_datasets['val'] = wiki_tokenized_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_tensor_dataset = {}\n",
    "wiki_tensor_dataset['train'] = TensoredDataset(wiki_tokenized_datasets['train'], y_train)\n",
    "wiki_tensor_dataset['val'] = TensoredDataset(wiki_tokenized_datasets['val'], y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_loaders = {}\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "for split, wiki_dataset in wiki_tensor_dataset.items():\n",
    "    wiki_loaders[split] = DataLoader(wiki_dataset, batch_size=batch_size, shuffle=True, collate_fn=pad_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Validate(model):\n",
    "    valid_loss_cache = 0\n",
    "    all_targets = []\n",
    "    all_logits = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (inp, target) in enumerate(wiki_loaders['val']):\n",
    "            inp = inp.to(current_device)\n",
    "            target = target.to(current_device)\n",
    "            logits, attention = model(inp)\n",
    "            loss = criterion(logits, target)\n",
    "            m = nn.Sigmoid()\n",
    "            logits = m(logits)\n",
    "            logits = logits.cpu().detach().numpy()\n",
    "            target = target.cpu().numpy()\n",
    "            all_targets.append(target)\n",
    "            all_logits.append(logits)\n",
    "            valid_loss_cache += loss.item()\n",
    "\n",
    "        avg_val_loss = valid_loss_cache / (i+1)\n",
    "        all_logits = np.concatenate(all_logits, axis=0)\n",
    "        all_targets = np.concatenate(all_targets, axis=0)\n",
    "        all_logits[all_logits > 0.5] = 1\n",
    "        all_logits[all_logits <= 0.5] = 0\n",
    "        prec_macro, rec_macro, f_score_macro, _ = precision_recall_fscore_support(all_targets, all_logits, average = 'macro')\n",
    "        print('Validation macro prec: {}, rec:{}, f_score:{}'.format(prec_macro, rec_macro, f_score_macro))\n",
    "        prec_micro, rec_micro, f_score_micro, _ = precision_recall_fscore_support(all_targets, all_logits, average = 'micro')\n",
    "        print('Validation micro prec: {}, rec:{}, f_score:{}'.format(prec_micro, rec_micro, f_score_micro))\n",
    "        print('Validation loss = {:.{prec}f}'.format(avg_val_loss, prec=4))\n",
    "        return f_score_micro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Trained Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2519371it [02:57, 14196.83it/s]\n"
     ]
    }
   ],
   "source": [
    "#Loading pre trained fastText word embeddings\n",
    "def load_vectors(fname):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    data = {}\n",
    "    for line in tqdm(fin):\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = list(map(float, tokens[1:]))\n",
    "    return data\n",
    "\n",
    "fasttext_emb = load_vectors(\"wiki.en.align.vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the weight matrix for pretrained word embeddings\n",
    "vocab_size = len(index_to_word)\n",
    "embed_dim = len(fasttext_emb[\"apple\"])\n",
    "weights_matrix = np.zeros((vocab_size,embed_dim))\n",
    "\n",
    "words_found = 0\n",
    "for i, word in enumerate(word_to_index):\n",
    "    try: \n",
    "        weights_matrix[i] = fasttext_emb[word]\n",
    "        words_found += 1\n",
    "    except KeyError:\n",
    "        weights_matrix[i] = np.random.normal(scale=0.6, size=(embed_dim))\n",
    "weights_matrix = torch.FloatTensor(weights_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in vocab: 595516\n",
      "No. of words from vocab found in fastText: 470498\n"
     ]
    }
   ],
   "source": [
    "print(\"Total words in vocab: {}\".format(len(vocab)))\n",
    "print(\"No. of words from vocab found in fastText: {}\".format(words_found))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {\n",
    "    'num_embeddings': len(word_to_index),\n",
    "    'embedding_dim': weights_matrix.size(1),\n",
    "    'num_labels':44,\n",
    "    'padding_idx': word_to_index['<PAD>'],\n",
    "    'input_size': weights_matrix.size(1),\n",
    "    'hidden_size': 64,\n",
    "    'num_layers': 1,\n",
    "}\n",
    "\n",
    "#model = LSTModel(options).to(current_device)\n",
    "model = StructuredSelfAttention(batch_size,64,64,1,emb_dim=100,vocab_size=len(vocab),use_pretrained_embeddings = True,embeddings=weights_matrix,n_classes = 44).to(current_device)\n",
    "\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "model_parameters = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = optim.Adam(model_parameters, lr=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredSelfAttention(\n",
       "  (embeddings): Embedding(595518, 300)\n",
       "  (lstm): LSTM(300, 64, batch_first=True)\n",
       "  (linear_first): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (linear_second): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (linear_final): Linear(in_features=64, out_features=44, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Epoch:1\n",
      "Step 0 avg train loss = 0.7146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa5154/miniconda3/lib/python3.7/site-packages/torch/nn/functional.py:1320: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
      "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
      "/home/sa5154/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:83: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "/home/sa5154/miniconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation macro prec: 0.03392667475920414, rec:0.5102942067374169, f_score:0.04402346269135621\n",
      "Validation micro prec: 0.04092312821322665, rec:0.5451411207853678, f_score:0.07613117510007059\n",
      "Validation loss = 0.6868\n",
      "Model saved!\n",
      "Step 500 avg train loss = 0.1488\n",
      "Validation macro prec: 0.0, rec:0.0, f_score:0.0\n",
      "Validation micro prec: 0.0, rec:0.0, f_score:0.0\n",
      "Validation loss = 0.1237\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa5154/miniconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1000 avg train loss = 0.1354\n",
      "Validation macro prec: 0.014155199639070607, rec:0.021994942540246865, f_score:0.017224983578914346\n",
      "Validation micro prec: 0.6228287841191067, rec:0.20534096885408754, f_score:0.3088551966600747\n",
      "Validation loss = 0.1146\n",
      "Model saved!\n",
      "Step 1500 avg train loss = 0.1228\n",
      "Validation macro prec: 0.16849045557460834, rec:0.07836493356598594, f_score:0.09176697091052408\n",
      "Validation micro prec: 0.9104685110524121, rec:0.38269152106585635, f_score:0.5388792890644286\n",
      "Validation loss = 0.0847\n",
      "Model saved!\n",
      "Step 2000 avg train loss = 0.1106\n",
      "Validation macro prec: 0.28754929927613887, rec:0.15595779888146685, f_score:0.1780293489536967\n",
      "Validation micro prec: 0.8795327102803738, rec:0.5499327996260153, f_score:0.6767339014130083\n",
      "Validation loss = 0.0669\n",
      "Model saved!\n",
      "Running Epoch:2\n",
      "Step 0 avg train loss = 0.0640\n",
      "Validation macro prec: 0.3520114203631843, rec:0.2114803211689487, f_score:0.24348594589537906\n",
      "Validation micro prec: 0.8770617105157293, rec:0.6370011102670484, f_score:0.7380001354004468\n",
      "Validation loss = 0.0574\n",
      "Model saved!\n",
      "Step 500 avg train loss = 0.0515\n",
      "Validation macro prec: 0.40124079290592896, rec:0.2422908379026257, f_score:0.2780449252900126\n",
      "Validation micro prec: 0.8829654958035437, rec:0.6639396949687372, f_score:0.7579466995763983\n",
      "Validation loss = 0.0519\n",
      "Model saved!\n",
      "Step 1000 avg train loss = 0.0495\n",
      "Validation macro prec: 0.476966978310706, rec:0.2870515255380171, f_score:0.32453763188857687\n",
      "Validation micro prec: 0.8744517149636873, rec:0.7106293461111436, f_score:0.7840747904577692\n",
      "Validation loss = 0.0478\n",
      "Model saved!\n",
      "Step 1500 avg train loss = 0.0479\n",
      "Validation macro prec: 0.5604221317596596, rec:0.31157905609076364, f_score:0.35773631151918556\n",
      "Validation micro prec: 0.8833540281937039, rec:0.7067141938876877, f_score:0.7852226983508637\n",
      "Validation loss = 0.0454\n",
      "Model saved!\n",
      "Step 2000 avg train loss = 0.0463\n",
      "Validation macro prec: 0.5521961635134705, rec:0.3578814304037684, f_score:0.41221976969076796\n",
      "Validation micro prec: 0.8796431807094571, rec:0.7375679308128323, f_score:0.8023647574852203\n",
      "Validation loss = 0.0430\n",
      "Model saved!\n",
      "Running Epoch:3\n",
      "Step 0 avg train loss = 0.0324\n",
      "Validation macro prec: 0.6013949584131546, rec:0.40355529154405867, f_score:0.450226178123393\n",
      "Validation micro prec: 0.8778762277628958, rec:0.7468591129550634, f_score:0.8070851225056832\n",
      "Validation loss = 0.0417\n",
      "Model saved!\n",
      "Step 500 avg train loss = 0.0307\n",
      "Validation macro prec: 0.5903282864655376, rec:0.4189915840701062, f_score:0.47005491429059687\n",
      "Validation micro prec: 0.8643730074388948, rec:0.7604744930754397, f_score:0.809101930429917\n",
      "Validation loss = 0.0414\n",
      "Model saved!\n",
      "Step 1000 avg train loss = 0.0303\n",
      "Validation macro prec: 0.6054912450573466, rec:0.4274931620487115, f_score:0.4772388255700271\n",
      "Validation micro prec: 0.8665433403805497, rec:0.7664348740723427, f_score:0.8134205711805017\n",
      "Validation loss = 0.0409\n",
      "Model saved!\n",
      "Step 1500 avg train loss = 0.0299\n",
      "Validation macro prec: 0.5991031122192166, rec:0.4332995115676793, f_score:0.4853883292616148\n",
      "Validation micro prec: 0.8652412063617766, rec:0.7661426985332788, f_score:0.8126820802082687\n",
      "Validation loss = 0.0405\n",
      "Step 2000 avg train loss = 0.0295\n",
      "Validation macro prec: 0.6352529058584507, rec:0.4542618072862119, f_score:0.5076843157514931\n",
      "Validation micro prec: 0.8728269590799679, rec:0.7628118973879506, f_score:0.8141195547101563\n",
      "Validation loss = 0.0402\n",
      "Model saved!\n",
      "Running Epoch:4\n",
      "Step 0 avg train loss = 0.0160\n",
      "Validation macro prec: 0.6756448698653702, rec:0.4472757862054244, f_score:0.508249593620749\n",
      "Validation micro prec: 0.8769417803593138, rec:0.7587214398410566, f_score:0.8135593220338982\n",
      "Validation loss = 0.0403\n",
      "Step 500 avg train loss = 0.0188\n",
      "Validation macro prec: 0.631650310071893, rec:0.4876308077477814, f_score:0.5392496111021352\n",
      "Validation micro prec: 0.8683740321620012, rec:0.7667854847192193, f_score:0.8144240317775571\n",
      "Validation loss = 0.0419\n",
      "Model saved!\n",
      "Step 1000 avg train loss = 0.0188\n",
      "Validation macro prec: 0.6588720033356121, rec:0.47151237342652325, f_score:0.5302826227861268\n",
      "Validation micro prec: 0.8668492784607162, rec:0.7581955238707415, f_score:0.8088899971946012\n",
      "Validation loss = 0.0436\n",
      "Step 1500 avg train loss = 0.0187\n",
      "Validation macro prec: 0.6678736850983625, rec:0.4872523038600253, f_score:0.5388315674844343\n",
      "Validation micro prec: 0.8591826041393765, rec:0.7665517442879682, f_score:0.8102282202526173\n",
      "Validation loss = 0.0441\n",
      "Step 2000 avg train loss = 0.0185\n",
      "Validation macro prec: 0.6696100514160045, rec:0.4924878323127882, f_score:0.5484279989446755\n",
      "Validation micro prec: 0.8669752066115702, rec:0.7662595687489043, f_score:0.8135120044667783\n",
      "Validation loss = 0.0434\n",
      "Running Epoch:5\n",
      "Step 0 avg train loss = 0.0080\n",
      "Validation macro prec: 0.673355132148397, rec:0.4996329252257039, f_score:0.5531027972610125\n",
      "Validation micro prec: 0.8611796803949591, rec:0.7746742242739438, f_score:0.8156397083705048\n",
      "Validation loss = 0.0433\n",
      "Model saved!\n",
      "Step 500 avg train loss = 0.0117\n",
      "Validation macro prec: 0.6472057635145215, rec:0.5018760280576314, f_score:0.5513269844868771\n",
      "Validation micro prec: 0.8543758043758044, rec:0.7758429264301993, f_score:0.8132177747833277\n",
      "Validation loss = 0.0460\n",
      "Step 1000 avg train loss = 0.0116\n",
      "Validation macro prec: 0.6466703837192892, rec:0.5098142221116869, f_score:0.5543283366733198\n",
      "Validation micro prec: 0.8438275927930222, rec:0.7744989189505055, f_score:0.8076782449725777\n",
      "Validation loss = 0.0478\n",
      "Step 1500 avg train loss = 0.0115\n",
      "Validation macro prec: 0.7014685779966183, rec:0.5072511934603917, f_score:0.5671801425695273\n",
      "Validation micro prec: 0.8562341792691633, rec:0.7708759422661134, f_score:0.8113161131611315\n",
      "Validation loss = 0.0476\n",
      "Step 2000 avg train loss = 0.0115\n",
      "Validation macro prec: 0.6890035565345431, rec:0.5224907485325053, f_score:0.5774533314686825\n",
      "Validation micro prec: 0.852168284789644, rec:0.7693566294629813, f_score:0.8086478518564014\n",
      "Validation loss = 0.0495\n",
      "Running Epoch:6\n",
      "Step 0 avg train loss = 0.0036\n",
      "Validation macro prec: 0.6965259024270817, rec:0.5353182083764172, f_score:0.5885352004380986\n",
      "Validation micro prec: 0.8472821945643891, rec:0.7796996435458423, f_score:0.8120872767109948\n",
      "Validation loss = 0.0485\n",
      "Step 500 avg train loss = 0.0074\n",
      "Validation macro prec: 0.6540971517230569, rec:0.5332025352952807, f_score:0.5749612018898346\n",
      "Validation micro prec: 0.8348027261927093, rec:0.7801671244083446, f_score:0.8065607442759621\n",
      "Validation loss = 0.0509\n",
      "Step 1000 avg train loss = 0.0073\n",
      "Validation macro prec: 0.698334400389365, rec:0.5270621203187772, f_score:0.587087173021894\n",
      "Validation micro prec: 0.8564021789066089, rec:0.7625197218488868, f_score:0.8067387944358578\n",
      "Validation loss = 0.0516\n",
      "Step 1500 avg train loss = 0.0073\n",
      "Validation macro prec: 0.6838158515937741, rec:0.525061294321729, f_score:0.5787401595331187\n",
      "Validation micro prec: 0.841775790482274, rec:0.7700578507567346, f_score:0.8043212890625\n",
      "Validation loss = 0.0528\n",
      "Step 2000 avg train loss = 0.0074\n",
      "Validation macro prec: 0.6447391733496048, rec:0.5589063754195039, f_score:0.5874311078097846\n",
      "Validation micro prec: 0.8222729798135687, rec:0.7783556360661485, f_score:0.7997118155619596\n",
      "Validation loss = 0.0550\n",
      "Running Epoch:7\n",
      "Step 0 avg train loss = 0.0041\n",
      "Validation macro prec: 0.6963192709696204, rec:0.5514889181975836, f_score:0.6006753765652173\n",
      "Validation micro prec: 0.8412162162162162, rec:0.7857184596505581, f_score:0.8125207722754328\n",
      "Validation loss = 0.0524\n",
      "Step 500 avg train loss = 0.0047\n",
      "Validation macro prec: 0.6928540046269991, rec:0.5692475183262584, f_score:0.6150675971142197\n",
      "Validation micro prec: 0.8424257802588175, rec:0.7760182317536376, f_score:0.8078595978951851\n",
      "Validation loss = 0.0540\n",
      "Step 1000 avg train loss = 0.0047\n",
      "Validation macro prec: 0.5788156781511755, rec:0.5695648453219901, f_score:0.5639221162917126\n",
      "Validation micro prec: 0.7947198275862069, rec:0.7757260562145737, f_score:0.7851080817340391\n",
      "Validation loss = 0.0607\n",
      "Step 1500 avg train loss = 0.0047\n",
      "Validation macro prec: 0.6251414553299561, rec:0.5688845372834981, f_score:0.5873423993516916\n",
      "Validation micro prec: 0.8223409481699828, rec:0.7825045287208555, f_score:0.8019283169146929\n",
      "Validation loss = 0.0574\n",
      "Step 2000 avg train loss = 0.0048\n",
      "Validation macro prec: 0.5303234798012189, rec:0.555465652902569, f_score:0.5273704012795811\n",
      "Validation micro prec: 0.7742162733356815, rec:0.7706422018348624, f_score:0.772425103230152\n",
      "Validation loss = 0.0625\n",
      "Running Epoch:8\n",
      "Step 0 avg train loss = 0.0040\n",
      "Validation macro prec: 0.6717262799011668, rec:0.5451227071667452, f_score:0.5930172522784235\n",
      "Validation micro prec: 0.8464818763326226, rec:0.7655583474551511, f_score:0.803988953666769\n",
      "Validation loss = 0.0587\n",
      "Step 500 avg train loss = 0.0032\n",
      "Validation macro prec: 0.6205391539447253, rec:0.5537776784453686, f_score:0.5764986728296774\n",
      "Validation micro prec: 0.8269279393173199, rec:0.7644480804067083, f_score:0.7944614824036682\n",
      "Validation loss = 0.0626\n",
      "Step 1000 avg train loss = 0.0032\n",
      "Validation macro prec: 0.6059117253900056, rec:0.5689989701794169, f_score:0.5779564918326585\n",
      "Validation micro prec: 0.808153188414524, rec:0.7842575819552388, f_score:0.7960260972716489\n",
      "Validation loss = 0.0621\n",
      "Step 1500 avg train loss = 0.0032\n",
      "Validation macro prec: 0.6490901080942435, rec:0.5758618723655377, f_score:0.6029181060326271\n",
      "Validation micro prec: 0.8219452887537994, rec:0.7901010927365161, f_score:0.8057086672824241\n",
      "Validation loss = 0.0613\n",
      "Step 2000 avg train loss = 0.0032\n",
      "Validation macro prec: 0.6974085389185588, rec:0.5916471288918493, f_score:0.6279884553033032\n",
      "Validation micro prec: 0.8269771421586604, rec:0.7906854438146438, f_score:0.8084241971620612\n",
      "Validation loss = 0.0614\n",
      "Running Epoch:9\n",
      "Step 0 avg train loss = 0.0021\n",
      "Validation macro prec: 0.6733200639472192, rec:0.5730118511608625, f_score:0.6119900299416356\n",
      "Validation micro prec: 0.8261451426485796, rec:0.7936071992052826, f_score:0.8095493562231759\n",
      "Validation loss = 0.0619\n",
      "Step 500 avg train loss = 0.0023\n",
      "Validation macro prec: 0.7124462325899911, rec:0.5644333980877655, f_score:0.6127638607896698\n",
      "Validation micro prec: 0.834408335400645, rec:0.7861859405130602, f_score:0.8095796852904894\n",
      "Validation loss = 0.0620\n",
      "Step 1000 avg train loss = 0.0022\n",
      "Validation macro prec: 0.6500484765556517, rec:0.5726414507507814, f_score:0.6023077184877851\n",
      "Validation micro prec: 0.8290232558139535, rec:0.7811605212411616, f_score:0.8043805283109694\n",
      "Validation loss = 0.0641\n",
      "Step 1500 avg train loss = 0.0022\n",
      "Validation macro prec: 0.5841615990221062, rec:0.5866653579195877, f_score:0.5721149315131115\n",
      "Validation micro prec: 0.788020589611605, rec:0.7872377724536902, f_score:0.787628986524014\n",
      "Validation loss = 0.0673\n",
      "Step 2000 avg train loss = 0.0022\n",
      "Validation macro prec: 0.6122994832386791, rec:0.5764412191238402, f_score:0.5854919041958758\n",
      "Validation micro prec: 0.8108600583090378, rec:0.7801086893005318, f_score:0.7951871817017602\n",
      "Validation loss = 0.0680\n",
      "Running Epoch:10\n",
      "Step 0 avg train loss = 0.0016\n",
      "Validation macro prec: 0.6673657230707417, rec:0.587166119925762, f_score:0.6181264143830982\n",
      "Validation micro prec: 0.8288578146269026, rec:0.7827967042599193, f_score:0.8051690458302029\n",
      "Validation loss = 0.0657\n",
      "Step 500 avg train loss = 0.0016\n",
      "Validation macro prec: 0.7003469704237735, rec:0.5868642906540991, f_score:0.6244689919697001\n",
      "Validation micro prec: 0.8273004265691651, rec:0.7933150236662186, f_score:0.8099513766667661\n",
      "Validation loss = 0.0655\n",
      "Step 1000 avg train loss = 0.0016\n",
      "Validation macro prec: 0.7043244185708655, rec:0.5794460242916029, f_score:0.6210154032746019\n",
      "Validation micro prec: 0.8296401456700204, rec:0.7854262841114942, f_score:0.8069280182505855\n",
      "Validation loss = 0.0669\n",
      "Step 1500 avg train loss = 0.0016\n",
      "Validation macro prec: 0.6782325423831037, rec:0.5830280383688379, f_score:0.618358635697176\n",
      "Validation micro prec: 0.8216978837265873, rec:0.7895751767662011, f_score:0.8053163274428585\n",
      "Validation loss = 0.0685\n",
      "Step 2000 avg train loss = 0.0017\n",
      "Validation macro prec: 0.6614185260783532, rec:0.5956824347513913, f_score:0.6204348968561306\n",
      "Validation micro prec: 0.8141609028030579, rec:0.7841407117396132, f_score:0.7988688792975144\n",
      "Validation loss = 0.0699\n"
     ]
    }
   ],
   "source": [
    "best_f_score_micro = -1\n",
    "count = 0\n",
    "PATH = '/scratch/sa5154/Capstone/Models/LSTM_Attention_Pretrained_epoch_30.pth'\n",
    "for epoch_number in range(10):\n",
    "    print(\"Running Epoch:{}\".format(epoch_number + 1))\n",
    "    avg_loss = -1\n",
    "    # do train\n",
    "    model.train()\n",
    "\n",
    "    train_loss_cache = 0\n",
    "\n",
    "    for i, (inp, target) in enumerate(wiki_loaders['train']):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        inp = inp.to(current_device)\n",
    "        target = target.to(current_device)\n",
    "        logits, _ = model(inp)\n",
    "        loss = criterion(logits, target)\n",
    "        train_loss_cache += loss.item()\n",
    "       \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 500 == 0:\n",
    "            avg_loss = train_loss_cache/(i+1)\n",
    "            print('Step {} avg train loss = {:.{prec}f}'.format(i, avg_loss, prec=4))\n",
    "\n",
    "            #do valid\n",
    "            f_score_micro = Validate(model)\n",
    "            if( f_score_micro > best_f_score_micro):\n",
    "                best_f_score_micro = f_score_micro\n",
    "                torch.save({\n",
    "                        'state_dict': model.state_dict()\n",
    "                        }, PATH)\n",
    "                print(\"Model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredSelfAttention(\n",
       "  (embeddings): Embedding(595518, 300)\n",
       "  (lstm): LSTM(300, 64, batch_first=True)\n",
       "  (linear_first): Linear(in_features=64, out_features=64, bias=True)\n",
       "  (linear_second): Linear(in_features=64, out_features=1, bias=True)\n",
       "  (linear_final): Linear(in_features=64, out_features=44, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = '/scratch/sa5154/Capstone/Models/LSTM_Attention_Pretrained_epoch_30.pth'\n",
    "model = StructuredSelfAttention(batch_size,64,64,1,emb_dim=100,vocab_size=len(vocab),use_pretrained_embeddings = True,embeddings=weights_matrix,n_classes = 44).to(current_device)\n",
    "model.load_state_dict(torch.load(PATH)['state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa5154/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:83: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation macro prec: 0.6733391704836106, rec:0.49977193784877055, f_score:0.5531555197979134\n",
      "Validation micro prec: 0.8611327617563004, rec:0.7747326593817565, f_score:0.8156510504783292\n",
      "Validation loss = 0.0433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa5154/miniconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8156510504783292"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Validate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printText(num):\n",
    "    in_ = inp[num].cpu().detach().numpy()\n",
    "    str_ = ''\n",
    "    for i in in_:\n",
    "        if(i!=0):\n",
    "            str_ += index_to_word[i]\n",
    "            str_+=' '\n",
    "    return str_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showAtttention(num):\n",
    "    att = attention[num].cpu().detach().numpy()\n",
    "    in_ = inp[num].cpu().detach().numpy()\n",
    "    targ = target[num].cpu().detach().numpy()\n",
    "    pred = logits[num]\n",
    "    att_dict = {}\n",
    "    for i in range(0, len(att)):\n",
    "        if(in_[i]!=0):\n",
    "            if index_to_word[in_[i]] not in att_dict:\n",
    "                att_dict[index_to_word[in_[i]]] = [att[i]]\n",
    "            else:\n",
    "                att_dict[index_to_word[in_[i]]].append(att[i])\n",
    "    for key in att_dict.keys():\n",
    "        att_dict[key] = np.mean(att_dict[key])\n",
    "        \n",
    "    att_dict = sorted(att_dict.items(), key=operator.itemgetter(1), reverse = True)\n",
    "    label = [index_to_category[i] for i in range(len(targ)) if targ[i] == 1] \n",
    "    pred =  [index_to_category[i] for i in range(len(pred)) if pred[i] == 1] \n",
    "    str_ = printText(num)\n",
    "    return label, pred, att_dict, str_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa5154/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:83: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "all_targets = []\n",
    "all_logits = []\n",
    "for i, (inp, target) in enumerate(wiki_loaders['val']):\n",
    "    inp = inp.to(current_device)\n",
    "    logits, attention = model(inp)\n",
    "    m = nn.Sigmoid()\n",
    "    logits = m(logits)\n",
    "    logits = logits.cpu().detach().numpy()\n",
    "    logits[logits > 0.5] = 1\n",
    "    logits[logits <= 0.5] = 0\n",
    "    attention.squeeze_()\n",
    "    break\n",
    "#     target = target.detach().numpy()\n",
    "#     all_targets.append(target)\n",
    "#     all_logits.append(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison to TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list =[]\n",
    "for index, row in wiki_train.iterrows():\n",
    "    train_list.append(' '.join(row.tokens))\n",
    "\n",
    "val_list =[]\n",
    "for index, row in wiki_valid.iterrows():\n",
    "    val_list.append(' '.join(row.tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_train_scores = tfidf.fit_transform(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_TFIDF_Attention(num):\n",
    "    label, pred, att_dict, text = showAtttention(num)\n",
    "    tfidf_scores = tfidf.transform([text])\n",
    "    terms = tfidf.get_feature_names()\n",
    "    data = []\n",
    "    for col, term in enumerate(terms):\n",
    "        data.append( (term, tfidf_scores[0,col] ))\n",
    "\n",
    "    ranking = pd.DataFrame(data, columns=['term','rank'])\n",
    "    ranking = ranking.sort_values('rank', ascending=False)\n",
    "    top_arr_words = set([w for w,s in att_dict[:10]])\n",
    "    top_tfidf_words = set(ranking[:10]['term'])\n",
    "    common_len = len(top_arr_words.intersection(top_tfidf_words))\n",
    "    print('The number of words common in top 10 words are: {}'.format(common_len))\n",
    "    return label, pred, att_dict, ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of words common in top 10 words are: 5\n"
     ]
    }
   ],
   "source": [
    "num = random.randint(0,32)\n",
    "label, pred, att_dict, tfidf_ranking = show_TFIDF_Attention(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_ranking[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('elections', 0.21944173),\n",
       " ('senate', 0.0134309335),\n",
       " ('states', 0.0038709235),\n",
       " ('labor', 0.0015933439),\n",
       " ('attorney', 0.0007289613),\n",
       " ('new', 0.00069535465),\n",
       " ('election', 0.0004225585),\n",
       " ('case', 0.00032382517),\n",
       " ('united', 0.0002881809),\n",
       " ('clifford', 0.00026884358)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "att_dict[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Geography.Americas']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Geography.Americas', 'History_And_Society.Politics and government']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_per_class_tables(loader, model, device, class_names, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Help function that tests the model's performance on a dataset\n",
    "    @param: loader - data loader for the dataset to test against\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    outputs_list_nc = []\n",
    "    true_list_nc = []\n",
    "    with torch.no_grad():\n",
    "        for data, labels in loader:\n",
    "            data_batch, label_batch = data.to(device), labels.float()\n",
    "            logits, _ = model(data_batch)\n",
    "            outputs_bc = torch.sigmoid(logits)\n",
    "            outputs_bc = outputs_bc.detach().cpu().numpy().astype(np.float)\n",
    "            outputs_bc = (outputs_bc > threshold)\n",
    "            outputs_list_nc.append(outputs_bc)\n",
    "            true_list_nc.append(label_batch.detach().cpu().numpy().astype(np.float))\n",
    "    # to np.array\n",
    "    outputs_list_nc = np.vstack(outputs_list_nc)\n",
    "    true_list_nc = np.vstack(true_list_nc)\n",
    "    \n",
    "    # per class counts\n",
    "    counts_c = true_list_nc.sum(axis=0)\n",
    "    \n",
    "    # per class confusion matrix: TN, FN, TP, FP\n",
    "    confusion_matrix_c22 = multilabel_confusion_matrix(\n",
    "        true_list_nc,\n",
    "        outputs_list_nc,\n",
    "    )\n",
    "    confusion_matrix_c4 = confusion_matrix_c22.reshape(-1, 4)\n",
    "    \n",
    "    # per class precision, recall, f-score\n",
    "    precision_c, recall_c, f1_c, _ = precision_recall_fscore_support(\n",
    "        true_list_nc,\n",
    "        outputs_list_nc,\n",
    "        average=None\n",
    "    )\n",
    "    \n",
    "    # combine all metrics in a dict\n",
    "    per_class_metrics = {\n",
    "        \"class_name\": class_names,\n",
    "        \"count\": counts_c,\n",
    "        \"TN\": confusion_matrix_c4[:,0], \n",
    "        \"FN\": confusion_matrix_c4[:,2],\n",
    "        \"TP\": confusion_matrix_c4[:,3],\n",
    "        \"FP\": confusion_matrix_c4[:,1],\n",
    "        \"precision\": precision_c, \n",
    "        \"recall\": recall_c, \n",
    "        \"f1\": f1_c\n",
    "    }\n",
    "    return pd.DataFrame(per_class_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sa5154/miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:83: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "per_class_metrics = create_per_class_tables(wiki_loaders['val'], model, current_device, categories, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_name</th>\n",
       "      <th>count</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Culture.Language and literature</td>\n",
       "      <td>3631.0</td>\n",
       "      <td>6226</td>\n",
       "      <td>196</td>\n",
       "      <td>3435</td>\n",
       "      <td>139</td>\n",
       "      <td>0.961108</td>\n",
       "      <td>0.946020</td>\n",
       "      <td>0.953505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Geography.Antarctica</td>\n",
       "      <td>27.0</td>\n",
       "      <td>9967</td>\n",
       "      <td>1</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.945455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Culture.Sports</td>\n",
       "      <td>1567.0</td>\n",
       "      <td>8299</td>\n",
       "      <td>151</td>\n",
       "      <td>1416</td>\n",
       "      <td>130</td>\n",
       "      <td>0.915912</td>\n",
       "      <td>0.903638</td>\n",
       "      <td>0.909733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>STEM.Biology</td>\n",
       "      <td>771.0</td>\n",
       "      <td>9175</td>\n",
       "      <td>99</td>\n",
       "      <td>672</td>\n",
       "      <td>50</td>\n",
       "      <td>0.930748</td>\n",
       "      <td>0.871595</td>\n",
       "      <td>0.900201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Geography.Oceania</td>\n",
       "      <td>468.0</td>\n",
       "      <td>9463</td>\n",
       "      <td>52</td>\n",
       "      <td>416</td>\n",
       "      <td>65</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.888889</td>\n",
       "      <td>0.876712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>STEM.Space</td>\n",
       "      <td>67.0</td>\n",
       "      <td>9927</td>\n",
       "      <td>14</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>0.963636</td>\n",
       "      <td>0.791045</td>\n",
       "      <td>0.868852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>History_And_Society.Transportation</td>\n",
       "      <td>551.0</td>\n",
       "      <td>9380</td>\n",
       "      <td>80</td>\n",
       "      <td>471</td>\n",
       "      <td>65</td>\n",
       "      <td>0.878731</td>\n",
       "      <td>0.854809</td>\n",
       "      <td>0.866605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Geography.Asia</td>\n",
       "      <td>1399.0</td>\n",
       "      <td>8449</td>\n",
       "      <td>338</td>\n",
       "      <td>1061</td>\n",
       "      <td>148</td>\n",
       "      <td>0.877585</td>\n",
       "      <td>0.758399</td>\n",
       "      <td>0.813650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Culture.Music</td>\n",
       "      <td>435.0</td>\n",
       "      <td>9501</td>\n",
       "      <td>96</td>\n",
       "      <td>339</td>\n",
       "      <td>60</td>\n",
       "      <td>0.849624</td>\n",
       "      <td>0.779310</td>\n",
       "      <td>0.812950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Culture.Games and toys</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9881</td>\n",
       "      <td>33</td>\n",
       "      <td>76</td>\n",
       "      <td>6</td>\n",
       "      <td>0.926829</td>\n",
       "      <td>0.697248</td>\n",
       "      <td>0.795812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Culture.Plastic arts</td>\n",
       "      <td>302.0</td>\n",
       "      <td>9635</td>\n",
       "      <td>73</td>\n",
       "      <td>229</td>\n",
       "      <td>59</td>\n",
       "      <td>0.795139</td>\n",
       "      <td>0.758278</td>\n",
       "      <td>0.776271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Geography.Europe</td>\n",
       "      <td>2168.0</td>\n",
       "      <td>7445</td>\n",
       "      <td>555</td>\n",
       "      <td>1613</td>\n",
       "      <td>383</td>\n",
       "      <td>0.808116</td>\n",
       "      <td>0.744004</td>\n",
       "      <td>0.774736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Geography.Americas</td>\n",
       "      <td>1884.0</td>\n",
       "      <td>7723</td>\n",
       "      <td>448</td>\n",
       "      <td>1436</td>\n",
       "      <td>389</td>\n",
       "      <td>0.786849</td>\n",
       "      <td>0.762208</td>\n",
       "      <td>0.774333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>History_And_Society.Military and warfare</td>\n",
       "      <td>331.0</td>\n",
       "      <td>9622</td>\n",
       "      <td>95</td>\n",
       "      <td>236</td>\n",
       "      <td>43</td>\n",
       "      <td>0.845878</td>\n",
       "      <td>0.712991</td>\n",
       "      <td>0.773770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Culture.Entertainment</td>\n",
       "      <td>295.0</td>\n",
       "      <td>9658</td>\n",
       "      <td>86</td>\n",
       "      <td>209</td>\n",
       "      <td>43</td>\n",
       "      <td>0.829365</td>\n",
       "      <td>0.708475</td>\n",
       "      <td>0.764168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Culture.Broadcasting</td>\n",
       "      <td>217.0</td>\n",
       "      <td>9739</td>\n",
       "      <td>61</td>\n",
       "      <td>156</td>\n",
       "      <td>40</td>\n",
       "      <td>0.795918</td>\n",
       "      <td>0.718894</td>\n",
       "      <td>0.755448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Geography.Bodies of water</td>\n",
       "      <td>81.0</td>\n",
       "      <td>9902</td>\n",
       "      <td>24</td>\n",
       "      <td>57</td>\n",
       "      <td>13</td>\n",
       "      <td>0.814286</td>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.754967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>History_And_Society.Politics and government</td>\n",
       "      <td>343.0</td>\n",
       "      <td>9581</td>\n",
       "      <td>113</td>\n",
       "      <td>230</td>\n",
       "      <td>72</td>\n",
       "      <td>0.761589</td>\n",
       "      <td>0.670554</td>\n",
       "      <td>0.713178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>STEM.Technology</td>\n",
       "      <td>275.0</td>\n",
       "      <td>9682</td>\n",
       "      <td>101</td>\n",
       "      <td>174</td>\n",
       "      <td>39</td>\n",
       "      <td>0.816901</td>\n",
       "      <td>0.632727</td>\n",
       "      <td>0.713115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>STEM.Medicine</td>\n",
       "      <td>154.0</td>\n",
       "      <td>9819</td>\n",
       "      <td>56</td>\n",
       "      <td>98</td>\n",
       "      <td>23</td>\n",
       "      <td>0.809917</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.712727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Geography.Africa</td>\n",
       "      <td>225.0</td>\n",
       "      <td>9739</td>\n",
       "      <td>88</td>\n",
       "      <td>137</td>\n",
       "      <td>32</td>\n",
       "      <td>0.810651</td>\n",
       "      <td>0.608889</td>\n",
       "      <td>0.695431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Culture.Food and drink</td>\n",
       "      <td>67.0</td>\n",
       "      <td>9927</td>\n",
       "      <td>33</td>\n",
       "      <td>34</td>\n",
       "      <td>2</td>\n",
       "      <td>0.944444</td>\n",
       "      <td>0.507463</td>\n",
       "      <td>0.660194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>History_And_Society.Education</td>\n",
       "      <td>181.0</td>\n",
       "      <td>9783</td>\n",
       "      <td>81</td>\n",
       "      <td>100</td>\n",
       "      <td>32</td>\n",
       "      <td>0.757576</td>\n",
       "      <td>0.552486</td>\n",
       "      <td>0.638978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>STEM.Geosciences</td>\n",
       "      <td>90.0</td>\n",
       "      <td>9895</td>\n",
       "      <td>44</td>\n",
       "      <td>46</td>\n",
       "      <td>11</td>\n",
       "      <td>0.807018</td>\n",
       "      <td>0.511111</td>\n",
       "      <td>0.625850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Culture.Performing arts</td>\n",
       "      <td>72.0</td>\n",
       "      <td>9916</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>8</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.620690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Geography.Landforms</td>\n",
       "      <td>57.0</td>\n",
       "      <td>9923</td>\n",
       "      <td>26</td>\n",
       "      <td>31</td>\n",
       "      <td>16</td>\n",
       "      <td>0.659574</td>\n",
       "      <td>0.543860</td>\n",
       "      <td>0.596154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Culture.Philosophy and religion</td>\n",
       "      <td>274.0</td>\n",
       "      <td>9652</td>\n",
       "      <td>130</td>\n",
       "      <td>144</td>\n",
       "      <td>70</td>\n",
       "      <td>0.672897</td>\n",
       "      <td>0.525547</td>\n",
       "      <td>0.590164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Culture.Visual arts</td>\n",
       "      <td>139.0</td>\n",
       "      <td>9824</td>\n",
       "      <td>73</td>\n",
       "      <td>66</td>\n",
       "      <td>33</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.474820</td>\n",
       "      <td>0.554622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Culture.Arts</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9974</td>\n",
       "      <td>11</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>0.421053</td>\n",
       "      <td>0.533333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Geography.Parks</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9929</td>\n",
       "      <td>36</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>0.774194</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.527473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>History_And_Society.Business and economics</td>\n",
       "      <td>207.0</td>\n",
       "      <td>9731</td>\n",
       "      <td>120</td>\n",
       "      <td>87</td>\n",
       "      <td>58</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.420290</td>\n",
       "      <td>0.494318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>STEM.Time</td>\n",
       "      <td>29.0</td>\n",
       "      <td>9967</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.388889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>STEM.Chemistry</td>\n",
       "      <td>36.0</td>\n",
       "      <td>9958</td>\n",
       "      <td>27</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.382979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>STEM.Engineering</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9973</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.357143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>History_And_Society.History and society</td>\n",
       "      <td>449.0</td>\n",
       "      <td>9460</td>\n",
       "      <td>333</td>\n",
       "      <td>116</td>\n",
       "      <td>87</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.258352</td>\n",
       "      <td>0.355828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>STEM.Science</td>\n",
       "      <td>43.0</td>\n",
       "      <td>9953</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.023256</td>\n",
       "      <td>0.045455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>STEM.Information science</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9986</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>STEM.Mathematics</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9985</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Culture.Media</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9993</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>STEM.Meteorology</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9991</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>STEM.Physics</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9976</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Culture.Internet culture</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9990</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Culture.Crafts and hobbies</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9982</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Geography.Maps</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9995</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     class_name   count    TN   FN    TP   FP  \\\n",
       "7               Culture.Language and literature  3631.0  6226  196  3435  139   \n",
       "17                         Geography.Antarctica    27.0  9967    1    26    2   \n",
       "13                               Culture.Sports  1567.0  8299  151  1416  130   \n",
       "31                                 STEM.Biology   771.0  9175   99   672   50   \n",
       "23                            Geography.Oceania   468.0  9463   52   416   65   \n",
       "41                                   STEM.Space    67.0  9927   14    53    2   \n",
       "30           History_And_Society.Transportation   551.0  9380   80   471   65   \n",
       "18                               Geography.Asia  1399.0  8449  338  1061  148   \n",
       "9                                 Culture.Music   435.0  9501   96   339   60   \n",
       "5                        Culture.Games and toys   109.0  9881   33    76    6   \n",
       "12                         Culture.Plastic arts   302.0  9635   73   229   59   \n",
       "20                             Geography.Europe  2168.0  7445  555  1613  383   \n",
       "16                           Geography.Americas  1884.0  7723  448  1436  389   \n",
       "28     History_And_Society.Military and warfare   331.0  9622   95   236   43   \n",
       "3                         Culture.Entertainment   295.0  9658   86   209   43   \n",
       "1                          Culture.Broadcasting   217.0  9739   61   156   40   \n",
       "19                    Geography.Bodies of water    81.0  9902   24    57   13   \n",
       "29  History_And_Society.Politics and government   343.0  9581  113   230   72   \n",
       "42                              STEM.Technology   275.0  9682  101   174   39   \n",
       "37                                STEM.Medicine   154.0  9819   56    98   23   \n",
       "15                             Geography.Africa   225.0  9739   88   137   32   \n",
       "4                        Culture.Food and drink    67.0  9927   33    34    2   \n",
       "26                History_And_Society.Education   181.0  9783   81   100   32   \n",
       "34                             STEM.Geosciences    90.0  9895   44    46   11   \n",
       "10                      Culture.Performing arts    72.0  9916   36    36    8   \n",
       "21                          Geography.Landforms    57.0  9923   26    31   16   \n",
       "11              Culture.Philosophy and religion   274.0  9652  130   144   70   \n",
       "14                          Culture.Visual arts   139.0  9824   73    66   33   \n",
       "0                                  Culture.Arts    19.0  9974   11     8    3   \n",
       "24                              Geography.Parks    60.0  9929   36    24    7   \n",
       "25   History_And_Society.Business and economics   207.0  9731  120    87   58   \n",
       "43                                    STEM.Time    29.0  9967   22     7    0   \n",
       "32                               STEM.Chemistry    36.0  9958   27     9    2   \n",
       "33                             STEM.Engineering    22.0  9973   17     5    1   \n",
       "27      History_And_Society.History and society   449.0  9460  333   116   87   \n",
       "40                                 STEM.Science    43.0  9953   42     1    0   \n",
       "35                     STEM.Information science    10.0  9986   10     0    0   \n",
       "36                             STEM.Mathematics    11.0  9985   11     0    0   \n",
       "8                                 Culture.Media     3.0  9993    3     0    0   \n",
       "38                             STEM.Meteorology     5.0  9991    5     0    0   \n",
       "39                                 STEM.Physics    18.0  9976   18     0    2   \n",
       "6                      Culture.Internet culture     6.0  9990    6     0    0   \n",
       "2                    Culture.Crafts and hobbies    14.0  9982   14     0    0   \n",
       "22                               Geography.Maps     1.0  9995    1     0    0   \n",
       "\n",
       "    precision    recall        f1  \n",
       "7    0.961108  0.946020  0.953505  \n",
       "17   0.928571  0.962963  0.945455  \n",
       "13   0.915912  0.903638  0.909733  \n",
       "31   0.930748  0.871595  0.900201  \n",
       "23   0.864865  0.888889  0.876712  \n",
       "41   0.963636  0.791045  0.868852  \n",
       "30   0.878731  0.854809  0.866605  \n",
       "18   0.877585  0.758399  0.813650  \n",
       "9    0.849624  0.779310  0.812950  \n",
       "5    0.926829  0.697248  0.795812  \n",
       "12   0.795139  0.758278  0.776271  \n",
       "20   0.808116  0.744004  0.774736  \n",
       "16   0.786849  0.762208  0.774333  \n",
       "28   0.845878  0.712991  0.773770  \n",
       "3    0.829365  0.708475  0.764168  \n",
       "1    0.795918  0.718894  0.755448  \n",
       "19   0.814286  0.703704  0.754967  \n",
       "29   0.761589  0.670554  0.713178  \n",
       "42   0.816901  0.632727  0.713115  \n",
       "37   0.809917  0.636364  0.712727  \n",
       "15   0.810651  0.608889  0.695431  \n",
       "4    0.944444  0.507463  0.660194  \n",
       "26   0.757576  0.552486  0.638978  \n",
       "34   0.807018  0.511111  0.625850  \n",
       "10   0.818182  0.500000  0.620690  \n",
       "21   0.659574  0.543860  0.596154  \n",
       "11   0.672897  0.525547  0.590164  \n",
       "14   0.666667  0.474820  0.554622  \n",
       "0    0.727273  0.421053  0.533333  \n",
       "24   0.774194  0.400000  0.527473  \n",
       "25   0.600000  0.420290  0.494318  \n",
       "43   1.000000  0.241379  0.388889  \n",
       "32   0.818182  0.250000  0.382979  \n",
       "33   0.833333  0.227273  0.357143  \n",
       "27   0.571429  0.258352  0.355828  \n",
       "40   1.000000  0.023256  0.045455  \n",
       "35   0.000000  0.000000  0.000000  \n",
       "36   0.000000  0.000000  0.000000  \n",
       "8    0.000000  0.000000  0.000000  \n",
       "38   0.000000  0.000000  0.000000  \n",
       "39   0.000000  0.000000  0.000000  \n",
       "6    0.000000  0.000000  0.000000  \n",
       "2    0.000000  0.000000  0.000000  \n",
       "22   0.000000  0.000000  0.000000  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_class_metrics.sort_values('f1', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import io\n",
    "import nltk\n",
    "import json\n",
    "import gzip\n",
    "import torch\n",
    "import string\n",
    "import random\n",
    "import operator\n",
    "import jsonlines\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from torch.utils.data import Dataset, RandomSampler, SequentialSampler, DataLoader\n",
    "from sklearn.metrics import precision_recall_fscore_support, multilabel_confusion_matrix\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpus = torch.cuda.device_count()\n",
    "if num_gpus > 0:\n",
    "    current_device = 'cuda'\n",
    "else:\n",
    "    current_device = 'cpu'\n",
    "\n",
    "FloatTensor = torch.cuda.FloatTensor if current_device == 'cuda' else torch.FloatTensor\n",
    "LongTensor = torch.cuda.LongTensor if current_device == 'cuda' else torch.LongTensor\n",
    "ByteTensor = torch.cuda.ByteTensor if current_device == 'cuda' else torch.ByteTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convCategories(categories, category_to_index):\n",
    "    return [category_to_index[category] for category in categories]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_validate_test_split(df, train_percent=.8, validate_percent=.1, seed=1):\n",
    "    np.random.seed(seed)\n",
    "    perm = np.random.permutation(df.index)\n",
    "    m = len(df.index)\n",
    "    train_end = int(train_percent * m)\n",
    "    validate_end = int(validate_percent * m) + train_end\n",
    "    train = df.iloc[perm[:train_end]]\n",
    "    validate = df.iloc[perm[train_end:validate_end]]\n",
    "    test = df.iloc[perm[validate_end:]]\n",
    "    return train, validate, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_dataset(dataset, word_to_index):\n",
    "    _current_dictified = []\n",
    "    for l in tqdm(dataset['tokens']):\n",
    "        encoded_l = [word_to_index[i] if i in word_to_index else word_to_index['<UNK>'] for i in l]\n",
    "        _current_dictified.append(encoded_l)\n",
    "    return _current_dictified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TensoredDataset(Dataset):\n",
    "    def __init__(self, list_of_lists_of_tokens, labels, IDF_list):\n",
    "        self.input_tensors = []\n",
    "        self.target_tensors = []\n",
    "        self.IDF_tensors = []\n",
    "        for i in range(0, len(list_of_lists_of_tokens)):\n",
    "            self.input_tensors.append(torch.tensor(list_of_lists_of_tokens[i], dtype=torch.long))\n",
    "            self.target_tensors.append(torch.tensor(labels[i], dtype=torch.long))\n",
    "            self.IDF_tensors.append(torch.tensor(IDF_list[i], dtype=torch.long))\n",
    "    def __len__(self):\n",
    "        return len(self.input_tensors)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # return a (input, target) tuple\n",
    "        return (self.input_tensors[idx], self.target_tensors[idx], self.IDF_tensors[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_list_of_tensors(list_of_tensors, pad_token):\n",
    "    max_length = max([t.size(-1) for t in list_of_tensors])\n",
    "    padded_list = []\n",
    "    \n",
    "    for t in list_of_tensors:\n",
    "        #print(t.reshape(1, -1).shape)\n",
    "        #print(torch.tensor([[pad_token]*(max_length - t.size(-1))])[0].shape)\n",
    "        padded_tensor = torch.cat([t.reshape(1, -1), torch.tensor([[pad_token]*(max_length - t.size(-1))], dtype=torch.long)], dim = -1)\n",
    "        padded_list.append(padded_tensor)\n",
    "    padded_tensor = torch.cat(padded_list, dim=0)\n",
    "    return padded_tensor\n",
    "\n",
    "def transform_labels(target_list):\n",
    "    padded_list = []\n",
    "    for t in target_list:\n",
    "        labels = t.unsqueeze(0)\n",
    "        target = torch.zeros(labels.size(0), len(category_to_index)).scatter_(1, labels, 1)\n",
    "        padded_list.append(target)\n",
    "    padded_tensor = torch.cat(padded_list, dim=0)\n",
    "    return padded_tensor\n",
    "\n",
    "def pad_collate_fn(batch):\n",
    "    # batch is a list of sample tuples\n",
    "    input_list = [s[0] for s in batch]\n",
    "    target_list = [s[1] for s in batch]\n",
    "    IDF_list = [s[2] for s in batch]\n",
    "    #pad_token = persona_dict.get_id('<pad>')\n",
    "    pad_token = word_to_index['<PAD>']\n",
    "    \n",
    "    input_tensor = pad_list_of_tensors(input_list, pad_token)\n",
    "    IDF_tensor = pad_list_of_tensors(IDF_list, 0)\n",
    "    #target_tensor = pad_list_of_tensors(target_list, pad_token)\n",
    "    target_tensor = transform_labels(target_list)\n",
    "    \n",
    "    return input_tensor, target_tensor, IDF_tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTModel(nn.Module):\n",
    "    \"\"\"\n",
    "    This model combines embedding, rnn and projection layer into a single model\n",
    "    \"\"\"\n",
    "    def __init__(self, options):\n",
    "        super().__init__()\n",
    "        \n",
    "        # create each LM part here \n",
    "        self.lookup = nn.Embedding(num_embeddings=options['num_embeddings'], embedding_dim=options['embedding_dim'], padding_idx=options['padding_idx']).from_pretrained(weights_matrix)\n",
    "        self.lstm = nn.LSTM(options['input_size'], options['hidden_size'], options['num_layers'], batch_first=True)\n",
    "        self.projection = nn.Linear(options['hidden_size']*options['num_layers'], options['num_labels'])\n",
    "        \n",
    "    def forward(self, encoded_input_sequence, attn):\n",
    "        \"\"\"\n",
    "        Forward method process the input from token ids to logits\n",
    "        \"\"\"\n",
    "        embeddings = self.lookup(encoded_input_sequence)\n",
    "        lstm_outputs, (hn, cn) = self.lstm(embeddings)\n",
    "        output_weighted = torch.sum((attn.unsqueeze(-1).float()*lstm_outputs.float()), 1)\n",
    "        \n",
    "        logits = self.projection(output_weighted)\n",
    "        \n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StructuredSelfAttention(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    The class is an implementation of the paper A Structured Self-Attentive Sentence Embedding including regularization\n",
    "    and without pruning. Slight modifications have been done for speedup\n",
    "    \"\"\"\n",
    "   \n",
    "    def __init__(self,batch_size,lstm_hid_dim,d_a,r,emb_dim=100,vocab_size=None,use_pretrained_embeddings = False,embeddings=None,n_classes = 1):\n",
    "        \"\"\"\n",
    "        Initializes parameters suggested in paper\n",
    " \n",
    "        Args:\n",
    "            batch_size  : {int} batch_size used for training\n",
    "            lstm_hid_dim: {int} hidden dimension for lstm\n",
    "            d_a         : {int} hidden dimension for the dense layer\n",
    "            r           : {int} attention-hops or attention heads\n",
    "            max_len     : {int} number of lstm timesteps\n",
    "            emb_dim     : {int} embeddings dimension\n",
    "            vocab_size  : {int} size of the vocabulary\n",
    "            use_pretrained_embeddings: {bool} use or train your own embeddings\n",
    "            embeddings  : {torch.FloatTensor} loaded pretrained embeddings\n",
    "            type        : [0,1] 0-->binary_classification 1-->multiclass classification\n",
    "            n_classes   : {int} number of classes\n",
    " \n",
    "        Returns:\n",
    "            self\n",
    " \n",
    "        Raises:\n",
    "            Exception\n",
    "        \"\"\"\n",
    "        super(StructuredSelfAttention,self).__init__()\n",
    "       \n",
    "        self.embeddings,emb_dim = self._load_embeddings(use_pretrained_embeddings,embeddings,vocab_size,emb_dim)\n",
    "        self.lstm = torch.nn.LSTM(emb_dim,lstm_hid_dim,1,batch_first=True)\n",
    "        self.linear_first = torch.nn.Linear(lstm_hid_dim,d_a)\n",
    "        self.linear_first.bias.data.fill_(0)\n",
    "        self.linear_second = torch.nn.Linear(d_a,r)\n",
    "        self.linear_second.bias.data.fill_(0)\n",
    "        self.n_classes = n_classes\n",
    "        self.linear_final = torch.nn.Linear(lstm_hid_dim,self.n_classes)\n",
    "        self.batch_size = batch_size       \n",
    "        self.lstm_hid_dim = lstm_hid_dim\n",
    "        self.hidden_state = self.init_hidden()\n",
    "        self.r = r\n",
    "                 \n",
    "    def _load_embeddings(self,use_pretrained_embeddings,embeddings,vocab_size,emb_dim):\n",
    "        \"\"\"Load the embeddings based on flag\"\"\"\n",
    "       \n",
    "        if use_pretrained_embeddings is True and embeddings is None:\n",
    "            raise Exception(\"Send a pretrained word embedding as an argument\")\n",
    "           \n",
    "        if not use_pretrained_embeddings and vocab_size is None:\n",
    "            raise Exception(\"Vocab size cannot be empty\")\n",
    "   \n",
    "        if not use_pretrained_embeddings:\n",
    "            word_embeddings = torch.nn.Embedding(vocab_size,emb_dim,padding_idx=0)\n",
    "            \n",
    "        elif use_pretrained_embeddings:\n",
    "            word_embeddings = torch.nn.Embedding(embeddings.size(0), embeddings.size(1))\n",
    "            word_embeddings.weight = torch.nn.Parameter(embeddings)\n",
    "            emb_dim = embeddings.size(1)\n",
    "            \n",
    "        return word_embeddings,emb_dim\n",
    "       \n",
    "        \n",
    "    def softmax(self,input, axis=1):\n",
    "        \"\"\"\n",
    "        Softmax applied to axis=n\n",
    " \n",
    "        Args:\n",
    "           input: {Tensor,Variable} input on which softmax is to be applied\n",
    "           axis : {int} axis on which softmax is to be applied\n",
    " \n",
    "        Returns:\n",
    "            softmaxed tensors\n",
    " \n",
    "       \n",
    "        \"\"\"\n",
    " \n",
    "        input_size = input.size()\n",
    "        trans_input = input.transpose(axis, len(input_size)-1)\n",
    "        trans_size = trans_input.size()\n",
    "        input_2d = trans_input.contiguous().view(-1, trans_size[-1])\n",
    "        soft_max_2d = F.softmax(input_2d)\n",
    "        soft_max_nd = soft_max_2d.view(*trans_size)\n",
    "        return soft_max_nd.transpose(axis, len(input_size)-1)\n",
    "       \n",
    "        \n",
    "    def init_hidden(self):\n",
    "        return (Variable(torch.zeros(1,self.batch_size,self.lstm_hid_dim)),Variable(torch.zeros(1,self.batch_size,self.lstm_hid_dim)))\n",
    "       \n",
    "        \n",
    "    def forward(self,x):\n",
    "        embeddings = self.embeddings(x)       \n",
    "        outputs, self.hidden_state = self.lstm(embeddings)       \n",
    "        x = F.tanh(self.linear_first(outputs))       \n",
    "        x = self.linear_second(x)       \n",
    "        x = self.softmax(x,1)       \n",
    "        attention = x.transpose(1,2)       \n",
    "        sentence_embeddings = attention@outputs       \n",
    "        avg_sentence_embeddings = torch.sum(sentence_embeddings,1)/self.r\n",
    "       \n",
    "        output = self.linear_final(avg_sentence_embeddings)\n",
    "        return output, attention\n",
    "       \n",
    "\t   \n",
    "\t#Regularization\n",
    "    def l2_matrix_norm(self,m):\n",
    "        \"\"\"\n",
    "        Frobenius norm calculation\n",
    " \n",
    "        Args:\n",
    "           m: {Variable} ||AAT - I||\n",
    " \n",
    "        Returns:\n",
    "            regularized value\n",
    " \n",
    "       \n",
    "        \"\"\"\n",
    "        return torch.sum(torch.sum(torch.sum(m**2,1),1)**0.5).type(torch.DoubleTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FILE = '/scratch/sa5154/Capstone/Models/wikitext_tokenized.p'\n",
    "wiki_df =  pkl.load(open(OUTPUT_FILE, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = []\n",
    "for i in list(wiki_df['mid_level_categories']):\n",
    "    categories.extend(i)\n",
    "categories = sorted(list(set(categories)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_to_index = {categories[i]:i for i in range(0, len(categories))}\n",
    "index_to_category = {v:k for k, v in category_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_df['category_tokens'] = wiki_df.apply(lambda row: convCategories(row['mid_level_categories'], category_to_index), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_df = wiki_df[wiki_df.astype(str)['category_tokens'] != '[]']\n",
    "wiki_df = wiki_df[wiki_df.astype(str)['tokens'] != '[]']\n",
    "wiki_df = wiki_df.reset_index().drop('index', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_train, wiki_valid, wiki_test = train_validate_test_split(wiki_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = list(wiki_train['category_tokens'])\n",
    "y_val = list(wiki_valid['category_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = sorted(set([y for x in list(wiki_train['tokens']) for y in x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list =[]\n",
    "for index, row in wiki_train.iterrows():\n",
    "    train_list.append(' '.join(row.tokens))\n",
    "\n",
    "val_list =[]\n",
    "for index, row in wiki_valid.iterrows():\n",
    "    val_list.append(' '.join(row.tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79968/79968 [00:17<00:00, 4488.24it/s]\n"
     ]
    }
   ],
   "source": [
    "# Get inverse document frequency\n",
    "IDF = {}\n",
    "for i in tqdm(range(len(train_list))):\n",
    "    tokens = train_list[i]\n",
    "    for w in tokens.split(' '):\n",
    "        try:\n",
    "            IDF[w].add(i)\n",
    "        except:\n",
    "            IDF[w] = {i}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in IDF:\n",
    "    IDF[i] = len(IDF[i])\n",
    "    IDF[i] = np.log(len(vocab)/(1+IDF[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79968/79968 [00:14<00:00, 5676.74it/s]\n"
     ]
    }
   ],
   "source": [
    "IDF_list_train = []\n",
    "for i in tqdm(range(len(train_list))):\n",
    "    tokens = train_list[i]\n",
    "    list_temp = []\n",
    "    for w in tokens.split(' '):\n",
    "        if w in IDF:\n",
    "            list_temp.append(IDF[w])\n",
    "        else:\n",
    "            list_temp.append(0)\n",
    "    IDF_list_train.append(list_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9996/9996 [00:01<00:00, 6383.15it/s]\n"
     ]
    }
   ],
   "source": [
    "IDF_list_val = []\n",
    "for i in tqdm(range(len(val_list))):\n",
    "    tokens = val_list[i]\n",
    "    list_temp = []\n",
    "    for w in tokens.split(' '):\n",
    "        if w in IDF:\n",
    "            list_temp.append(IDF[w])\n",
    "        else:\n",
    "            list_temp.append(0)\n",
    "    IDF_list_val.append(list_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "595516"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index = {\"<PAD>\":0, \"<UNK>\":1}\n",
    "for word in vocab:\n",
    "    if(word not in word_to_index):\n",
    "        word_to_index[word]=len(word_to_index)\n",
    "index_to_word = {v:k for k, v in word_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79968/79968 [00:08<00:00, 9505.45it/s] \n"
     ]
    }
   ],
   "source": [
    "wiki_tokenized_train = tokenize_dataset(wiki_train, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9996/9996 [00:01<00:00, 8694.59it/s]\n"
     ]
    }
   ],
   "source": [
    "wiki_tokenized_val = tokenize_dataset(wiki_valid, word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_tokenized_datasets = {}\n",
    "wiki_tokenized_datasets['train'] = wiki_tokenized_train\n",
    "wiki_tokenized_datasets['val'] = wiki_tokenized_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_tensor_dataset = {}\n",
    "wiki_tensor_dataset['train'] = TensoredDataset(wiki_tokenized_datasets['train'], y_train, IDF_list_train)\n",
    "wiki_tensor_dataset['val'] = TensoredDataset(wiki_tokenized_datasets['val'], y_val, IDF_list_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_loaders = {}\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "for split, wiki_dataset in wiki_tensor_dataset.items():\n",
    "    wiki_loaders[split] = DataLoader(wiki_dataset, batch_size=batch_size, shuffle=True, collate_fn=pad_collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Validate(model):\n",
    "    valid_loss_cache = 0\n",
    "    all_targets = []\n",
    "    all_logits = []\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for i, (inp, target, attn) in enumerate(wiki_loaders['val']):\n",
    "            inp = inp.to(current_device)\n",
    "            target = target.to(current_device)\n",
    "            attn = attn.to(current_device)\n",
    "            logits = model(inp, attn)\n",
    "            loss = criterion(logits, target)\n",
    "            m = nn.Sigmoid()\n",
    "            logits = m(logits)\n",
    "            logits = logits.cpu().detach().numpy()\n",
    "            target = target.cpu().numpy()\n",
    "            all_targets.append(target)\n",
    "            all_logits.append(logits)\n",
    "            valid_loss_cache += loss.item()\n",
    "\n",
    "        avg_val_loss = valid_loss_cache / (i+1)\n",
    "        all_logits = np.concatenate(all_logits, axis=0)\n",
    "        all_targets = np.concatenate(all_targets, axis=0)\n",
    "        all_logits[all_logits > 0.5] = 1\n",
    "        all_logits[all_logits <= 0.5] = 0\n",
    "        prec_macro, rec_macro, f_score_macro, _ = precision_recall_fscore_support(all_targets, all_logits, average = 'macro')\n",
    "        print('Validation macro prec: {}, rec:{}, f_score:{}'.format(prec_macro, rec_macro, f_score_macro))\n",
    "        prec_micro, rec_micro, f_score_micro, _ = precision_recall_fscore_support(all_targets, all_logits, average = 'micro')\n",
    "        print('Validation micro prec: {}, rec:{}, f_score:{}'.format(prec_micro, rec_micro, f_score_micro))\n",
    "        print('Validation loss = {:.{prec}f}'.format(avg_val_loss, prec=4))\n",
    "        return f_score_micro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre Trained Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2519371it [03:16, 12812.29it/s]\n"
     ]
    }
   ],
   "source": [
    "#Loading pre trained fastText word embeddings\n",
    "def load_vectors(fname):\n",
    "    fin = io.open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
    "    data = {}\n",
    "    for line in tqdm(fin):\n",
    "        tokens = line.rstrip().split(' ')\n",
    "        data[tokens[0]] = list(map(float, tokens[1:]))\n",
    "    return data\n",
    "\n",
    "fasttext_emb = load_vectors(\"wiki.en.align.vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the weight matrix for pretrained word embeddings\n",
    "vocab_size = len(index_to_word)\n",
    "embed_dim = len(fasttext_emb[\"apple\"])\n",
    "weights_matrix = np.zeros((vocab_size,embed_dim))\n",
    "\n",
    "words_found = 0\n",
    "for i, word in enumerate(word_to_index):\n",
    "    try: \n",
    "        weights_matrix[i] = fasttext_emb[word]\n",
    "        words_found += 1\n",
    "    except KeyError:\n",
    "        weights_matrix[i] = np.random.normal(scale=0.6, size=(embed_dim))\n",
    "weights_matrix = torch.FloatTensor(weights_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in vocab: 595516\n",
      "No. of words from vocab found in fastText: 470498\n"
     ]
    }
   ],
   "source": [
    "print(\"Total words in vocab: {}\".format(len(vocab)))\n",
    "print(\"No. of words from vocab found in fastText: {}\".format(words_found))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {\n",
    "    'num_embeddings': len(word_to_index),\n",
    "    'embedding_dim': weights_matrix.size(1),\n",
    "    'num_labels':44,\n",
    "    'padding_idx': word_to_index['<PAD>'],\n",
    "    'input_size': weights_matrix.size(1),\n",
    "    'hidden_size': 128,\n",
    "    'num_layers': 1,\n",
    "}\n",
    "\n",
    "model = LSTModel(options).to(current_device)\n",
    "#model = StructuredSelfAttention(batch_size,64,64,1,emb_dim=100,vocab_size=len(vocab),use_pretrained_embeddings = True,embeddings=weights_matrix,n_classes = 44).to(current_device)\n",
    "\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "model_parameters = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = optim.Adam(model_parameters, lr=0.0005)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTModel(\n",
       "  (lookup): Embedding(595518, 300)\n",
       "  (lstm): LSTM(300, 128, batch_first=True)\n",
       "  (projection): Linear(in_features=128, out_features=44, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_f_score_micro = -1\n",
    "count = 0\n",
    "PATH = '/scratch/sa5154/Capstone/Models/LSTM_TFIDF.pth'\n",
    "for epoch_number in range(50):\n",
    "    print(\"Running Epoch:{}\".format(epoch_number + 1))\n",
    "    avg_loss = -1\n",
    "    # do train\n",
    "    model.train()\n",
    "\n",
    "    train_loss_cache = 0\n",
    "\n",
    "    for i, (inp, target, attn) in enumerate(wiki_loaders['train']):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        inp = inp.to(current_device)\n",
    "        target = target.to(current_device)\n",
    "        attn = attn.to(current_device)\n",
    "        logits= model(inp, attn)\n",
    "        loss = criterion(logits, target)\n",
    "        train_loss_cache += loss.item()\n",
    "       \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if i % 500 == 0:\n",
    "            avg_loss = train_loss_cache/(i+1)\n",
    "            print('Step {} avg train loss = {:.{prec}f}'.format(i, avg_loss, prec=4))\n",
    "\n",
    "            #do valid\n",
    "            f_score_micro = Validate(model)\n",
    "            if( f_score_micro > best_f_score_micro):\n",
    "                best_f_score_micro = f_score_micro\n",
    "                torch.save({\n",
    "                        'state_dict': model.state_dict(), 'options':options\n",
    "                        }, PATH)\n",
    "                print(\"Model saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTModel(\n",
       "  (lookup): Embedding(595518, 300)\n",
       "  (lstm): LSTM(300, 128, batch_first=True)\n",
       "  (projection): Linear(in_features=128, out_features=44, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PATH = '/scratch/sa5154/Capstone/Models/LSTM_TFIDF.pth'\n",
    "model_loaded = torch.load(PATH)\n",
    "model = LSTModel(model_loaded['options']).to(current_device)\n",
    "model.load_state_dict(model_loaded['state_dict'])\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation macro prec: 0.586680838325009, rec:0.5801327898279524, f_score:0.5737182960715755\n",
      "Validation micro prec: 0.8146804522643449, rec:0.7873546426693158, f_score:0.8007845001782955\n",
      "Validation loss = 0.0690\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8007845001782955"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Validate(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_per_class_tables(loader, model, device, class_names, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Help function that tests the model's performance on a dataset\n",
    "    @param: loader - data loader for the dataset to test against\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    outputs_list_nc = []\n",
    "    true_list_nc = []\n",
    "    with torch.no_grad():\n",
    "        for data, labels, attn in loader:\n",
    "            data_batch, label_batch, attn_batch = data.to(device), labels.float(), attn.to(device)\n",
    "            logits = model(data_batch, attn_batch)\n",
    "            outputs_bc = torch.sigmoid(logits)\n",
    "            outputs_bc = outputs_bc.detach().cpu().numpy().astype(np.float)\n",
    "            outputs_bc = (outputs_bc > threshold)\n",
    "            outputs_list_nc.append(outputs_bc)\n",
    "            true_list_nc.append(label_batch.detach().cpu().numpy().astype(np.float))\n",
    "    # to np.array\n",
    "    outputs_list_nc = np.vstack(outputs_list_nc)\n",
    "    true_list_nc = np.vstack(true_list_nc)\n",
    "    \n",
    "    # per class counts\n",
    "    counts_c = true_list_nc.sum(axis=0)\n",
    "    \n",
    "    # per class confusion matrix: TN, FN, TP, FP\n",
    "    confusion_matrix_c22 = multilabel_confusion_matrix(\n",
    "        true_list_nc,\n",
    "        outputs_list_nc,\n",
    "    )\n",
    "    confusion_matrix_c4 = confusion_matrix_c22.reshape(-1, 4)\n",
    "    \n",
    "    # per class precision, recall, f-score\n",
    "    precision_c, recall_c, f1_c, _ = precision_recall_fscore_support(\n",
    "        true_list_nc,\n",
    "        outputs_list_nc,\n",
    "        average=None\n",
    "    )\n",
    "    \n",
    "    # combine all metrics in a dict\n",
    "    per_class_metrics = {\n",
    "        \"class_name\": class_names,\n",
    "        \"count\": counts_c,\n",
    "        \"TN\": confusion_matrix_c4[:,0], \n",
    "        \"FN\": confusion_matrix_c4[:,2],\n",
    "        \"TP\": confusion_matrix_c4[:,3],\n",
    "        \"FP\": confusion_matrix_c4[:,1],\n",
    "        \"precision\": precision_c, \n",
    "        \"recall\": recall_c, \n",
    "        \"f1\": f1_c\n",
    "    }\n",
    "    return pd.DataFrame(per_class_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "per_class_metrics = create_per_class_tables(wiki_loaders['val'], model, current_device, categories, threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class_name</th>\n",
       "      <th>count</th>\n",
       "      <th>TN</th>\n",
       "      <th>FN</th>\n",
       "      <th>TP</th>\n",
       "      <th>FP</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Culture.Language and literature</td>\n",
       "      <td>3631.0</td>\n",
       "      <td>6167</td>\n",
       "      <td>175</td>\n",
       "      <td>3456</td>\n",
       "      <td>198</td>\n",
       "      <td>0.945813</td>\n",
       "      <td>0.951804</td>\n",
       "      <td>0.948799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Culture.Sports</td>\n",
       "      <td>1567.0</td>\n",
       "      <td>8206</td>\n",
       "      <td>87</td>\n",
       "      <td>1480</td>\n",
       "      <td>223</td>\n",
       "      <td>0.869055</td>\n",
       "      <td>0.944480</td>\n",
       "      <td>0.905199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Geography.Oceania</td>\n",
       "      <td>468.0</td>\n",
       "      <td>9479</td>\n",
       "      <td>57</td>\n",
       "      <td>411</td>\n",
       "      <td>49</td>\n",
       "      <td>0.893478</td>\n",
       "      <td>0.878205</td>\n",
       "      <td>0.885776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>STEM.Biology</td>\n",
       "      <td>771.0</td>\n",
       "      <td>9181</td>\n",
       "      <td>153</td>\n",
       "      <td>618</td>\n",
       "      <td>44</td>\n",
       "      <td>0.933535</td>\n",
       "      <td>0.801556</td>\n",
       "      <td>0.862526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>History_And_Society.Transportation</td>\n",
       "      <td>551.0</td>\n",
       "      <td>9339</td>\n",
       "      <td>69</td>\n",
       "      <td>482</td>\n",
       "      <td>106</td>\n",
       "      <td>0.819728</td>\n",
       "      <td>0.874773</td>\n",
       "      <td>0.846356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Geography.Asia</td>\n",
       "      <td>1399.0</td>\n",
       "      <td>8384</td>\n",
       "      <td>244</td>\n",
       "      <td>1155</td>\n",
       "      <td>213</td>\n",
       "      <td>0.844298</td>\n",
       "      <td>0.825590</td>\n",
       "      <td>0.834839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Culture.Games and toys</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9873</td>\n",
       "      <td>22</td>\n",
       "      <td>87</td>\n",
       "      <td>14</td>\n",
       "      <td>0.861386</td>\n",
       "      <td>0.798165</td>\n",
       "      <td>0.828571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Culture.Music</td>\n",
       "      <td>435.0</td>\n",
       "      <td>9452</td>\n",
       "      <td>61</td>\n",
       "      <td>374</td>\n",
       "      <td>109</td>\n",
       "      <td>0.774327</td>\n",
       "      <td>0.859770</td>\n",
       "      <td>0.814815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>STEM.Space</td>\n",
       "      <td>67.0</td>\n",
       "      <td>9908</td>\n",
       "      <td>10</td>\n",
       "      <td>57</td>\n",
       "      <td>21</td>\n",
       "      <td>0.730769</td>\n",
       "      <td>0.850746</td>\n",
       "      <td>0.786207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Geography.Europe</td>\n",
       "      <td>2168.0</td>\n",
       "      <td>7454</td>\n",
       "      <td>571</td>\n",
       "      <td>1597</td>\n",
       "      <td>374</td>\n",
       "      <td>0.810249</td>\n",
       "      <td>0.736624</td>\n",
       "      <td>0.771684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Geography.Americas</td>\n",
       "      <td>1884.0</td>\n",
       "      <td>7730</td>\n",
       "      <td>472</td>\n",
       "      <td>1412</td>\n",
       "      <td>382</td>\n",
       "      <td>0.787068</td>\n",
       "      <td>0.749469</td>\n",
       "      <td>0.767809</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Culture.Entertainment</td>\n",
       "      <td>295.0</td>\n",
       "      <td>9641</td>\n",
       "      <td>84</td>\n",
       "      <td>211</td>\n",
       "      <td>60</td>\n",
       "      <td>0.778598</td>\n",
       "      <td>0.715254</td>\n",
       "      <td>0.745583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Culture.Plastic arts</td>\n",
       "      <td>302.0</td>\n",
       "      <td>9614</td>\n",
       "      <td>75</td>\n",
       "      <td>227</td>\n",
       "      <td>80</td>\n",
       "      <td>0.739414</td>\n",
       "      <td>0.751656</td>\n",
       "      <td>0.745484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>History_And_Society.Military and warfare</td>\n",
       "      <td>331.0</td>\n",
       "      <td>9598</td>\n",
       "      <td>99</td>\n",
       "      <td>232</td>\n",
       "      <td>67</td>\n",
       "      <td>0.775920</td>\n",
       "      <td>0.700906</td>\n",
       "      <td>0.736508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Geography.Bodies of water</td>\n",
       "      <td>81.0</td>\n",
       "      <td>9877</td>\n",
       "      <td>12</td>\n",
       "      <td>69</td>\n",
       "      <td>38</td>\n",
       "      <td>0.644860</td>\n",
       "      <td>0.851852</td>\n",
       "      <td>0.734043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Geography.Africa</td>\n",
       "      <td>225.0</td>\n",
       "      <td>9710</td>\n",
       "      <td>63</td>\n",
       "      <td>162</td>\n",
       "      <td>61</td>\n",
       "      <td>0.726457</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.723214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>STEM.Geosciences</td>\n",
       "      <td>90.0</td>\n",
       "      <td>9878</td>\n",
       "      <td>24</td>\n",
       "      <td>66</td>\n",
       "      <td>28</td>\n",
       "      <td>0.702128</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.717391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Culture.Broadcasting</td>\n",
       "      <td>217.0</td>\n",
       "      <td>9726</td>\n",
       "      <td>70</td>\n",
       "      <td>147</td>\n",
       "      <td>53</td>\n",
       "      <td>0.735000</td>\n",
       "      <td>0.677419</td>\n",
       "      <td>0.705036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Geography.Antarctica</td>\n",
       "      <td>27.0</td>\n",
       "      <td>9946</td>\n",
       "      <td>0</td>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.701299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>STEM.Technology</td>\n",
       "      <td>275.0</td>\n",
       "      <td>9581</td>\n",
       "      <td>67</td>\n",
       "      <td>208</td>\n",
       "      <td>140</td>\n",
       "      <td>0.597701</td>\n",
       "      <td>0.756364</td>\n",
       "      <td>0.667737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Culture.Arts</td>\n",
       "      <td>19.0</td>\n",
       "      <td>9974</td>\n",
       "      <td>8</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Culture.Food and drink</td>\n",
       "      <td>67.0</td>\n",
       "      <td>9921</td>\n",
       "      <td>30</td>\n",
       "      <td>37</td>\n",
       "      <td>8</td>\n",
       "      <td>0.822222</td>\n",
       "      <td>0.552239</td>\n",
       "      <td>0.660714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>History_And_Society.Politics and government</td>\n",
       "      <td>343.0</td>\n",
       "      <td>9580</td>\n",
       "      <td>147</td>\n",
       "      <td>196</td>\n",
       "      <td>73</td>\n",
       "      <td>0.728625</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.640523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>History_And_Society.Education</td>\n",
       "      <td>181.0</td>\n",
       "      <td>9775</td>\n",
       "      <td>83</td>\n",
       "      <td>98</td>\n",
       "      <td>40</td>\n",
       "      <td>0.710145</td>\n",
       "      <td>0.541436</td>\n",
       "      <td>0.614420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Culture.Visual arts</td>\n",
       "      <td>139.0</td>\n",
       "      <td>9788</td>\n",
       "      <td>51</td>\n",
       "      <td>88</td>\n",
       "      <td>69</td>\n",
       "      <td>0.560510</td>\n",
       "      <td>0.633094</td>\n",
       "      <td>0.594595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>STEM.Medicine</td>\n",
       "      <td>154.0</td>\n",
       "      <td>9815</td>\n",
       "      <td>80</td>\n",
       "      <td>74</td>\n",
       "      <td>27</td>\n",
       "      <td>0.732673</td>\n",
       "      <td>0.480519</td>\n",
       "      <td>0.580392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Culture.Performing arts</td>\n",
       "      <td>72.0</td>\n",
       "      <td>9899</td>\n",
       "      <td>34</td>\n",
       "      <td>38</td>\n",
       "      <td>25</td>\n",
       "      <td>0.603175</td>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.562963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Culture.Philosophy and religion</td>\n",
       "      <td>274.0</td>\n",
       "      <td>9672</td>\n",
       "      <td>162</td>\n",
       "      <td>112</td>\n",
       "      <td>50</td>\n",
       "      <td>0.691358</td>\n",
       "      <td>0.408759</td>\n",
       "      <td>0.513761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>History_And_Society.Business and economics</td>\n",
       "      <td>207.0</td>\n",
       "      <td>9668</td>\n",
       "      <td>103</td>\n",
       "      <td>104</td>\n",
       "      <td>121</td>\n",
       "      <td>0.462222</td>\n",
       "      <td>0.502415</td>\n",
       "      <td>0.481481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>STEM.Information science</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9979</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.454545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>STEM.Meteorology</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9989</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Culture.Crafts and hobbies</td>\n",
       "      <td>14.0</td>\n",
       "      <td>9971</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.437500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Geography.Parks</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9903</td>\n",
       "      <td>35</td>\n",
       "      <td>25</td>\n",
       "      <td>33</td>\n",
       "      <td>0.431034</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.423729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>STEM.Chemistry</td>\n",
       "      <td>36.0</td>\n",
       "      <td>9938</td>\n",
       "      <td>21</td>\n",
       "      <td>15</td>\n",
       "      <td>22</td>\n",
       "      <td>0.405405</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.410959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Geography.Landforms</td>\n",
       "      <td>57.0</td>\n",
       "      <td>9890</td>\n",
       "      <td>30</td>\n",
       "      <td>27</td>\n",
       "      <td>49</td>\n",
       "      <td>0.355263</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.406015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>STEM.Engineering</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9962</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.380952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>History_And_Society.History and society</td>\n",
       "      <td>449.0</td>\n",
       "      <td>9422</td>\n",
       "      <td>330</td>\n",
       "      <td>119</td>\n",
       "      <td>125</td>\n",
       "      <td>0.487705</td>\n",
       "      <td>0.265033</td>\n",
       "      <td>0.343434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>STEM.Time</td>\n",
       "      <td>29.0</td>\n",
       "      <td>9915</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>52</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.329897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>STEM.Mathematics</td>\n",
       "      <td>11.0</td>\n",
       "      <td>9968</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.303030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>STEM.Science</td>\n",
       "      <td>43.0</td>\n",
       "      <td>9937</td>\n",
       "      <td>34</td>\n",
       "      <td>9</td>\n",
       "      <td>16</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.209302</td>\n",
       "      <td>0.264706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>STEM.Physics</td>\n",
       "      <td>18.0</td>\n",
       "      <td>9972</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Culture.Media</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9987</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Culture.Internet culture</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9986</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Geography.Maps</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9991</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     class_name   count    TN   FN    TP   FP  \\\n",
       "7               Culture.Language and literature  3631.0  6167  175  3456  198   \n",
       "13                               Culture.Sports  1567.0  8206   87  1480  223   \n",
       "23                            Geography.Oceania   468.0  9479   57   411   49   \n",
       "31                                 STEM.Biology   771.0  9181  153   618   44   \n",
       "30           History_And_Society.Transportation   551.0  9339   69   482  106   \n",
       "18                               Geography.Asia  1399.0  8384  244  1155  213   \n",
       "5                        Culture.Games and toys   109.0  9873   22    87   14   \n",
       "9                                 Culture.Music   435.0  9452   61   374  109   \n",
       "41                                   STEM.Space    67.0  9908   10    57   21   \n",
       "20                             Geography.Europe  2168.0  7454  571  1597  374   \n",
       "16                           Geography.Americas  1884.0  7730  472  1412  382   \n",
       "3                         Culture.Entertainment   295.0  9641   84   211   60   \n",
       "12                         Culture.Plastic arts   302.0  9614   75   227   80   \n",
       "28     History_And_Society.Military and warfare   331.0  9598   99   232   67   \n",
       "19                    Geography.Bodies of water    81.0  9877   12    69   38   \n",
       "15                             Geography.Africa   225.0  9710   63   162   61   \n",
       "34                             STEM.Geosciences    90.0  9878   24    66   28   \n",
       "1                          Culture.Broadcasting   217.0  9726   70   147   53   \n",
       "17                         Geography.Antarctica    27.0  9946    0    27   23   \n",
       "42                              STEM.Technology   275.0  9581   67   208  140   \n",
       "0                                  Culture.Arts    19.0  9974    8    11    3   \n",
       "4                        Culture.Food and drink    67.0  9921   30    37    8   \n",
       "29  History_And_Society.Politics and government   343.0  9580  147   196   73   \n",
       "26                History_And_Society.Education   181.0  9775   83    98   40   \n",
       "14                          Culture.Visual arts   139.0  9788   51    88   69   \n",
       "37                                STEM.Medicine   154.0  9815   80    74   27   \n",
       "10                      Culture.Performing arts    72.0  9899   34    38   25   \n",
       "11              Culture.Philosophy and religion   274.0  9672  162   112   50   \n",
       "25   History_And_Society.Business and economics   207.0  9668  103   104  121   \n",
       "35                     STEM.Information science    10.0  9979    5     5    7   \n",
       "38                             STEM.Meteorology     5.0  9989    3     2    2   \n",
       "2                    Culture.Crafts and hobbies    14.0  9971    7     7   11   \n",
       "24                              Geography.Parks    60.0  9903   35    25   33   \n",
       "32                               STEM.Chemistry    36.0  9938   21    15   22   \n",
       "21                          Geography.Landforms    57.0  9890   30    27   49   \n",
       "33                             STEM.Engineering    22.0  9962   14     8   12   \n",
       "27      History_And_Society.History and society   449.0  9422  330   119  125   \n",
       "43                                    STEM.Time    29.0  9915   13    16   52   \n",
       "36                             STEM.Mathematics    11.0  9968    6     5   17   \n",
       "40                                 STEM.Science    43.0  9937   34     9   16   \n",
       "39                                 STEM.Physics    18.0  9972   18     0    6   \n",
       "8                                 Culture.Media     3.0  9987    3     0    6   \n",
       "6                      Culture.Internet culture     6.0  9986    6     0    4   \n",
       "22                               Geography.Maps     1.0  9991    1     0    4   \n",
       "\n",
       "    precision    recall        f1  \n",
       "7    0.945813  0.951804  0.948799  \n",
       "13   0.869055  0.944480  0.905199  \n",
       "23   0.893478  0.878205  0.885776  \n",
       "31   0.933535  0.801556  0.862526  \n",
       "30   0.819728  0.874773  0.846356  \n",
       "18   0.844298  0.825590  0.834839  \n",
       "5    0.861386  0.798165  0.828571  \n",
       "9    0.774327  0.859770  0.814815  \n",
       "41   0.730769  0.850746  0.786207  \n",
       "20   0.810249  0.736624  0.771684  \n",
       "16   0.787068  0.749469  0.767809  \n",
       "3    0.778598  0.715254  0.745583  \n",
       "12   0.739414  0.751656  0.745484  \n",
       "28   0.775920  0.700906  0.736508  \n",
       "19   0.644860  0.851852  0.734043  \n",
       "15   0.726457  0.720000  0.723214  \n",
       "34   0.702128  0.733333  0.717391  \n",
       "1    0.735000  0.677419  0.705036  \n",
       "17   0.540000  1.000000  0.701299  \n",
       "42   0.597701  0.756364  0.667737  \n",
       "0    0.785714  0.578947  0.666667  \n",
       "4    0.822222  0.552239  0.660714  \n",
       "29   0.728625  0.571429  0.640523  \n",
       "26   0.710145  0.541436  0.614420  \n",
       "14   0.560510  0.633094  0.594595  \n",
       "37   0.732673  0.480519  0.580392  \n",
       "10   0.603175  0.527778  0.562963  \n",
       "11   0.691358  0.408759  0.513761  \n",
       "25   0.462222  0.502415  0.481481  \n",
       "35   0.416667  0.500000  0.454545  \n",
       "38   0.500000  0.400000  0.444444  \n",
       "2    0.388889  0.500000  0.437500  \n",
       "24   0.431034  0.416667  0.423729  \n",
       "32   0.405405  0.416667  0.410959  \n",
       "21   0.355263  0.473684  0.406015  \n",
       "33   0.400000  0.363636  0.380952  \n",
       "27   0.487705  0.265033  0.343434  \n",
       "43   0.235294  0.551724  0.329897  \n",
       "36   0.227273  0.454545  0.303030  \n",
       "40   0.360000  0.209302  0.264706  \n",
       "39   0.000000  0.000000  0.000000  \n",
       "8    0.000000  0.000000  0.000000  \n",
       "6    0.000000  0.000000  0.000000  \n",
       "22   0.000000  0.000000  0.000000  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "per_class_metrics.sort_values('f1', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

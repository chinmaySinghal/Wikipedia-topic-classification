{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import nltk\n",
    "import json\n",
    "import io\n",
    "import gzip\n",
    "import torch\n",
    "import string\n",
    "import random\n",
    "import jsonlines\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, RandomSampler, SequentialSampler, DataLoader\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_EMBEDDINGS_FOLDER = \"/scratch/mz2476/wiki/embeddings/\"\n",
    "PATH_TO_DATA_FOLDER = \"/scratch/mz2476/wiki/data/\"\n",
    "PATH_TO_MODELS_FOLDER = \"/scratch/mz2476/wiki/models/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/mz2476/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from preprocess import create_lookups_for_vocab, pad_collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size is: 682850\n"
     ]
    }
   ],
   "source": [
    "# LOAD vocab, tensor dataset, classes\n",
    "vocab = torch.load(PATH_TO_DATA_FOLDER + \"vocab_all_en.pt\")\n",
    "print(\"Vocab size is:\", len(vocab))\n",
    "index_to_word, word_to_index = create_lookups_for_vocab(vocab)\n",
    "\n",
    "wiki_tensor_dataset = torch.load(PATH_TO_DATA_FOLDER + \"wiki_tensor_dataset_vocab_all_en.pt\")\n",
    "\n",
    "classes = torch.load(PATH_TO_DATA_FOLDER + \"classes_list.pt\")\n",
    "mlb = MultiLabelBinarizer(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([13030,  8330,  3721,  8330,  3721,   132,  2496, 13031,  4719,  3982,\n",
       "         13031,  3178,   303,  5510, 13032,  8334,  2496, 13031,  4719,  1828,\n",
       "          2496,  1985, 13033, 10701, 13034,     7,  5299,  2338,  6948,     5,\n",
       "             9,     9,     8, 10510,   480, 13035, 13036, 11814, 13035, 13036,\n",
       "           965,   933,  2789,     5,   223,    10,   933, 13037,  6777,  1646,\n",
       "          3271, 13038,  2496, 13031,  4719,  1036, 13039,  1985,  2300,  1495,\n",
       "           601, 13040,  1495,     5,     9,   208,     6,     5,     9,     9,\n",
       "            11,   568,     5,     9,     9,   208, 13041,  1467,   403, 13042,\n",
       "          9309,  1065, 13043, 13044, 13043, 13044,  2300,  2189,  1880,  8330,\n",
       "          4719,   452,    10,     8,     8,     8, 13035, 13036,    21, 13045,\n",
       "          2300, 13045,  2641,  3721,  4340,  4251, 13043, 13044, 13046,  2496,\n",
       "         13031,  4719,  4340, 13045, 13047, 13048, 13049, 13050,  5496,  9571,\n",
       "           648,     5,     9,    10,     8,     5,    11, 13051,  6945,  9127,\n",
       "          2496,    53,  5458, 13051,  6945,  9127,  6945,  9127,  2025,   833,\n",
       "          6777,  3721, 13052,  3271, 13053, 13054,  3721, 11814, 13035, 13036,\n",
       "           689,  1261,    10,     8,     5,   253, 13055,  2496, 13031,  4719,\n",
       "         12197, 13052,  3271, 13053,  3721,  5251,   952,  3078,   167,  6674,\n",
       "            10,  8340,   439,  1366, 13056,   952,  1199,    10,     8,     5,\n",
       "             6,  3541,  1816,   794,    10,     8,     8,   611,   532,    10,\n",
       "             8,    10,     8,  1108, 13057,  2471,  5251,   952,   439,  8340,\n",
       "          1140,  2496, 13031,  4719,   132, 10436,  3078,  3271, 13053,   132,\n",
       "            58, 13058,   414, 13031,   132,   277,  2496,  2076, 13031,  1869,\n",
       "           525,    24, 13031,  4719,   526,  8330,  8340,  2496,    81,   397,\n",
       "           398, 13059,  3435,  2869,  2496, 13031,  8330,  8340,  2055,     5,\n",
       "             9,     9,     8,  8330,  8340,  2496, 13035, 13036]),\n",
       " tensor([248.]),\n",
       " tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki_tensor_dataset[\"train\"].__getitem__(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloader\n",
    "wiki_loaders = {}\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "for split, wiki_dataset in wiki_tensor_dataset.items():\n",
    "    wiki_loaders[split] = DataLoader(\n",
    "        wiki_dataset, \n",
    "        batch_size=batch_size, \n",
    "        shuffle=True, \n",
    "        collate_fn=partial(pad_collate_fn, word_to_index=word_to_index)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the embeddings and make a pretrained embeddings matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils' from '/home/mz2476/topic-modeling/topic-modeling/baseline/utils.py'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import utils\n",
    "import importlib\n",
    "importlib.reload(utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2519370it [03:08, 13337.59it/s]\n"
     ]
    }
   ],
   "source": [
    "# # Aligned fasstext. 2.5 million\n",
    "embeddings = utils.load_vectors(PATH_TO_EMBEDDINGS_FOLDER + \"wiki.en.align.vec\")\n",
    "\n",
    "# # CHANGE to googlenews vectors\n",
    "# import gensim\n",
    " \n",
    "# model = gensim.models.KeyedVectors.load(\"/scratch/mz2476/GoogleNews-vectors-negative300.bin\", binary=True)  \n",
    " \n",
    "# embeddings = model.vocab.keys()\n",
    "# wordsInVocab = len(embeddings)\n",
    "# print (wordsInVocab)\n",
    "\n",
    "# # embeddings = load_vectors(\"/scratch/mz2476/GoogleNews-vectors-negative300.bin\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words in vocab: 682850\n",
      "No. of words from vocab found in embeddings: 528314\n"
     ]
    }
   ],
   "source": [
    "#Creating the weight matrix for pretrained word embeddings\n",
    "weights_matrix_ve = utils.create_embeddings_matrix(word_to_index, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model\n",
    "import importlib\n",
    "importlib.reload(model)\n",
    "\n",
    "from model import FinalModel\n",
    "from torchcontrib.optim import SWA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = {\n",
    "    \"VOCAB_SIZE\": len(index_to_word),\n",
    "    \"dim_e\": weights_matrix.shape[1],\n",
    "    \"pretrained_embeddings\": weights_matrix,\n",
    "    \"num_layers\": 2,\n",
    "    \"num_classes\": len(mlb.classes_),\n",
    "    \"mid_features\": 150,\n",
    "    \"dropout_rate\": 0.2,\n",
    "    \"activation\": nn.ReLU()\n",
    "}\n",
    "model = FinalModel(options)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model = model.to(device)\n",
    "    \n",
    "# Criterion and Optimizer\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "base_opt = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "optimizer = SWA(base_opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FinalModel(\n",
       "  (layer_bag_of_words): BagOfWords(\n",
       "    (embed_e): Embedding(595366, 300)\n",
       "  )\n",
       "  (layer_out): Sequential(\n",
       "    (0): Linear(in_features=300, out_features=150, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=150, out_features=44, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search vs. Random search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ol>\n",
    "    <li> dropout </li>\n",
    "    <li> learning rate </li>\n",
    "    <li> optimizer </li>\n",
    "    <li> num of hidden layers </li>\n",
    "    <li> dim of hidden layers </li>\n",
    "    <li> take only first 500 words from the article </li>\n",
    "    <li> TODO threshold </li>\n",
    "<ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I focused on SWA optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # one layer\n",
    "# range_dropout = [0]\n",
    "# range_num_hidden = [1]\n",
    "# range_dim_hidden = [80, 120, 150]\n",
    "# range_lr = [0.01]\n",
    "\n",
    "# many layers\n",
    "range_dropout = [0, 0.1, 0.2]\n",
    "range_num_hidden = [2, 3]\n",
    "range_dim_hidden = [40, 80, 120]\n",
    "range_lr = [0.001, 0.01]\n",
    "\n",
    "# # best hyperparams\n",
    "# range_dropout = [0.2]\n",
    "# range_num_hidden = [2]\n",
    "# range_dim_hidden = [120, 150, 200]\n",
    "# range_lr = [0.01]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model\n",
    "import importlib\n",
    "importlib.reload(model)\n",
    "\n",
    "from model import FinalModel\n",
    "from torchcontrib.optim import SWA\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from utils import test_model\n",
    "\n",
    "def train_model(wiki_loaders, model, criterion, optimizer, num_epochs=10, device=device, model_name=\"model\"):\n",
    "    best_val_f1_micro = 0\n",
    "    best_metrics_dict = {}\n",
    "    for epoch in range(num_epochs):\n",
    "        runnin_loss = 0.0\n",
    "        for i, (data, length, labels) in enumerate(wiki_loaders[\"train\"]):        \n",
    "            model.train()\n",
    "            data_batch, length_batch, label_batch = data.to(device),length.to(device), labels.float().to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data_batch, length_batch)\n",
    "            loss = criterion(outputs, label_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            runnin_loss += loss.item()\n",
    "            #torch.nn.utils.clip_grad_norm(model.parameters(), 10)\n",
    "            if i>0 and i % 1000 == 0:\n",
    "                print('Epoch: [{}/{}], Step: [{}/{}], Train_loss: {}'.format(\n",
    "                    epoch+1, num_epochs, i+1, len(wiki_loaders[\"train\"]), runnin_loss / i))\n",
    "            # validate every 300 iterations\n",
    "            if i > 0 and i % 1000 == 0:\n",
    "                optimizer.update_swa()\n",
    "                metrics_dict = test_model(wiki_loaders[\"val\"], model, device=device)\n",
    "                print(\"Precision macro: {}, Recall macro: {}, F1 macro: {} \".format(\n",
    "                    metrics_dict[\"precision_macro\"], metrics_dict[\"recall_macro\"], metrics_dict[\"f1_macro\"]\n",
    "                ))\n",
    "                print(\"Precision micro: {}, Recall micro: {}, F1 micro: {} \".format(\n",
    "                    metrics_dict[\"precision_micro\"], metrics_dict[\"recall_micro\"], metrics_dict[\"f1_micro\"]\n",
    "                ))\n",
    "\n",
    "                if metrics_dict[\"f1_micro\"] > best_val_f1_micro:\n",
    "                    best_val_f1_micro = metrics_dict[\"f1_micro\"]\n",
    "                    best_metrics_dict = metrics_dict\n",
    "                    optimizer.swap_swa_sgd()\n",
    "                    torch.save(model.state_dict(), f\"{PATH_TO_MODELS_FOLDER}en_{model_name}.pth\")\n",
    "                    print('Model Saved')\n",
    "                    print()\n",
    "    optimizer.swap_swa_sgd()\n",
    "    return best_metrics_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df_without_best = results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " {'optimizer': 'SWA', 'num_hidden': 2, 'dim_hidden': 40, 'dropout_rate': 0, 'learning_rate': 0.001, 'num_epochs': 10}\n",
      "Epoch: [1/10], Step: [1001/2499], Train_loss: 0.1613335421010852\n",
      "Precision macro: 0.07763095820863863, Recall macro: 0.022133927127800327, F1 macro: 0.02803677062124604 \n",
      "Precision micro: 0.6717482173592328, Recall micro: 0.15964471454449833, F1 micro: 0.2579792256846081 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [1/10], Step: [2001/2499], Train_loss: 0.13147279946506024\n",
      "Precision macro: 0.11809104702657391, Recall macro: 0.061221524474661226, F1 macro: 0.0676405812609879 \n",
      "Precision micro: 0.7536959954069183, Recall micro: 0.3068427511248758, F1 micro: 0.43612956810631226 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [2/10], Step: [1001/2499], Train_loss: 0.08414565202966333\n",
      "Precision macro: 0.15466359242020145, Recall macro: 0.09444943925158747, F1 macro: 0.10662958689069836 \n",
      "Precision micro: 0.7951121879279469, Recall micro: 0.4410681937708175, F1 micro: 0.5673908141020823 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [2/10], Step: [2001/2499], Train_loss: 0.0829362342171371\n",
      "Precision macro: 0.2003969834251638, Recall macro: 0.10030206781573629, F1 macro: 0.11315574429679455 \n",
      "Precision micro: 0.8110995850622407, Recall micro: 0.45690410798807923, F1 micro: 0.5845325757858931 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [3/10], Step: [1001/2499], Train_loss: 0.07102981609851122\n",
      "Precision macro: 0.30059340191407036, Recall macro: 0.13502718795778146, F1 macro: 0.15685563121917334 \n",
      "Precision micro: 0.8170898170898171, Recall micro: 0.524688833050897, F1 micro: 0.6390292505871469 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [3/10], Step: [2001/2499], Train_loss: 0.07137939257733524\n",
      "Precision macro: 0.27866896659111257, Recall macro: 0.12831827379083338, F1 macro: 0.14980718275922222 \n",
      "Precision micro: 0.8232227488151659, Recall micro: 0.5075089113539415, F1 micro: 0.6279145428912265 \n",
      "Epoch: [4/10], Step: [1001/2499], Train_loss: 0.06365261610969901\n",
      "Precision macro: 0.36272392782588775, Recall macro: 0.1668015884493493, F1 macro: 0.19817612170677223 \n",
      "Precision micro: 0.829625797551302, Recall micro: 0.5622626073745106, F1 micro: 0.6702657518024451 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [4/10], Step: [2001/2499], Train_loss: 0.0641889440510422\n",
      "Precision macro: 0.36393171020288195, Recall macro: 0.16590300871165223, F1 macro: 0.19672826605874197 \n",
      "Precision micro: 0.8224643899090441, Recall micro: 0.560100508385438, F1 micro: 0.6663885702367296 \n",
      "Epoch: [5/10], Step: [1001/2499], Train_loss: 0.05933181545883417\n",
      "Precision macro: 0.432218646984138, Recall macro: 0.1983965216228907, F1 macro: 0.23738769779207586 \n",
      "Precision micro: 0.8369366372858806, Recall micro: 0.5881493601355694, F1 micro: 0.6908267270668177 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [5/10], Step: [2001/2499], Train_loss: 0.059824428640305995\n",
      "Precision macro: 0.4199456973424733, Recall macro: 0.1988261294247742, F1 macro: 0.2360876684857556 \n",
      "Precision micro: 0.8374487318992215, Recall micro: 0.584643253666803, F1 micro: 0.688575361321404 \n",
      "Epoch: [6/10], Step: [1001/2499], Train_loss: 0.05665300438553095\n",
      "Precision macro: 0.44309613952688776, Recall macro: 0.2186398434719199, F1 macro: 0.2614985553048511 \n",
      "Precision micro: 0.8318030710780434, Recall micro: 0.6140945480044411, F1 micro: 0.7065586445692003 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [6/10], Step: [2001/2499], Train_loss: 0.056971511159092186\n",
      "Precision macro: 0.4462593886019939, Recall macro: 0.21972494145455573, F1 macro: 0.26002531501169557 \n",
      "Precision micro: 0.8305592805868897, Recall micro: 0.6152632501606965, F1 micro: 0.7068815038603558 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [7/10], Step: [1001/2499], Train_loss: 0.05440715150535107\n",
      "Precision macro: 0.49912000832755116, Recall macro: 0.2531101386731522, F1 macro: 0.29890006151305704 \n",
      "Precision micro: 0.8222023676569131, Recall micro: 0.6452988955764624, F1 micro: 0.7230880041906756 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [7/10], Step: [2001/2499], Train_loss: 0.05484144066646695\n",
      "Precision macro: 0.4664014126215013, Recall macro: 0.24516556719258056, F1 macro: 0.29240918496710205 \n",
      "Precision micro: 0.8301814268142681, Recall micro: 0.6310407292701455, F1 micro: 0.7170412668902095 \n",
      "Epoch: [8/10], Step: [1001/2499], Train_loss: 0.053180619910359384\n",
      "Precision macro: 0.5163594067611879, Recall macro: 0.2692891171814398, F1 macro: 0.31965102205461327 \n",
      "Precision micro: 0.8338216512658704, Recall micro: 0.6485712616139777, F1 micro: 0.7296213515645544 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [8/10], Step: [2001/2499], Train_loss: 0.05305031879525632\n",
      "Precision macro: 0.5283511965083475, Recall macro: 0.26414482950465784, F1 macro: 0.313878477494937 \n",
      "Precision micro: 0.8336609708150613, Recall micro: 0.6443054987436452, F1 micro: 0.726853225221662 \n",
      "Epoch: [9/10], Step: [1001/2499], Train_loss: 0.05155713684670627\n",
      "Precision macro: 0.5329218043888294, Recall macro: 0.2946615042576652, F1 macro: 0.35077385578326187 \n",
      "Precision micro: 0.8341926929876252, Recall micro: 0.6617775959796646, F1 micro: 0.7380494639773209 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [9/10], Step: [2001/2499], Train_loss: 0.051850678117014465\n",
      "Precision macro: 0.540059315411565, Recall macro: 0.27517132940989075, F1 macro: 0.33388903050917645 \n",
      "Precision micro: 0.8474339035769829, Recall micro: 0.6368258049436101, F1 micro: 0.7271878023554531 \n",
      "Epoch: [10/10], Step: [1001/2499], Train_loss: 0.050932021727785465\n",
      "Precision macro: 0.5400990436242795, Recall macro: 0.30842387794060777, F1 macro: 0.36560244179309404 \n",
      "Precision micro: 0.8338169157115914, Recall micro: 0.6717115643078362, F1 micro: 0.7440370238519045 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [10/10], Step: [2001/2499], Train_loss: 0.05056303682923317\n",
      "Precision macro: 0.5313848855259032, Recall macro: 0.3161078485685251, F1 macro: 0.37067053129100125 \n",
      "Precision micro: 0.8316731629854194, Recall micro: 0.6732893122187811, F1 micro: 0.7441469951884265 \n",
      "Model Saved\n",
      "\n",
      "\n",
      " {'optimizer': 'SWA', 'num_hidden': 2, 'dim_hidden': 40, 'dropout_rate': 0, 'learning_rate': 0.01, 'num_epochs': 10}\n",
      "Epoch: [1/10], Step: [1001/2499], Train_loss: 0.09420600923895836\n",
      "Precision macro: 0.2900471927531631, Recall macro: 0.1651449987330909, F1 macro: 0.19025626885182298 \n",
      "Precision micro: 0.821841505612288, Recall micro: 0.5690410798807923, F1 micro: 0.6724673710379118 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [1/10], Step: [2001/2499], Train_loss: 0.0763409390365705\n",
      "Precision macro: 0.4635147291894992, Recall macro: 0.25432265734408116, F1 macro: 0.29668457898506917 \n",
      "Precision micro: 0.8370050960407683, Recall micro: 0.6238532110091743, F1 micro: 0.714878800053569 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [2/10], Step: [1001/2499], Train_loss: 0.05156842380389571\n",
      "Precision macro: 0.5177337266675539, Recall macro: 0.3382314314920541, F1 macro: 0.3886269640730653 \n",
      "Precision micro: 0.8285855309547313, Recall micro: 0.6866709519079063, F1 micro: 0.7509825850774884 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [2/10], Step: [2001/2499], Train_loss: 0.05109807264991104\n",
      "Precision macro: 0.5233246110069584, Recall macro: 0.3526164479789486, F1 macro: 0.40634478397372165 \n",
      "Precision micro: 0.8272512834743999, Recall micro: 0.6967802255595161, F1 micro: 0.7564309956545183 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [3/10], Step: [1001/2499], Train_loss: 0.047541171576827766\n",
      "Precision macro: 0.5670676112246832, Recall macro: 0.3721155042872965, F1 macro: 0.4256546430187477 \n",
      "Precision micro: 0.8418766908728463, Recall micro: 0.6909951498860515, F1 micro: 0.7590102378125101 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [3/10], Step: [2001/2499], Train_loss: 0.04751466442085803\n",
      "Precision macro: 0.5670851004333811, Recall macro: 0.35945944808539226, F1 macro: 0.4131531248731456 \n",
      "Precision micro: 0.8408993880745695, Recall micro: 0.6905861041313621, F1 micro: 0.7583662206821318 \n",
      "Epoch: [4/10], Step: [1001/2499], Train_loss: 0.04605161285214126\n",
      "Precision macro: 0.579884303797821, Recall macro: 0.4100251720269462, F1 macro: 0.4540438231812835 \n",
      "Precision micro: 0.8266738660907127, Recall micro: 0.7157132004908549, F1 micro: 0.7672022299476964 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [4/10], Step: [2001/2499], Train_loss: 0.04608741063345224\n",
      "Precision macro: 0.6082670338505148, Recall macro: 0.3856325850681252, F1 macro: 0.44072756299404503 \n",
      "Precision micro: 0.8273646161054957, Recall micro: 0.7222579325658856, F1 micro: 0.7712467240733808 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [5/10], Step: [1001/2499], Train_loss: 0.04526675626635551\n",
      "Precision macro: 0.6048731533732071, Recall macro: 0.3913200892844703, F1 macro: 0.454208182679972 \n",
      "Precision micro: 0.84590712592386, Recall micro: 0.7089347279845731, F1 micro: 0.7713876967095852 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n",
      "\n",
      "Epoch: [5/10], Step: [2001/2499], Train_loss: 0.045241340330801905\n",
      "Precision macro: 0.5935961974640986, Recall macro: 0.40162432873399223, F1 macro: 0.45300709048177407 \n",
      "Precision micro: 0.8311810599946193, Recall micro: 0.72214106235026, F1 micro: 0.7728338701103781 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [6/10], Step: [1001/2499], Train_loss: 0.04443852431699634\n",
      "Precision macro: 0.6351501796401967, Recall macro: 0.4022228833570848, F1 macro: 0.46324434824108063 \n",
      "Precision micro: 0.8586662771163538, Recall micro: 0.6869631274469702, F1 micro: 0.7632774964290352 \n",
      "Epoch: [6/10], Step: [2001/2499], Train_loss: 0.04420813321415335\n",
      "Precision macro: 0.63294608095334, Recall macro: 0.4154389094393022, F1 macro: 0.47938124212300726 \n",
      "Precision micro: 0.8390406305204512, Recall micro: 0.7216151463799451, F1 micro: 0.7759102761458956 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [7/10], Step: [1001/2499], Train_loss: 0.04428689499758184\n",
      "Precision macro: 0.6029069795898866, Recall macro: 0.39880245318659147, F1 macro: 0.4551504901317451 \n",
      "Precision micro: 0.8395631232616512, Recall micro: 0.72319289429089, F1 micro: 0.777045269039995 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [7/10], Step: [2001/2499], Train_loss: 0.04404516060743481\n",
      "Precision macro: 0.6159890562407381, Recall macro: 0.4511979984939157, F1 macro: 0.498827988215061 \n",
      "Precision micro: 0.8274049071790212, Recall micro: 0.7448723192894291, F1 micro: 0.7839724468772102 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [8/10], Step: [1001/2499], Train_loss: 0.043910448748618366\n",
      "Precision macro: 0.6043588142475593, Recall macro: 0.4516644268744413, F1 macro: 0.4988388068057864 \n",
      "Precision micro: 0.8257482308641174, Recall micro: 0.7432361362706714, F1 micro: 0.7823225488990037 \n",
      "Epoch: [8/10], Step: [2001/2499], Train_loss: 0.04380735315568745\n",
      "Precision macro: 0.6076440182350644, Recall macro: 0.4313726116583092, F1 macro: 0.48220267226173247 \n",
      "Precision micro: 0.8289473684210527, Recall micro: 0.7436451820253608, F1 micro: 0.7839827506545509 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [9/10], Step: [1001/2499], Train_loss: 0.0434856366161257\n",
      "Precision macro: 0.6536079000168418, Recall macro: 0.43323672871547675, F1 macro: 0.4955960994678596 \n",
      "Precision micro: 0.8483333333333334, Recall micro: 0.7138432770408462, F1 micro: 0.7752990829181607 \n",
      "Epoch: [9/10], Step: [2001/2499], Train_loss: 0.04345204274356365\n",
      "Precision macro: 0.6812999884614985, Recall macro: 0.4263443130677194, F1 macro: 0.4912146498275174 \n",
      "Precision micro: 0.8448323444183801, Recall micro: 0.7155378951674166, F1 micro: 0.7748283608061506 \n",
      "Epoch: [10/10], Step: [1001/2499], Train_loss: 0.04336620434932411\n",
      "Precision macro: 0.6202485662180174, Recall macro: 0.4612019569696361, F1 macro: 0.5044139757851678 \n",
      "Precision micro: 0.8152056449049647, Recall micro: 0.7493718225910126, F1 micro: 0.7809036658141518 \n",
      "Epoch: [10/10], Step: [2001/2499], Train_loss: 0.043136389829218386\n",
      "Precision macro: 0.6047689336072, Recall macro: 0.4342922420149147, F1 macro: 0.48789996365320965 \n",
      "Precision micro: 0.8323850631090184, Recall micro: 0.7437620522409863, F1 micro: 0.785582026910258 \n",
      "Model Saved\n",
      "\n",
      "\n",
      " {'optimizer': 'SWA', 'num_hidden': 2, 'dim_hidden': 40, 'dropout_rate': 0.1, 'learning_rate': 0.001, 'num_epochs': 10}\n",
      "Epoch: [1/10], Step: [1001/2499], Train_loss: 0.1543136665970087\n",
      "Precision macro: 0.07873978402694058, Recall macro: 0.022412099497594984, F1 macro: 0.029287803654170108 \n",
      "Precision micro: 0.7070484581497798, Recall micro: 0.1500613568632034, F1 micro: 0.24757772957339116 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [1/10], Step: [2001/2499], Train_loss: 0.1274257309138775\n",
      "Precision macro: 0.11992564053396042, Recall macro: 0.06300698716656056, F1 macro: 0.0695883739857596 \n",
      "Precision micro: 0.774442538593482, Recall micro: 0.31660141412960907, F1 micro: 0.4494587083661703 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [2/10], Step: [1001/2499], Train_loss: 0.08440421551838517\n",
      "Precision macro: 0.1740016264955585, Recall macro: 0.09274974049950546, F1 macro: 0.10744043136277232 \n",
      "Precision micro: 0.8307377515061953, Recall micro: 0.42704376789575177, F1 micro: 0.5641065225781552 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [2/10], Step: [2001/2499], Train_loss: 0.08278679016046225\n",
      "Precision macro: 0.2209290400194891, Recall macro: 0.10424334076671017, F1 macro: 0.12113901908133719 \n",
      "Precision micro: 0.8289839572192513, Recall micro: 0.4529305206568106, F1 micro: 0.5857990401692931 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [3/10], Step: [1001/2499], Train_loss: 0.0697623304463923\n",
      "Precision macro: 0.2821684501869984, Recall macro: 0.13996744691528507, F1 macro: 0.16410508633551762 \n",
      "Precision micro: 0.829508501347208, Recall micro: 0.5217086425524455, F1 micro: 0.6405510116229014 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [3/10], Step: [2001/2499], Train_loss: 0.07017290194146335\n",
      "Precision macro: 0.26976196785916035, Recall macro: 0.13785838291638472, F1 macro: 0.16128461056963345 \n",
      "Precision micro: 0.8222283406754772, Recall micro: 0.5235201308946416, F1 micro: 0.6397229461958657 \n",
      "Epoch: [4/10], Step: [1001/2499], Train_loss: 0.06279366490617394\n",
      "Precision macro: 0.3296609722996708, Recall macro: 0.17759460367688007, F1 macro: 0.2074400342876865 \n",
      "Precision micro: 0.8227890029811196, Recall micro: 0.5806112312277216, F1 micro: 0.6808044126211928 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [4/10], Step: [2001/2499], Train_loss: 0.06357876140996814\n",
      "Precision macro: 0.34314038133920755, Recall macro: 0.16669531932712844, F1 macro: 0.1951491278231498 \n",
      "Precision micro: 0.8322479812451159, Recall micro: 0.560100508385438, F1 micro: 0.6695773663988822 \n",
      "Epoch: [5/10], Step: [1001/2499], Train_loss: 0.05927113904058933\n",
      "Precision macro: 0.3960876277605781, Recall macro: 0.19708657614057176, F1 macro: 0.2295733648035783 \n",
      "Precision micro: 0.8329511955453652, Recall micro: 0.5944019166715363, F1 micro: 0.6937425404944586 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [5/10], Step: [2001/2499], Train_loss: 0.05942083935067058\n",
      "Precision macro: 0.4037060822164041, Recall macro: 0.2013578234497828, F1 macro: 0.23565972848273795 \n",
      "Precision micro: 0.8368290668868703, Recall micro: 0.5921813825746508, F1 micro: 0.6935632891900215 \n",
      "Epoch: [6/10], Step: [1001/2499], Train_loss: 0.05627416709251702\n",
      "Precision macro: 0.44927714447532935, Recall macro: 0.2209586076795462, F1 macro: 0.26062666077467783 \n",
      "Precision micro: 0.8321760162284466, Recall micro: 0.6232688599310465, F1 micro: 0.7127297026394922 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [6/10], Step: [2001/2499], Train_loss: 0.056354290788061916\n",
      "Precision macro: 0.4279238725657509, Recall macro: 0.2152848254677272, F1 macro: 0.2512771223446603 \n",
      "Precision micro: 0.8347578347578347, Recall micro: 0.6163735172091392, F1 micro: 0.7091330801035329 \n",
      "Epoch: [7/10], Step: [1001/2499], Train_loss: 0.054077619714662434\n",
      "Precision macro: 0.43930287822438435, Recall macro: 0.24238121046349476, F1 macro: 0.28545116343704297 \n",
      "Precision micro: 0.8392285468884204, Recall micro: 0.628060538771694, F1 micro: 0.7184491978609625 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [7/10], Step: [2001/2499], Train_loss: 0.05416973084118217\n",
      "Precision macro: 0.444242224759178, Recall macro: 0.23905104325599594, F1 macro: 0.28014057336377224 \n",
      "Precision micro: 0.8390938813638487, Recall micro: 0.62987202711389, F1 micro: 0.7195834306886078 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [8/10], Step: [1001/2499], Train_loss: 0.05229839073494077\n",
      "Precision macro: 0.5311404955172037, Recall macro: 0.2641846391156694, F1 macro: 0.3178596573629681 \n",
      "Precision micro: 0.8484563548033224, Recall micro: 0.632735347396716, F1 micro: 0.724887029288703 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [8/10], Step: [2001/2499], Train_loss: 0.05237410777248442\n",
      "Precision macro: 0.5011605916065852, Recall macro: 0.26807631892810313, F1 macro: 0.31901825170585607 \n",
      "Precision micro: 0.832463854523774, Recall micro: 0.6527201542686846, F1 micro: 0.7317153057548066 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [9/10], Step: [1001/2499], Train_loss: 0.05081885577365756\n",
      "Precision macro: 0.5426716814941613, Recall macro: 0.2967362458536891, F1 macro: 0.35300888828050336 \n",
      "Precision micro: 0.8382243960278642, Recall micro: 0.6609595044702857, F1 micro: 0.7391119678504917 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [9/10], Step: [2001/2499], Train_loss: 0.05122279134113342\n",
      "Precision macro: 0.5259146067559513, Recall macro: 0.28779054198745196, F1 macro: 0.34313183843695927 \n",
      "Precision micro: 0.8397055509652219, Recall micro: 0.6532460702389996, F1 micro: 0.7348320515348715 \n",
      "Epoch: [10/10], Step: [1001/2499], Train_loss: 0.05032600782066583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision macro: 0.5383566964211329, Recall macro: 0.3095567281430236, F1 macro: 0.36634320053363945 \n",
      "Precision micro: 0.8399765533411488, Recall micro: 0.6699000759656402, F1 micro: 0.7453593836351223 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [10/10], Step: [2001/2499], Train_loss: 0.04996282046381384\n",
      "Precision macro: 0.5387569722860307, Recall macro: 0.3092359896188814, F1 macro: 0.3663281541815256 \n",
      "Precision micro: 0.8417335001103672, Recall micro: 0.6684976333781336, F1 micro: 0.7451797811360082 \n",
      "\n",
      " {'optimizer': 'SWA', 'num_hidden': 2, 'dim_hidden': 40, 'dropout_rate': 0.1, 'learning_rate': 0.01, 'num_epochs': 10}\n",
      "Epoch: [1/10], Step: [1001/2499], Train_loss: 0.09957867152988911\n",
      "Precision macro: 0.26034356474413944, Recall macro: 0.13783823045531732, F1 macro: 0.15619433959436096 \n",
      "Precision micro: 0.803516211679477, Recall micro: 0.5314673055571788, F1 micro: 0.6397720877884074 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [1/10], Step: [2001/2499], Train_loss: 0.08068148791603744\n",
      "Precision macro: 0.4117928284563574, Recall macro: 0.21375226564516694, F1 macro: 0.2501656439452717 \n",
      "Precision micro: 0.8209857165280176, Recall micro: 0.6112896628294279, F1 micro: 0.7007871378328587 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [2/10], Step: [1001/2499], Train_loss: 0.0548566023260355\n",
      "Precision macro: 0.484897143075418, Recall macro: 0.2687355766798349, F1 macro: 0.32054368538507405 \n",
      "Precision micro: 0.8398248444342015, Recall micro: 0.6388125986092444, F1 micro: 0.7256554928642549 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [2/10], Step: [2001/2499], Train_loss: 0.05420206008851528\n",
      "Precision macro: 0.5208344497275573, Recall macro: 0.3021607756086697, F1 macro: 0.35357224916093655 \n",
      "Precision micro: 0.8325253415601587, Recall micro: 0.6623035119499795, F1 micro: 0.7377225241644156 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [3/10], Step: [1001/2499], Train_loss: 0.05031500310637057\n",
      "Precision macro: 0.5202290516015123, Recall macro: 0.3459791676706834, F1 macro: 0.39601537130926034 \n",
      "Precision micro: 0.8344698873017012, Recall micro: 0.6793081283234967, F1 micro: 0.7489369926555857 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [3/10], Step: [2001/2499], Train_loss: 0.0507050557937473\n",
      "Precision macro: 0.5384773550431357, Recall macro: 0.3235006552985538, F1 macro: 0.38115622924310416 \n",
      "Precision micro: 0.8294096341905107, Recall micro: 0.6690819844562613, F1 micro: 0.7406688660327317 \n",
      "Epoch: [4/10], Step: [1001/2499], Train_loss: 0.049439030250534415\n",
      "Precision macro: 0.5349366177400147, Recall macro: 0.357213762484151, F1 macro: 0.408507133405719 \n",
      "Precision micro: 0.8299561311886359, Recall micro: 0.6964880500204523, F1 micro: 0.7573870496282645 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [4/10], Step: [2001/2499], Train_loss: 0.04946242271177471\n",
      "Precision macro: 0.5613449440225118, Recall macro: 0.3397473450606703, F1 macro: 0.3998316908606859 \n",
      "Precision micro: 0.8487724054827535, Recall micro: 0.658563665049962, F1 micro: 0.7416669408706525 \n",
      "Epoch: [5/10], Step: [1001/2499], Train_loss: 0.048613810716196894\n",
      "Precision macro: 0.5413150379903867, Recall macro: 0.3428932178170808, F1 macro: 0.40291224905394485 \n",
      "Precision micro: 0.8363636363636363, Recall micro: 0.6800677847250628, F1 micro: 0.7501611447724634 \n",
      "Epoch: [5/10], Step: [2001/2499], Train_loss: 0.048405039160512385\n",
      "Precision macro: 0.5399984176902067, Recall macro: 0.3777959644649255, F1 macro: 0.4243328238790498 \n",
      "Precision micro: 0.8331259505046316, Recall micro: 0.7042599193595512, F1 micro: 0.763292061179898 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [6/10], Step: [1001/2499], Train_loss: 0.048738058276474476\n",
      "Precision macro: 0.5416812478416285, Recall macro: 0.3912657748171631, F1 macro: 0.43109104960947986 \n",
      "Precision micro: 0.8166168162180126, Recall micro: 0.7179337345877403, F1 micro: 0.7641022451645004 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [6/10], Step: [2001/2499], Train_loss: 0.048263403236865995\n",
      "Precision macro: 0.5507020159424653, Recall macro: 0.3737299990238785, F1 macro: 0.42136922459091886 \n",
      "Precision micro: 0.8263408010862185, Recall micro: 0.7112721322970841, F1 micro: 0.7645008322080206 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [7/10], Step: [1001/2499], Train_loss: 0.04778035932965577\n",
      "Precision macro: 0.5538193317049376, Recall macro: 0.3684508769865008, F1 macro: 0.4248887062906068 \n",
      "Precision micro: 0.8355568038196882, Recall micro: 0.6953777829720096, F1 micro: 0.7590495933662893 \n",
      "Epoch: [7/10], Step: [2001/2499], Train_loss: 0.04774435221869498\n",
      "Precision macro: 0.5682259654476255, Recall macro: 0.39315858505504936, F1 macro: 0.44006424132044997 \n",
      "Precision micro: 0.8291426215993405, Recall micro: 0.7052533161923684, F1 micro: 0.7621964697338092 \n",
      "Epoch: [8/10], Step: [1001/2499], Train_loss: 0.047095496755093336\n",
      "Precision macro: 0.5580010234239572, Recall macro: 0.3644652595112581, F1 macro: 0.417744357646704 \n",
      "Precision micro: 0.8383267382702092, Recall micro: 0.6932741190907498, F1 micro: 0.7589317127778666 \n",
      "Epoch: [8/10], Step: [2001/2499], Train_loss: 0.04729208323545754\n",
      "Precision macro: 0.5594215197586941, Recall macro: 0.3853141735827465, F1 macro: 0.43461099562331024 \n",
      "Precision micro: 0.8332169297387904, Recall micro: 0.6971308362063928, F1 micro: 0.7591231586650123 \n",
      "Epoch: [9/10], Step: [1001/2499], Train_loss: 0.046955787397921084\n",
      "Precision macro: 0.5802577872091731, Recall macro: 0.3990765488783485, F1 macro: 0.4473736206963729 \n",
      "Precision micro: 0.8317185460042603, Recall micro: 0.7072985449658155, F1 micro: 0.7644792521947831 \n",
      "Epoch: [9/10], Step: [2001/2499], Train_loss: 0.04673125382047147\n",
      "Precision macro: 0.5457452041221924, Recall macro: 0.3802003161698579, F1 macro: 0.4314510131774727 \n",
      "Precision micro: 0.8148868572910588, Recall micro: 0.7344124349909426, F1 micro: 0.7725596262601426 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [10/10], Step: [1001/2499], Train_loss: 0.04734851820208132\n",
      "Precision macro: 0.5712099272821981, Recall macro: 0.38615080783278993, F1 macro: 0.4388642506678331 \n",
      "Precision micro: 0.830380264413248, Recall micro: 0.7120317886986501, F1 micro: 0.7666656180199453 \n",
      "Epoch: [10/10], Step: [2001/2499], Train_loss: 0.04709140926785767\n",
      "Precision macro: 0.5695723606982125, Recall macro: 0.37775280782911375, F1 macro: 0.43238598716703164 \n",
      "Precision micro: 0.8358712878109281, Recall micro: 0.7088762928767603, F1 micro: 0.767153607791058 \n",
      "\n",
      " {'optimizer': 'SWA', 'num_hidden': 2, 'dim_hidden': 40, 'dropout_rate': 0.2, 'learning_rate': 0.001, 'num_epochs': 10}\n",
      "Epoch: [1/10], Step: [1001/2499], Train_loss: 0.1601890443339944\n",
      "Precision macro: 0.079878204819301, Recall macro: 0.018035008925780274, F1 macro: 0.0249703209912558 \n",
      "Precision micro: 0.7213967310549777, Recall micro: 0.11348097937240695, F1 micro: 0.19611209290583187 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [1/10], Step: [2001/2499], Train_loss: 0.12975438045710325\n",
      "Precision macro: 0.1382998194204354, Recall macro: 0.06494106291449873, F1 macro: 0.07625727312499904 \n",
      "Precision micro: 0.7783799619159221, Recall micro: 0.31052416291708057, F1 micro: 0.4439431913116123 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [2/10], Step: [1001/2499], Train_loss: 0.08445154750719666\n",
      "Precision macro: 0.17628933353669313, Recall macro: 0.0914871258946687, F1 macro: 0.10563369247911719 \n",
      "Precision micro: 0.8149760071420601, Recall micro: 0.4267515923566879, F1 micro: 0.560174886860474 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [2/10], Step: [2001/2499], Train_loss: 0.08307950935140253\n",
      "Precision macro: 0.1944187608310792, Recall macro: 0.0987894746139219, F1 macro: 0.11219941143676987 \n",
      "Precision micro: 0.8047931175747645, Recall micro: 0.4591830771927774, F1 micro: 0.584737879971723 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [3/10], Step: [1001/2499], Train_loss: 0.07104580423235893\n",
      "Precision macro: 0.26703599739809847, Recall macro: 0.1444269689085322, F1 macro: 0.16926647814276885 \n",
      "Precision micro: 0.818698160836639, Recall micro: 0.5306492140478, F1 micro: 0.6439283814926432 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [3/10], Step: [2001/2499], Train_loss: 0.0710916672963649\n",
      "Precision macro: 0.27117217411379047, Recall macro: 0.1311342046046797, F1 macro: 0.15344218533730591 \n",
      "Precision micro: 0.81597285897671, Recall micro: 0.5200140244258751, F1 micro: 0.6352118205503409 \n",
      "Epoch: [4/10], Step: [1001/2499], Train_loss: 0.06342060431838036\n",
      "Precision macro: 0.37123173405614146, Recall macro: 0.18112622231608963, F1 macro: 0.21155837039398276 \n",
      "Precision micro: 0.8214787277984305, Recall micro: 0.5810787120902238, F1 micro: 0.6806762954343213 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [4/10], Step: [2001/2499], Train_loss: 0.06419248619303107\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision macro: 0.3587469613088194, Recall macro: 0.17181313160027176, F1 macro: 0.20207192032294996 \n",
      "Precision micro: 0.8318999218139171, Recall micro: 0.559574592415123, F1 micro: 0.6690888764673001 \n",
      "Epoch: [5/10], Step: [1001/2499], Train_loss: 0.05985771159827709\n",
      "Precision macro: 0.4086369437389045, Recall macro: 0.20218833925281496, F1 macro: 0.24002676833976244 \n",
      "Precision micro: 0.8370883882149047, Recall micro: 0.5927072985449658, F1 micro: 0.6940130003421143 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [5/10], Step: [2001/2499], Train_loss: 0.05995417389832437\n",
      "Precision macro: 0.4164411991128871, Recall macro: 0.20027846281074657, F1 macro: 0.23667165367735252 \n",
      "Precision micro: 0.8303955811875559, Recall micro: 0.5973821071699877, F1 micro: 0.6948749320282762 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [6/10], Step: [1001/2499], Train_loss: 0.056579754617065194\n",
      "Precision macro: 0.4441704263370419, Recall macro: 0.23129980080294568, F1 macro: 0.27352593707734896 \n",
      "Precision micro: 0.8337280909521554, Recall micro: 0.6170747385028925, F1 micro: 0.7092246213774808 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [6/10], Step: [2001/2499], Train_loss: 0.05707814578153193\n",
      "Precision macro: 0.43289851000706103, Recall macro: 0.22666321287495209, F1 macro: 0.2665254940246513 \n",
      "Precision micro: 0.8340216010165185, Recall micro: 0.6136855022497516, F1 micro: 0.7070863490994781 \n",
      "Epoch: [7/10], Step: [1001/2499], Train_loss: 0.054914245486259464\n",
      "Precision macro: 0.4642273260225632, Recall macro: 0.2536030550848919, F1 macro: 0.2985824766794774 \n",
      "Precision micro: 0.8283127947664689, Recall micro: 0.6362998889732951, F1 micro: 0.7197197528008196 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [7/10], Step: [2001/2499], Train_loss: 0.05500435060728341\n",
      "Precision macro: 0.46378000076869424, Recall macro: 0.24596420424052837, F1 macro: 0.28909578339159087 \n",
      "Precision micro: 0.8260180995475113, Recall micro: 0.6400397358733126, F1 micro: 0.7212326737562967 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [8/10], Step: [1001/2499], Train_loss: 0.05320788702368736\n",
      "Precision macro: 0.5551183342274607, Recall macro: 0.2776765152498573, F1 macro: 0.3297748163125295 \n",
      "Precision micro: 0.8351383874849578, Recall micro: 0.6488634371530415, F1 micro: 0.7303101055608537 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [8/10], Step: [2001/2499], Train_loss: 0.053355818277224895\n",
      "Precision macro: 0.5304424234428354, Recall macro: 0.2659490606673385, F1 macro: 0.3152460257993522 \n",
      "Precision micro: 0.8318383960202005, Recall micro: 0.6448898498217729, F1 micro: 0.7265306122448979 \n",
      "Epoch: [9/10], Step: [1001/2499], Train_loss: 0.05196680118702352\n",
      "Precision macro: 0.5267427501670435, Recall macro: 0.2900047052391679, F1 macro: 0.34409171031733554 \n",
      "Precision micro: 0.8319457746997716, Recall micro: 0.6598492374218431, F1 micro: 0.7359708010167505 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [9/10], Step: [2001/2499], Train_loss: 0.051967228437773884\n",
      "Precision macro: 0.5733372994507374, Recall macro: 0.305319416480611, F1 macro: 0.3587079915249807 \n",
      "Precision micro: 0.8316672747172564, Recall micro: 0.6660433588499971, F1 micro: 0.7396975793367514 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [10/10], Step: [1001/2499], Train_loss: 0.050322621768340466\n",
      "Precision macro: 0.5751205341843278, Recall macro: 0.30936401952597287, F1 macro: 0.3658585078304188 \n",
      "Precision micro: 0.8412733914858719, Recall micro: 0.6593817565593408, F1 micro: 0.7393041996986177 \n",
      "Epoch: [10/10], Step: [2001/2499], Train_loss: 0.05000723831728101\n",
      "Precision macro: 0.5795526365009849, Recall macro: 0.31304221257792325, F1 macro: 0.3715871926231586 \n",
      "Precision micro: 0.8421169339936433, Recall micro: 0.6657511833109332, F1 micro: 0.7436198681548201 \n",
      "Model Saved\n",
      "\n",
      "\n",
      " {'optimizer': 'SWA', 'num_hidden': 2, 'dim_hidden': 40, 'dropout_rate': 0.2, 'learning_rate': 0.01, 'num_epochs': 10}\n",
      "Epoch: [1/10], Step: [1001/2499], Train_loss: 0.08970451453700662\n",
      "Precision macro: 0.40795074591494346, Recall macro: 0.16973097750701463, F1 macro: 0.20276053636837113 \n",
      "Precision micro: 0.8153089302092887, Recall micro: 0.5713784841933033, F1 micro: 0.6718889576032433 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [1/10], Step: [2001/2499], Train_loss: 0.07284524124115706\n",
      "Precision macro: 0.49715986405644935, Recall macro: 0.29501534572250193, F1 macro: 0.3462256664361048 \n",
      "Precision micro: 0.8394912174439734, Recall micro: 0.6479284754280371, F1 micro: 0.7313742950430394 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [2/10], Step: [1001/2499], Train_loss: 0.049397339314222334\n",
      "Precision macro: 0.5491551934104962, Recall macro: 0.3687741493672153, F1 macro: 0.4174258355130808 \n",
      "Precision micro: 0.8323353293413174, Recall micro: 0.6985332787938994, F1 micro: 0.7595869737887212 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [2/10], Step: [2001/2499], Train_loss: 0.04915714890602976\n",
      "Precision macro: 0.5820023294220027, Recall macro: 0.3763451569636283, F1 macro: 0.42670471634667817 \n",
      "Precision micro: 0.8437365166115346, Recall micro: 0.6856191199672763, F1 micro: 0.7565040781456527 \n",
      "Epoch: [3/10], Step: [1001/2499], Train_loss: 0.04566768151521683\n",
      "Precision macro: 0.5914102281672637, Recall macro: 0.4093615357229112, F1 macro: 0.4532240685763021 \n",
      "Precision micro: 0.8350041197473221, Recall micro: 0.7106293461111436, F1 micro: 0.7678126085172208 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [3/10], Step: [2001/2499], Train_loss: 0.045833344412036243\n",
      "Precision macro: 0.5578775942913944, Recall macro: 0.39857077882875, F1 macro: 0.44210817966894383 \n",
      "Precision micro: 0.8271604938271605, Recall micro: 0.7203880091158769, F1 micro: 0.7700908892151045 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [4/10], Step: [1001/2499], Train_loss: 0.04430154406093061\n",
      "Precision macro: 0.618202029157413, Recall macro: 0.40890397610441165, F1 macro: 0.46580101201797747 \n",
      "Precision micro: 0.8361358611911301, Recall micro: 0.7293285806112312, F1 micro: 0.7790886392009988 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [4/10], Step: [2001/2499], Train_loss: 0.044579566802829505\n",
      "Precision macro: 0.6209077005990143, Recall macro: 0.41404112300851303, F1 macro: 0.465277154044972 \n",
      "Precision micro: 0.8305546330122883, Recall micro: 0.7306725880909251, F1 micro: 0.7774185525988562 \n",
      "Epoch: [5/10], Step: [1001/2499], Train_loss: 0.0440376179330051\n",
      "Precision macro: 0.6280695290912629, Recall macro: 0.4081085107659673, F1 macro: 0.46583703148711264 \n",
      "Precision micro: 0.8544317603431979, Recall micro: 0.6866709519079063, F1 micro: 0.7614203330525496 \n",
      "Epoch: [5/10], Step: [2001/2499], Train_loss: 0.043812496502883734\n",
      "Precision macro: 0.6295603415546036, Recall macro: 0.44329307086050085, F1 macro: 0.49277292767946934 \n",
      "Precision micro: 0.8383353341336535, Recall micro: 0.7345293052065681, F1 micro: 0.7830068209424735 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [6/10], Step: [1001/2499], Train_loss: 0.043177524177357554\n",
      "Precision macro: 0.6190408604447831, Recall macro: 0.40858967509799965, F1 macro: 0.4729347945640335 \n",
      "Precision micro: 0.8463912464052746, Recall micro: 0.7051364459767429, F1 micro: 0.7693337583678673 \n",
      "Epoch: [6/10], Step: [2001/2499], Train_loss: 0.0432943974006921\n",
      "Precision macro: 0.6086323293521286, Recall macro: 0.40039136573601636, F1 macro: 0.4569129763163458 \n",
      "Precision micro: 0.831145584725537, Recall micro: 0.7326009466487465, F1 micro: 0.778768208218157 \n",
      "Epoch: [7/10], Step: [1001/2499], Train_loss: 0.04229578511044383\n",
      "Precision macro: 0.6537517747619307, Recall macro: 0.421927711634431, F1 macro: 0.48367945888298575 \n",
      "Precision micro: 0.8482457961386756, Recall micro: 0.7162975515689827, F1 micro: 0.7767076416170321 \n",
      "Epoch: [7/10], Step: [2001/2499], Train_loss: 0.04258132182061672\n",
      "Precision macro: 0.6654179046098732, Recall macro: 0.44838647997703374, F1 macro: 0.5054506067827484 \n",
      "Precision micro: 0.8426258383578349, Recall micro: 0.726815870975282, F1 micro: 0.7804480140553429 \n",
      "Epoch: [8/10], Step: [1001/2499], Train_loss: 0.04207070130482316\n",
      "Precision macro: 0.6643610040021094, Recall macro: 0.4816476665408306, F1 macro: 0.5374742107834695 \n",
      "Precision micro: 0.8414082257420471, Recall micro: 0.7387950680769007, F1 micro: 0.7867699679517097 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [8/10], Step: [2001/2499], Train_loss: 0.042140891888178884\n",
      "Precision macro: 0.6107307670161867, Recall macro: 0.431733117331873, F1 macro: 0.4844358749520383 \n",
      "Precision micro: 0.8432096234023648, Recall micro: 0.7209139250861918, F1 micro: 0.7772807459677419 \n",
      "Epoch: [9/10], Step: [1001/2499], Train_loss: 0.04229303826391697\n",
      "Precision macro: 0.6620405513317356, Recall macro: 0.4723511647937933, F1 macro: 0.5221364641430198 \n",
      "Precision micro: 0.8205980066445183, Recall micro: 0.7649739963770233, F1 micro: 0.7918103187564266 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n",
      "\n",
      "Epoch: [9/10], Step: [2001/2499], Train_loss: 0.0419212734894827\n",
      "Precision macro: 0.6420684272835433, Recall macro: 0.46890087997055657, F1 macro: 0.516845698949471 \n",
      "Precision micro: 0.8253856493631185, Recall micro: 0.7535207152457196, F1 micro: 0.7878176930596286 \n",
      "Epoch: [10/10], Step: [1001/2499], Train_loss: 0.041473331943154335\n",
      "Precision macro: 0.64841616267524, Recall macro: 0.4728196700507425, F1 macro: 0.5288279309651372 \n",
      "Precision micro: 0.8232939263151311, Recall micro: 0.7691228890317303, F1 micro: 0.7952870090634442 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [10/10], Step: [2001/2499], Train_loss: 0.041732057453133166\n",
      "Precision macro: 0.6563796483158757, Recall macro: 0.4731986137201607, F1 macro: 0.5275840622652775 \n",
      "Precision micro: 0.8366339890782288, Recall micro: 0.7430608309472331, F1 micro: 0.7870760089130973 \n",
      "\n",
      " {'optimizer': 'SWA', 'num_hidden': 2, 'dim_hidden': 80, 'dropout_rate': 0, 'learning_rate': 0.001, 'num_epochs': 10}\n",
      "Epoch: [1/10], Step: [1001/2499], Train_loss: 0.147076711602509\n",
      "Precision macro: 0.0974663252626824, Recall macro: 0.03552319932110236, F1 macro: 0.04665568394134625 \n",
      "Precision micro: 0.7513304305757136, Recall micro: 0.1814994448664758, F1 micro: 0.2923706876264885 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [1/10], Step: [2001/2499], Train_loss: 0.12005073995143176\n",
      "Precision macro: 0.13714965784354383, Recall macro: 0.07880608377414, F1 macro: 0.09056037820589134 \n",
      "Precision micro: 0.8216236818701562, Recall micro: 0.3778998422252089, F1 micro: 0.5176913224463657 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [2/10], Step: [1001/2499], Train_loss: 0.07604315251857043\n",
      "Precision macro: 0.2567473064988721, Recall macro: 0.11807101310945778, F1 macro: 0.1328612790964514 \n",
      "Precision micro: 0.8078500839082603, Recall micro: 0.506340209197686, F1 micro: 0.622507992384784 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [2/10], Step: [2001/2499], Train_loss: 0.07477229780331254\n",
      "Precision macro: 0.2806501264686825, Recall macro: 0.12980455599835333, F1 macro: 0.15110493209599982 \n",
      "Precision micro: 0.8187406855439643, Recall micro: 0.5136445976742827, F1 micro: 0.6312614456533449 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [3/10], Step: [1001/2499], Train_loss: 0.06365343006327748\n",
      "Precision macro: 0.3529514407377423, Recall macro: 0.17644116333806095, F1 macro: 0.2083455282637915 \n",
      "Precision micro: 0.8250042208340368, Recall micro: 0.5710863086542395, F1 micro: 0.6749542456576539 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [3/10], Step: [2001/2499], Train_loss: 0.06403126556240023\n",
      "Precision macro: 0.35500687844944584, Recall macro: 0.17245864935199015, F1 macro: 0.2042439580435174 \n",
      "Precision micro: 0.8190547762191048, Recall micro: 0.5731899725354993, F1 micro: 0.6744130083536732 \n",
      "Epoch: [4/10], Step: [1001/2499], Train_loss: 0.05816409881599247\n",
      "Precision macro: 0.4170870265187507, Recall macro: 0.2192273775100617, F1 macro: 0.26074580373795747 \n",
      "Precision micro: 0.8324711500198966, Recall micro: 0.6112312277216152, F1 micro: 0.7048992519711571 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [4/10], Step: [2001/2499], Train_loss: 0.05822088888380676\n",
      "Precision macro: 0.4169337188103226, Recall macro: 0.20958434766615178, F1 macro: 0.2473213413731351 \n",
      "Precision micro: 0.829160648371048, Recall micro: 0.6038099690293929, F1 micro: 0.6987658495350804 \n",
      "Epoch: [5/10], Step: [1001/2499], Train_loss: 0.053881946165114644\n",
      "Precision macro: 0.5042734310381686, Recall macro: 0.24317720925415917, F1 macro: 0.287526608880002 \n",
      "Precision micro: 0.8333588253288468, Recall micro: 0.6367673698357973, F1 micro: 0.7219185796150916 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [5/10], Step: [2001/2499], Train_loss: 0.05445183142926544\n",
      "Precision macro: 0.48258859677502, Recall macro: 0.24856715531695175, F1 macro: 0.2927944648868994 \n",
      "Precision micro: 0.8344513840697046, Recall micro: 0.6323847367498393, F1 micro: 0.7195000332424706 \n",
      "Epoch: [6/10], Step: [1001/2499], Train_loss: 0.051692872336134316\n",
      "Precision macro: 0.5394280638325711, Recall macro: 0.2758699245749963, F1 macro: 0.3305703303031274 \n",
      "Precision micro: 0.8329029878273699, Recall micro: 0.6597323672062175, F1 micro: 0.7362723359853921 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [6/10], Step: [2001/2499], Train_loss: 0.0520254907598719\n",
      "Precision macro: 0.5173601874658327, Recall macro: 0.2749833608735152, F1 macro: 0.32472847654442066 \n",
      "Precision micro: 0.8338914936369726, Recall micro: 0.6547653830421317, F1 micro: 0.7335515548281507 \n",
      "Epoch: [7/10], Step: [1001/2499], Train_loss: 0.04999730470217764\n",
      "Precision macro: 0.5111890982351401, Recall macro: 0.3146932186466147, F1 macro: 0.37163455265816925 \n",
      "Precision micro: 0.8350131463628396, Recall micro: 0.6680885876234441, F1 micro: 0.7422820970621653 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [7/10], Step: [2001/2499], Train_loss: 0.0501252435464412\n",
      "Precision macro: 0.5216055917677006, Recall macro: 0.3110741929897784, F1 macro: 0.3668941820770039 \n",
      "Precision micro: 0.8289615522817104, Recall micro: 0.6740489686203471, F1 micro: 0.7435219801469639 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [8/10], Step: [1001/2499], Train_loss: 0.048499945571646094\n",
      "Precision macro: 0.5343259613693561, Recall macro: 0.3320608403348454, F1 macro: 0.39097445320203617 \n",
      "Precision micro: 0.8461538461538461, Recall micro: 0.6736399228656577, F1 micro: 0.7501057357582067 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [8/10], Step: [2001/2499], Train_loss: 0.04883866112492979\n",
      "Precision macro: 0.5353661072534689, Recall macro: 0.329246951028721, F1 macro: 0.385917147511712 \n",
      "Precision micro: 0.8375081209846242, Recall micro: 0.677964120843803, F1 micro: 0.7493379835949106 \n",
      "Epoch: [9/10], Step: [1001/2499], Train_loss: 0.047842896645888686\n",
      "Precision macro: 0.5336668121073962, Recall macro: 0.34668393218923027, F1 macro: 0.40337424743059636 \n",
      "Precision micro: 0.838631503920171, Recall micro: 0.6875474785250979, F1 micro: 0.7556112127926019 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [9/10], Step: [2001/2499], Train_loss: 0.047693092509172856\n",
      "Precision macro: 0.5319602820422071, Recall macro: 0.3435371857459766, F1 macro: 0.3984172416897085 \n",
      "Precision micro: 0.8410672021803055, Recall micro: 0.6852685093203997, F1 micro: 0.7552163833075733 \n",
      "Epoch: [10/10], Step: [1001/2499], Train_loss: 0.046485960511490704\n",
      "Precision macro: 0.5646363543783617, Recall macro: 0.3600706005719068, F1 macro: 0.4149341831975042 \n",
      "Precision micro: 0.8461483390607102, Recall micro: 0.6906445392391749, F1 micro: 0.7605289405102796 \n",
      "Model Saved\n",
      "\n",
      "Model Saved\n",
      "\n",
      "\n",
      " {'optimizer': 'SWA', 'num_hidden': 2, 'dim_hidden': 80, 'dropout_rate': 0, 'learning_rate': 0.01, 'num_epochs': 10}\n",
      "Epoch: [1/10], Step: [1001/2499], Train_loss: 0.079350580945611\n",
      "Precision macro: 0.4226084046666219, Recall macro: 0.24399764514866729, F1 macro: 0.277265677883945 \n",
      "Precision micro: 0.793319118692253, Recall micro: 0.6522526734061824, F1 micro: 0.7159028958086138 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [1/10], Step: [2001/2499], Train_loss: 0.06569280884042382\n",
      "Precision macro: 0.5638557598520547, Recall macro: 0.3505306694129758, F1 macro: 0.4043647763696297 \n",
      "Precision micro: 0.8475282004693769, Recall micro: 0.654181031964004, F1 micro: 0.7384077567442782 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [2/10], Step: [1001/2499], Train_loss: 0.047144574902951715\n",
      "Precision macro: 0.584083190998387, Recall macro: 0.40239412250501394, F1 macro: 0.45078083508194505 \n",
      "Precision micro: 0.8288081924139324, Recall micro: 0.7188686963127447, F1 micro: 0.7699336587808236 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [2/10], Step: [2001/2499], Train_loss: 0.04644301577284932\n",
      "Precision macro: 0.604138378702994, Recall macro: 0.39391767938603617, F1 macro: 0.4475338839864991 \n",
      "Precision micro: 0.835663851585214, Recall micro: 0.7054286215158067, F1 micro: 0.7650432523210495 \n",
      "Epoch: [3/10], Step: [1001/2499], Train_loss: 0.04353164249844849\n",
      "Precision macro: 0.6401879871003449, Recall macro: 0.4418895952776163, F1 macro: 0.4970346207055849 \n",
      "Precision micro: 0.82591674279003, Recall micro: 0.7396715946940922, F1 micro: 0.7804186318937082 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [3/10], Step: [2001/2499], Train_loss: 0.04360666721034795\n",
      "Precision macro: 0.6424758797469253, Recall macro: 0.4481166776457972, F1 macro: 0.49527369439986496 \n",
      "Precision micro: 0.8418661422662237, Recall micro: 0.7254718634955881, F1 micro: 0.7793471437539234 \n",
      "Epoch: [4/10], Step: [1001/2499], Train_loss: 0.042212154004722835\n",
      "Precision macro: 0.6477255755619811, Recall macro: 0.45433519539720213, F1 macro: 0.5147810033565264 \n",
      "Precision micro: 0.835609278013721, Recall micro: 0.7473265938175656, F1 micro: 0.7890061077179343 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n",
      "\n",
      "Epoch: [4/10], Step: [2001/2499], Train_loss: 0.04206683901138604\n",
      "Precision macro: 0.6361788981719751, Recall macro: 0.47578629825211044, F1 macro: 0.5233490115479097 \n",
      "Precision micro: 0.8417789038538471, Recall micro: 0.7377432361362707, F1 micro: 0.7863349008128055 \n",
      "Epoch: [5/10], Step: [1001/2499], Train_loss: 0.040664397651329634\n",
      "Precision macro: 0.6917799094831893, Recall macro: 0.4874054682349925, F1 macro: 0.543914854331587 \n",
      "Precision micro: 0.8298335467349552, Recall micro: 0.7574358674691755, F1 micro: 0.7919836250878319 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [5/10], Step: [2001/2499], Train_loss: 0.040856748732738195\n",
      "Precision macro: 0.6444962768339741, Recall macro: 0.4894134532041894, F1 macro: 0.5344626112903257 \n",
      "Precision micro: 0.8191717134642442, Recall micro: 0.7825045287208555, F1 micro: 0.8004184100418409 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [6/10], Step: [1001/2499], Train_loss: 0.04039205405302346\n",
      "Precision macro: 0.6747897653006243, Recall macro: 0.5028756609868804, F1 macro: 0.5544831194445125 \n",
      "Precision micro: 0.8396992683090555, Recall micro: 0.7309647636299889, F1 micro: 0.7815682599187753 \n",
      "Epoch: [6/10], Step: [2001/2499], Train_loss: 0.040036214818246665\n",
      "Precision macro: 0.7062938940188612, Recall macro: 0.5135970485406024, F1 macro: 0.5632485891074779 \n",
      "Precision micro: 0.8276727980413083, Recall micro: 0.7704084614036113, F1 micro: 0.7980146480237275 \n",
      "Epoch: [7/10], Step: [1001/2499], Train_loss: 0.039169249903410676\n",
      "Precision macro: 0.7084277583025509, Recall macro: 0.4680476086952576, F1 macro: 0.5283847835777581 \n",
      "Precision micro: 0.8279853385634365, Recall micro: 0.7524104481972769, F1 micro: 0.7883908890521676 \n",
      "Epoch: [7/10], Step: [2001/2499], Train_loss: 0.03932117270398885\n",
      "Precision macro: 0.7005677923880556, Recall macro: 0.5030543898278771, F1 macro: 0.5638489597857794 \n",
      "Precision micro: 0.8454829471491799, Recall micro: 0.7590720504879331, F1 micro: 0.7999507343658588 \n",
      "Epoch: [8/10], Step: [1001/2499], Train_loss: 0.038573797811754046\n",
      "Precision macro: 0.7065179233813768, Recall macro: 0.5454290195990956, F1 macro: 0.5961918750031134 \n",
      "Precision micro: 0.8402539353501328, Recall micro: 0.7579617834394905, F1 micro: 0.7969892473118281 \n",
      "Epoch: [8/10], Step: [2001/2499], Train_loss: 0.03855755697609857\n",
      "Precision macro: 0.7204649794233495, Recall macro: 0.5317846694244269, F1 macro: 0.589264098609377 \n",
      "Precision micro: 0.8411220994118027, Recall micro: 0.7604160579676269, F1 micro: 0.7987355757426958 \n",
      "Epoch: [9/10], Step: [1001/2499], Train_loss: 0.0381235387083143\n",
      "Precision macro: 0.7161393209915781, Recall macro: 0.5347356387903538, F1 macro: 0.5894057097124242 \n",
      "Precision micro: 0.8267979929381156, Recall micro: 0.7799333839770934, F1 micro: 0.8026822227567958 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [9/10], Step: [2001/2499], Train_loss: 0.038826033042743804\n",
      "Precision macro: 0.683761517789415, Recall macro: 0.4911948190668685, F1 macro: 0.5529228341318516 \n",
      "Precision micro: 0.8276542895356984, Recall micro: 0.759364226026997, F1 micro: 0.7920399829341135 \n",
      "Epoch: [10/10], Step: [1001/2499], Train_loss: 0.039374421179294586\n",
      "Precision macro: 0.7228440453720427, Recall macro: 0.5211813581257366, F1 macro: 0.56928272424987 \n",
      "Precision micro: 0.836074908262685, Recall micro: 0.7722199497458073, F1 micro: 0.8028797958625717 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [10/10], Step: [2001/2499], Train_loss: 0.0389233226981014\n",
      "Precision macro: 0.6951650927169993, Recall macro: 0.5073908659073392, F1 macro: 0.5646819602245512 \n",
      "Precision micro: 0.8448612739351309, Recall micro: 0.7580202185473032, F1 micro: 0.7990883050482028 \n",
      "\n",
      " {'optimizer': 'SWA', 'num_hidden': 2, 'dim_hidden': 80, 'dropout_rate': 0.1, 'learning_rate': 0.001, 'num_epochs': 10}\n",
      "Epoch: [1/10], Step: [1001/2499], Train_loss: 0.14373438358306884\n",
      "Precision macro: 0.11305309501320955, Recall macro: 0.051343192201863605, F1 macro: 0.06447771222965122 \n",
      "Precision micro: 0.8078875439281531, Recall micro: 0.24180447612925846, F1 micro: 0.37220598156060264 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [1/10], Step: [2001/2499], Train_loss: 0.11493386144004762\n",
      "Precision macro: 0.14548895700735293, Recall macro: 0.0991789579903342, F1 macro: 0.11296162993409639 \n",
      "Precision micro: 0.8203592814371258, Recall micro: 0.4483141471396015, F1 micro: 0.5797846211978085 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [2/10], Step: [1001/2499], Train_loss: 0.0726863650791347\n",
      "Precision macro: 0.26861759355567116, Recall macro: 0.13405550980719003, F1 macro: 0.1565029490307268 \n",
      "Precision micro: 0.8337164750957854, Recall micro: 0.5086191784023841, F1 micro: 0.6318005298878524 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [2/10], Step: [2001/2499], Train_loss: 0.07118178489245475\n",
      "Precision macro: 0.31736842751274447, Recall macro: 0.14092252606413946, F1 macro: 0.1685100175176827 \n",
      "Precision micro: 0.8452564596991902, Recall micro: 0.512300590194589, F1 micro: 0.6379479716208841 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [3/10], Step: [1001/2499], Train_loss: 0.06161099637299776\n",
      "Precision macro: 0.40134950753463, Recall macro: 0.1831030422183454, F1 macro: 0.21876396848445223 \n",
      "Precision micro: 0.8411654135338346, Recall micro: 0.5752936364167592, F1 micro: 0.6832772321893328 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [3/10], Step: [2001/2499], Train_loss: 0.061705354871228336\n",
      "Precision macro: 0.41737491567081314, Recall macro: 0.18790714148143223, F1 macro: 0.2233451730264031 \n",
      "Precision micro: 0.8392061222773526, Recall micro: 0.5831239408636709, F1 micro: 0.6881119845538546 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [4/10], Step: [1001/2499], Train_loss: 0.05622987750917673\n",
      "Precision macro: 0.4668896267765335, Recall macro: 0.23171885923358906, F1 macro: 0.2737982832957373 \n",
      "Precision micro: 0.8355485646873771, Recall micro: 0.62081458540291, F1 micro: 0.7123508113182244 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [4/10], Step: [2001/2499], Train_loss: 0.05651357102207839\n",
      "Precision macro: 0.42309947397518427, Recall macro: 0.2183843261687354, F1 macro: 0.2588535936289819 \n",
      "Precision micro: 0.842203321182665, Recall micro: 0.6075498159294104, F1 micro: 0.7058863466630457 \n",
      "Epoch: [5/10], Step: [1001/2499], Train_loss: 0.053192180449143055\n",
      "Precision macro: 0.5055411725779528, Recall macro: 0.25755049366914384, F1 macro: 0.3067715193559356 \n",
      "Precision micro: 0.8460392156862745, Recall micro: 0.6303395079763923, F1 micro: 0.7224324414827714 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [5/10], Step: [2001/2499], Train_loss: 0.05312666269484907\n",
      "Precision macro: 0.5080112965547732, Recall macro: 0.2625665279122428, F1 macro: 0.3126593728511436 \n",
      "Precision micro: 0.8369614512471655, Recall micro: 0.6470519488108456, F1 micro: 0.7298553208318228 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [6/10], Step: [1001/2499], Train_loss: 0.050296867879107594\n",
      "Precision macro: 0.5334631606333416, Recall macro: 0.31534404618492795, F1 macro: 0.37038538752709993 \n",
      "Precision micro: 0.8428539675483441, Recall micro: 0.664757786478116, F1 micro: 0.7432865076772297 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [6/10], Step: [2001/2499], Train_loss: 0.05063278644066304\n",
      "Precision macro: 0.5435406819702472, Recall macro: 0.300990891223057, F1 macro: 0.3565617849110905 \n",
      "Precision micro: 0.8413536630717738, Recall micro: 0.6610179395780985, F1 micro: 0.7403625891746842 \n",
      "Epoch: [7/10], Step: [1001/2499], Train_loss: 0.04917752498574555\n",
      "Precision macro: 0.5271540820365451, Recall macro: 0.34154732560490436, F1 macro: 0.3935968919998679 \n",
      "Precision micro: 0.832579185520362, Recall micro: 0.6881318296032256, F1 micro: 0.753495217071376 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [7/10], Step: [2001/2499], Train_loss: 0.048884881120175125\n",
      "Precision macro: 0.5629094098715252, Recall macro: 0.34147835703193324, F1 macro: 0.3976726287599043 \n",
      "Precision micro: 0.8366175219733485, Recall micro: 0.6897095775141705, F1 micro: 0.7560936549117582 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [8/10], Step: [1001/2499], Train_loss: 0.04698168520256877\n",
      "Precision macro: 0.5770592063787384, Recall macro: 0.3613972161638459, F1 macro: 0.41505827724562305 \n",
      "Precision micro: 0.8396186440677966, Recall micro: 0.6947349967860691, F1 micro: 0.7603363924151824 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [8/10], Step: [2001/2499], Train_loss: 0.04744793847948313\n",
      "Precision macro: 0.5808545494960542, Recall macro: 0.3555529801237711, F1 macro: 0.41209202494720515 \n",
      "Precision micro: 0.8411447237608294, Recall micro: 0.692163852042307, F1 micro: 0.759416573168777 \n",
      "Epoch: [9/10], Step: [1001/2499], Train_loss: 0.045893013970926405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision macro: 0.5570126226515768, Recall macro: 0.3679056903056623, F1 macro: 0.42217098329046476 \n",
      "Precision micro: 0.8411992945326279, Recall micro: 0.6967802255595161, F1 micro: 0.7622091536691383 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [9/10], Step: [2001/2499], Train_loss: 0.04626221817731857\n",
      "Precision macro: 0.5993456693311546, Recall macro: 0.37624498620813307, F1 macro: 0.43081878394296974 \n",
      "Precision micro: 0.840849926123971, Recall micro: 0.698357973470461, F1 micro: 0.7630083636595799 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [10/10], Step: [1001/2499], Train_loss: 0.0450018363147974\n",
      "Precision macro: 0.5823232653311243, Recall macro: 0.3881703382237813, F1 macro: 0.4399912284297571 \n",
      "Precision micro: 0.8373939228031755, Recall micro: 0.7150119791971016, F1 micro: 0.7713790386130812 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [10/10], Step: [2001/2499], Train_loss: 0.045324886388145386\n",
      "Precision macro: 0.5968843683455428, Recall macro: 0.3804581802030391, F1 macro: 0.4371502675214689 \n",
      "Precision micro: 0.8417236089806164, Recall micro: 0.7054286215158067, F1 micro: 0.7675727229375298 \n",
      "\n",
      " {'optimizer': 'SWA', 'num_hidden': 2, 'dim_hidden': 80, 'dropout_rate': 0.1, 'learning_rate': 0.01, 'num_epochs': 10}\n",
      "Epoch: [1/10], Step: [1001/2499], Train_loss: 0.0816636622659862\n",
      "Precision macro: 0.43760237916609895, Recall macro: 0.22729922159011665, F1 macro: 0.2635661236538977 \n",
      "Precision micro: 0.8243253632659338, Recall micro: 0.6265412259685619, F1 micro: 0.7119521912350598 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [1/10], Step: [2001/2499], Train_loss: 0.06665435222908854\n",
      "Precision macro: 0.53299903268137, Recall macro: 0.3504861213631174, F1 macro: 0.40226288465127297 \n",
      "Precision micro: 0.8370524130773223, Recall micro: 0.6597908023140303, F1 micro: 0.7379256257760931 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [2/10], Step: [1001/2499], Train_loss: 0.0467045652680099\n",
      "Precision macro: 0.5850192927183638, Recall macro: 0.42229521652994056, F1 macro: 0.4669765415761438 \n",
      "Precision micro: 0.8222641763872969, Recall micro: 0.7126161397767778, F1 micro: 0.7635236664162283 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [2/10], Step: [2001/2499], Train_loss: 0.046432577231898906\n",
      "Precision macro: 0.6066478102457735, Recall macro: 0.3953238033774485, F1 macro: 0.4538004613979837 \n",
      "Precision micro: 0.8361025641025641, Recall micro: 0.7145444983345994, F1 micro: 0.770558951414708 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [3/10], Step: [1001/2499], Train_loss: 0.0438212524317205\n",
      "Precision macro: 0.595848854706011, Recall macro: 0.4351071073072784, F1 macro: 0.48727221672144433 \n",
      "Precision micro: 0.8240823066175537, Recall micro: 0.7582539589785543, F1 micro: 0.7897988374570132 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [3/10], Step: [2001/2499], Train_loss: 0.0436657327413559\n",
      "Precision macro: 0.5798571592717772, Recall macro: 0.45096921829147657, F1 macro: 0.4909782774298685 \n",
      "Precision micro: 0.8403384467221573, Recall micro: 0.7138432770408462, F1 micro: 0.7719431279620852 \n",
      "Epoch: [4/10], Step: [1001/2499], Train_loss: 0.04216874808818102\n",
      "Precision macro: 0.6331037215861295, Recall macro: 0.48380289171474294, F1 macro: 0.5246994840636617 \n",
      "Precision micro: 0.8220115519839277, Recall micro: 0.7650908665926489, F1 micro: 0.7925304924185104 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [4/10], Step: [2001/2499], Train_loss: 0.042119321114383636\n",
      "Precision macro: 0.645531305427482, Recall macro: 0.433875638303375, F1 macro: 0.48628614600177983 \n",
      "Precision micro: 0.8208448579331155, Recall micro: 0.7630456378192018, F1 micro: 0.7908906453469005 \n",
      "Epoch: [5/10], Step: [1001/2499], Train_loss: 0.04142074013128877\n",
      "Precision macro: 0.6607502671904708, Recall macro: 0.469266364342851, F1 macro: 0.5257112271933602 \n",
      "Precision micro: 0.8231493099121706, Recall micro: 0.7667270496114066, F1 micro: 0.7939370102562551 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [5/10], Step: [2001/2499], Train_loss: 0.041160053848288955\n",
      "Precision macro: 0.6332300392950647, Recall macro: 0.47171952060531214, F1 macro: 0.523634927846643 \n",
      "Precision micro: 0.8416611295681063, Recall micro: 0.7401975106644072, F1 micro: 0.7876752790473526 \n",
      "Epoch: [6/10], Step: [1001/2499], Train_loss: 0.04053806144744158\n",
      "Precision macro: 0.6469216166279903, Recall macro: 0.4680249364541792, F1 macro: 0.5218140008170701 \n",
      "Precision micro: 0.8288665019324589, Recall micro: 0.7644480804067083, F1 micro: 0.7953550583657587 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [6/10], Step: [2001/2499], Train_loss: 0.04034328964911401\n",
      "Precision macro: 0.6816825497775718, Recall macro: 0.48546575748446297, F1 macro: 0.5431813910330264 \n",
      "Precision micro: 0.8517962027045486, Recall micro: 0.7288026646409163, F1 micro: 0.7855140922689341 \n",
      "Epoch: [7/10], Step: [1001/2499], Train_loss: 0.03990892579965293\n",
      "Precision macro: 0.7099407102196357, Recall macro: 0.4717191303271035, F1 macro: 0.5363000750815213 \n",
      "Precision micro: 0.8483732762083278, Recall micro: 0.7405481213112838, F1 micro: 0.7908021590589998 \n",
      "Epoch: [7/10], Step: [2001/2499], Train_loss: 0.03986260684113949\n",
      "Precision macro: 0.6873662230261361, Recall macro: 0.5201954800275146, F1 macro: 0.5637911375519796 \n",
      "Precision micro: 0.807975930623562, Recall micro: 0.8003272366037515, F1 micro: 0.8041333959605448 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [8/10], Step: [1001/2499], Train_loss: 0.039954358372837305\n",
      "Precision macro: 0.6818328122732022, Recall macro: 0.4870788803018467, F1 macro: 0.5486973246201955 \n",
      "Precision micro: 0.8478998868401784, Recall micro: 0.7443464033191142, F1 micro: 0.7927557879014191 \n",
      "Epoch: [8/10], Step: [2001/2499], Train_loss: 0.0397883587917313\n",
      "Precision macro: 0.6923654743052804, Recall macro: 0.5041002703052798, F1 macro: 0.5629492510680696 \n",
      "Precision micro: 0.8325004744133089, Recall micro: 0.7690644539239175, F1 micro: 0.7995261527246218 \n",
      "Epoch: [9/10], Step: [1001/2499], Train_loss: 0.039166527626104654\n",
      "Precision macro: 0.7081270516337607, Recall macro: 0.5191855837508369, F1 macro: 0.5769830669361339 \n",
      "Precision micro: 0.8293202909455731, Recall micro: 0.7728627359317478, F1 micro: 0.8000967907806782 \n",
      "Epoch: [9/10], Step: [2001/2499], Train_loss: 0.03911225138651207\n",
      "Precision macro: 0.7242829401706813, Recall macro: 0.5150004879039821, F1 macro: 0.5726450977391809 \n",
      "Precision micro: 0.8415726716081212, Recall micro: 0.762987202711389, F1 micro: 0.8003555228637981 \n",
      "Epoch: [10/10], Step: [1001/2499], Train_loss: 0.038286118613556026\n",
      "Precision macro: 0.6928947444990652, Recall macro: 0.5132887393253129, F1 macro: 0.5716006410245348 \n",
      "Precision micro: 0.8520259533898306, Recall micro: 0.7520014024425875, F1 micro: 0.7988949933265046 \n",
      "Epoch: [10/10], Step: [2001/2499], Train_loss: 0.03854647483956069\n",
      "Precision macro: 0.6916981377411409, Recall macro: 0.5394490935732318, F1 macro: 0.5765183528649813 \n",
      "Precision micro: 0.8115244689590424, Recall micro: 0.8081575410506633, F1 micro: 0.8098375054896795 \n",
      "Model Saved\n",
      "\n",
      "\n",
      " {'optimizer': 'SWA', 'num_hidden': 2, 'dim_hidden': 80, 'dropout_rate': 0.2, 'learning_rate': 0.001, 'num_epochs': 10}\n",
      "Epoch: [1/10], Step: [1001/2499], Train_loss: 0.1417414743900299\n",
      "Precision macro: 0.11580396546724875, Recall macro: 0.04788412550889593, F1 macro: 0.05665591578443492 \n",
      "Precision micro: 0.7704034207101692, Recall micro: 0.2421550867761351, F1 micro: 0.3684865730037346 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [1/10], Step: [2001/2499], Train_loss: 0.11487612077593803\n",
      "Precision macro: 0.13184513492477204, Recall macro: 0.09212808139854473, F1 macro: 0.10432723572530044 \n",
      "Precision micro: 0.8077544426494345, Recall micro: 0.43826330859580437, F1 micro: 0.5682248655201152 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [2/10], Step: [1001/2499], Train_loss: 0.07283569106087089\n",
      "Precision macro: 0.2936957718648376, Recall macro: 0.13073539682516264, F1 macro: 0.1538090440531173 \n",
      "Precision micro: 0.8203088441740758, Recall micro: 0.5121837199789634, F1 micro: 0.6306209079789913 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [2/10], Step: [2001/2499], Train_loss: 0.07177608454972506\n",
      "Precision macro: 0.29237648214544887, Recall macro: 0.14061491163012513, F1 macro: 0.1664329744560977 \n",
      "Precision micro: 0.8256072686816244, Recall micro: 0.5203646350727517, F1 micro: 0.6383741352736657 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [3/10], Step: [1001/2499], Train_loss: 0.06200759693980217\n",
      "Precision macro: 0.429597151908929, Recall macro: 0.19696290529899524, F1 macro: 0.23264451674648276 \n",
      "Precision micro: 0.8313073678987845, Recall micro: 0.5874481388418161, F1 micro: 0.6884201876326782 \n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [3/10], Step: [2001/2499], Train_loss: 0.06183473600819707\n",
      "Precision macro: 0.3855679830473306, Recall macro: 0.19376788810883247, F1 macro: 0.23000923573366955 \n",
      "Precision micro: 0.8256262833675565, Recall micro: 0.5873897037340033, F1 micro: 0.6864244741873805 \n",
      "Epoch: [4/10], Step: [1001/2499], Train_loss: 0.05614892731979489\n",
      "Precision macro: 0.4346780167986582, Recall macro: 0.22974691372693978, F1 macro: 0.2721614326347502 \n",
      "Precision micro: 0.8378314580218743, Recall micro: 0.6222170279904167, F1 micro: 0.7141036818456175 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [4/10], Step: [2001/2499], Train_loss: 0.056379694627597926\n",
      "Precision macro: 0.43778010931927264, Recall macro: 0.2273467935454587, F1 macro: 0.26787722889590593 \n",
      "Precision micro: 0.8270955768635941, Recall micro: 0.6250219131654298, F1 micro: 0.7119986686636711 \n",
      "Epoch: [5/10], Step: [1001/2499], Train_loss: 0.05303310260362923\n",
      "Precision macro: 0.524237616679755, Recall macro: 0.27699303798920005, F1 macro: 0.3281567687342629 \n",
      "Precision micro: 0.8306385515237314, Recall micro: 0.6514345818968036, F1 micro: 0.7302023973275693 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [5/10], Step: [2001/2499], Train_loss: 0.05287304232828319\n",
      "Precision macro: 0.534248695546162, Recall macro: 0.2733462441705583, F1 macro: 0.3280466055596143 \n",
      "Precision micro: 0.8373402312842362, Recall micro: 0.6431367965873898, F1 micro: 0.727501074131606 \n",
      "Epoch: [6/10], Step: [1001/2499], Train_loss: 0.050601992893964054\n",
      "Precision macro: 0.5289747132315854, Recall macro: 0.31692745673983447, F1 macro: 0.37309930232708804 \n",
      "Precision micro: 0.8314437428243399, Recall micro: 0.6770875942266114, F1 micro: 0.7463686431124996 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [6/10], Step: [2001/2499], Train_loss: 0.05051868907455355\n",
      "Precision macro: 0.5238684280747248, Recall macro: 0.30722656418459987, F1 macro: 0.3607143716143301 \n",
      "Precision micro: 0.8315843171549336, Recall micro: 0.6668030152515632, F1 micro: 0.7401329657856334 \n",
      "Epoch: [7/10], Step: [1001/2499], Train_loss: 0.04867823473922908\n",
      "Precision macro: 0.5437759378447352, Recall macro: 0.32503472979221193, F1 macro: 0.38373884406256153 \n",
      "Precision micro: 0.8421168043271691, Recall micro: 0.6732308771109683, F1 micro: 0.7482626485679028 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [7/10], Step: [2001/2499], Train_loss: 0.048864498229697344\n",
      "Precision macro: 0.5540074594971618, Recall macro: 0.3379154130234669, F1 macro: 0.394735371381074 \n",
      "Precision micro: 0.8385514355792815, Recall micro: 0.679249693215684, F1 micro: 0.750540758676352 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [8/10], Step: [1001/2499], Train_loss: 0.04733423865772784\n",
      "Precision macro: 0.5802855644745476, Recall macro: 0.3659490766738411, F1 macro: 0.4215857176168402 \n",
      "Precision micro: 0.8358167386157916, Recall micro: 0.701455034184538, F1 micro: 0.7627640984908659 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [8/10], Step: [2001/2499], Train_loss: 0.04745151613559574\n",
      "Precision macro: 0.5517438853116107, Recall macro: 0.35605922151790664, F1 macro: 0.41099838278800543 \n",
      "Precision micro: 0.835626102292769, Recall micro: 0.692163852042307, F1 micro: 0.7571592942981334 \n",
      "Epoch: [9/10], Step: [1001/2499], Train_loss: 0.046660139758139846\n",
      "Precision macro: 0.5722041718178513, Recall macro: 0.3762372264244089, F1 macro: 0.4262298804674888 \n",
      "Precision micro: 0.8295423774708909, Recall micro: 0.7160638111377315, F1 micro: 0.7686372902618787 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [9/10], Step: [2001/2499], Train_loss: 0.04638984597939998\n",
      "Precision macro: 0.5523156544967815, Recall macro: 0.3717320714234986, F1 macro: 0.42790864376696053 \n",
      "Precision micro: 0.8408353322985749, Recall micro: 0.6964296149126395, F1 micro: 0.7618499696359511 \n",
      "Epoch: [10/10], Step: [1001/2499], Train_loss: 0.04540835950896144\n",
      "Precision macro: 0.5605461119351065, Recall macro: 0.3882414277767806, F1 macro: 0.44086453375410267 \n",
      "Precision micro: 0.8396343996676361, Recall micro: 0.7085841173376964, F1 micro: 0.7685628268103312 \n",
      "Epoch: [10/10], Step: [2001/2499], Train_loss: 0.04509262944944203\n",
      "Precision macro: 0.5854671345640385, Recall macro: 0.38755024327637205, F1 macro: 0.44342425109496997 \n",
      "Precision micro: 0.8444863995524788, Recall micro: 0.7057207970548706, F1 micro: 0.7688928503215128 \n",
      "Model Saved\n",
      "\n",
      "\n",
      " {'optimizer': 'SWA', 'num_hidden': 2, 'dim_hidden': 80, 'dropout_rate': 0.2, 'learning_rate': 0.01, 'num_epochs': 10}\n",
      "Epoch: [1/10], Step: [1001/2499], Train_loss: 0.08212505570426583\n",
      "Precision macro: 0.41803668176012626, Recall macro: 0.21657749896525438, F1 macro: 0.2572436856586832 \n",
      "Precision micro: 0.8299449892370246, Recall micro: 0.6083094723309764, F1 micro: 0.7020501753439439 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [1/10], Step: [2001/2499], Train_loss: 0.06737961793225258\n",
      "Precision macro: 0.5643802846792592, Recall macro: 0.3475322082640845, F1 macro: 0.4077700621718127 \n",
      "Precision micro: 0.8420741179081292, Recall micro: 0.6652252673406183, F1 micro: 0.7432750065291198 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [2/10], Step: [1001/2499], Train_loss: 0.04710308854281902\n",
      "Precision macro: 0.5675953449841968, Recall macro: 0.425001466787702, F1 macro: 0.46817702722253124 \n",
      "Precision micro: 0.8211248104437265, Recall micro: 0.7277508327002863, F1 micro: 0.771623296158612 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [2/10], Step: [2001/2499], Train_loss: 0.04690579469036311\n",
      "Precision macro: 0.6211858028505293, Recall macro: 0.42176416478573747, F1 macro: 0.4721715410752358 \n",
      "Precision micro: 0.8289819874519329, Recall micro: 0.7180506048033659, F1 micro: 0.7695390781563126 \n",
      "Epoch: [3/10], Step: [1001/2499], Train_loss: 0.04343548389151693\n",
      "Precision macro: 0.5967085258497073, Recall macro: 0.45437933393408286, F1 macro: 0.5013681195684022 \n",
      "Precision micro: 0.8334315844632213, Recall micro: 0.7435283118097353, F1 micro: 0.7859172328597899 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [3/10], Step: [2001/2499], Train_loss: 0.04379622695501894\n",
      "Precision macro: 0.6326178571413225, Recall macro: 0.4300238944415119, F1 macro: 0.4856935217184644 \n",
      "Precision micro: 0.8303162920230754, Recall micro: 0.7317244200315549, F1 micro: 0.7779089271292787 \n",
      "Epoch: [4/10], Step: [1001/2499], Train_loss: 0.043008089430630204\n",
      "Precision macro: 0.6381005708172178, Recall macro: 0.46426015790274133, F1 macro: 0.5133401242580448 \n",
      "Precision micro: 0.8399573219525207, Recall micro: 0.7360486180097002, F1 micro: 0.7845775327789717 \n",
      "Epoch: [4/10], Step: [2001/2499], Train_loss: 0.04242349763121456\n",
      "Precision macro: 0.6456924567597393, Recall macro: 0.4688461886364863, F1 macro: 0.5228859084900241 \n",
      "Precision micro: 0.8330903790087464, Recall micro: 0.7347046105300065, F1 micro: 0.7808104331625524 \n",
      "Epoch: [5/10], Step: [1001/2499], Train_loss: 0.04083973597735167\n",
      "Precision macro: 0.6369741714885925, Recall macro: 0.47703558190564765, F1 macro: 0.5270112589584376 \n",
      "Precision micro: 0.8467938311688312, Recall micro: 0.7315491147081167, F1 micro: 0.7849641032071982 \n",
      "Epoch: [5/10], Step: [2001/2499], Train_loss: 0.040843362481333315\n",
      "Precision macro: 0.6809787952182479, Recall macro: 0.4677184976200079, F1 macro: 0.5225212452987694 \n",
      "Precision micro: 0.830062016495109, Recall micro: 0.7586630047332438, F1 micro: 0.7927581364108202 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [6/10], Step: [1001/2499], Train_loss: 0.04192005958594382\n",
      "Precision macro: 0.6757813622822458, Recall macro: 0.47225596337685266, F1 macro: 0.5254253443033462 \n",
      "Precision micro: 0.8205321285140562, Recall micro: 0.7640974697598317, F1 micro: 0.7913098732185543 \n",
      "Epoch: [6/10], Step: [2001/2499], Train_loss: 0.04144467284716666\n",
      "Precision macro: 0.6825732812004508, Recall macro: 0.47590640219851815, F1 macro: 0.5306736044518744 \n",
      "Precision micro: 0.8444459261234831, Recall micro: 0.7400806404487816, F1 micro: 0.7888262589143907 \n",
      "Epoch: [7/10], Step: [1001/2499], Train_loss: 0.04087913233414292\n",
      "Precision macro: 0.7345365298275638, Recall macro: 0.5046838865234883, F1 macro: 0.5602821421373565 \n",
      "Precision micro: 0.8270934731062024, Recall micro: 0.7745573540583183, F1 micro: 0.7999637888892241 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [7/10], Step: [2001/2499], Train_loss: 0.04045063562411815\n",
      "Precision macro: 0.7179402791059804, Recall macro: 0.5059694927404489, F1 macro: 0.5569265767848889 \n",
      "Precision micro: 0.8324697754749568, Recall micro: 0.7604744930754397, F1 micro: 0.794845171929396 \n",
      "Epoch: [8/10], Step: [1001/2499], Train_loss: 0.04007550150342286\n",
      "Precision macro: 0.7177964287203201, Recall macro: 0.4955176258297135, F1 macro: 0.5601600073113605 \n",
      "Precision micro: 0.8437686740588274, Recall micro: 0.7425933500847309, F1 micro: 0.7899546217442656 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [8/10], Step: [2001/2499], Train_loss: 0.03996502546034753\n",
      "Precision macro: 0.7407214491203914, Recall macro: 0.5218365553274494, F1 macro: 0.5754217412386878 \n",
      "Precision micro: 0.8260762151812735, Recall micro: 0.7815695669958511, F1 micro: 0.803206822003363 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [9/10], Step: [1001/2499], Train_loss: 0.039831197841092944\n",
      "Precision macro: 0.7332671322501366, Recall macro: 0.500245361430969, F1 macro: 0.5569116262943682 \n",
      "Precision micro: 0.83280430135389, Recall micro: 0.7512417460410215, F1 micro: 0.7899231950844855 \n",
      "Epoch: [9/10], Step: [2001/2499], Train_loss: 0.040014788595028224\n",
      "Precision macro: 0.7165103419399753, Recall macro: 0.5178763358562315, F1 macro: 0.5679686748650299 \n",
      "Precision micro: 0.8271817428443935, Recall micro: 0.7582539589785543, F1 micro: 0.7912195121951221 \n",
      "Epoch: [10/10], Step: [1001/2499], Train_loss: 0.039303801646456124\n",
      "Precision macro: 0.7222768487806164, Recall macro: 0.4960993852996312, F1 macro: 0.5579203756050976 \n",
      "Precision micro: 0.8354981166385245, Recall micro: 0.7517676620113364, F1 micro: 0.7914244409584448 \n",
      "Epoch: [10/10], Step: [2001/2499], Train_loss: 0.03921638949494809\n",
      "Precision macro: 0.7237929809994759, Recall macro: 0.5260516149630431, F1 macro: 0.5801796556795316 \n",
      "Precision micro: 0.8290852713178295, Recall micro: 0.7812189563489744, F1 micro: 0.8044407004031531 \n",
      "Model Saved\n",
      "\n",
      "\n",
      " {'optimizer': 'SWA', 'num_hidden': 2, 'dim_hidden': 120, 'dropout_rate': 0, 'learning_rate': 0.001, 'num_epochs': 10}\n",
      "Epoch: [1/10], Step: [1001/2499], Train_loss: 0.136982500359416\n",
      "Precision macro: 0.11348227728616571, Recall macro: 0.04949849280835366, F1 macro: 0.058969412389223624 \n",
      "Precision micro: 0.7545980031529165, Recall micro: 0.25173844445743004, F1 micro: 0.37753045307159766 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [1/10], Step: [2001/2499], Train_loss: 0.11147442043200136\n",
      "Precision macro: 0.20697994603653258, Recall macro: 0.10115535478323846, F1 macro: 0.11483873037424831 \n",
      "Precision micro: 0.8189555532205527, Recall micro: 0.4554432302927599, F1 micro: 0.5853548629365377 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [2/10], Step: [1001/2499], Train_loss: 0.06959654592722654\n",
      "Precision macro: 0.3045023402077444, Recall macro: 0.15363490433134191, F1 macro: 0.18064623282486944 \n",
      "Precision micro: 0.8244018716341485, Recall micro: 0.5456670367556828, F1 micro: 0.6566807313642757 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [2/10], Step: [2001/2499], Train_loss: 0.06822103121690452\n",
      "Precision macro: 0.2892831970490669, Recall macro: 0.16476396459047302, F1 macro: 0.19332948058367821 \n",
      "Precision micro: 0.8290471624095546, Recall micro: 0.5557178752994799, F1 micro: 0.665407220822838 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [3/10], Step: [1001/2499], Train_loss: 0.05834688458405435\n",
      "Precision macro: 0.4445601287886053, Recall macro: 0.2156037048385805, F1 macro: 0.2522724888651778 \n",
      "Precision micro: 0.8317533657293077, Recall micro: 0.6101209606731725, F1 micro: 0.7039034585046856 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [3/10], Step: [2001/2499], Train_loss: 0.058711877000518144\n",
      "Precision macro: 0.441308313006659, Recall macro: 0.21390136044740482, F1 macro: 0.2517720408338935 \n",
      "Precision micro: 0.8329055029680732, Recall micro: 0.6067317244200315, F1 micro: 0.702052131579837 \n",
      "Epoch: [4/10], Step: [1001/2499], Train_loss: 0.053730147417634724\n",
      "Precision macro: 0.5036955442649328, Recall macro: 0.26678959446579137, F1 macro: 0.31992169598831477 \n",
      "Precision micro: 0.8352432268346361, Recall micro: 0.6431367965873898, F1 micro: 0.7267084846483989 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [4/10], Step: [2001/2499], Train_loss: 0.053897784021683035\n",
      "Precision macro: 0.5246770618264066, Recall macro: 0.24689999346167457, F1 macro: 0.29415777335574783 \n",
      "Precision micro: 0.8337656393042416, Recall micro: 0.6386372932858061, F1 micro: 0.7232718970252474 \n",
      "Epoch: [5/10], Step: [1001/2499], Train_loss: 0.05049538019672036\n",
      "Precision macro: 0.530847314926506, Recall macro: 0.30895442258147515, F1 macro: 0.3643227443729952 \n",
      "Precision micro: 0.825516609069751, Recall micro: 0.6839829369485186, F1 micro: 0.748114534066215 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [5/10], Step: [2001/2499], Train_loss: 0.050796869055368\n",
      "Precision macro: 0.5406885557038709, Recall macro: 0.2958985824808928, F1 macro: 0.35451407898338555 \n",
      "Precision micro: 0.841030262071037, Recall micro: 0.6544732075030678, F1 micro: 0.7361156753204076 \n",
      "Epoch: [6/10], Step: [1001/2499], Train_loss: 0.048540692811831834\n",
      "Precision macro: 0.5355145114336264, Recall macro: 0.34097472151451425, F1 macro: 0.39666826831991864 \n",
      "Precision micro: 0.8380590050965473, Recall micro: 0.6822298837141354, F1 micro: 0.7521582270325989 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [6/10], Step: [2001/2499], Train_loss: 0.04869734746590257\n",
      "Precision macro: 0.5433143463909708, Recall macro: 0.3527888996037882, F1 macro: 0.40498209471638086 \n",
      "Precision micro: 0.8287246639270043, Recall micro: 0.695260912756384, F1 micro: 0.7561487130600572 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [7/10], Step: [1001/2499], Train_loss: 0.046588044069707395\n",
      "Precision macro: 0.5695932363593387, Recall macro: 0.37082373632229493, F1 macro: 0.4249295948180936 \n",
      "Precision micro: 0.8359191023687491, Recall micro: 0.7052533161923684, F1 micro: 0.7650470666539889 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [7/10], Step: [2001/2499], Train_loss: 0.04730345784686506\n",
      "Precision macro: 0.5710813325268794, Recall macro: 0.3567147340925276, F1 macro: 0.41202219207108387 \n",
      "Precision micro: 0.8390106007067137, Recall micro: 0.6937415999532519, F1 micro: 0.7594920513066564 \n",
      "Epoch: [8/10], Step: [1001/2499], Train_loss: 0.04587073295004666\n",
      "Precision macro: 0.5649077546376889, Recall macro: 0.3807480719700235, F1 macro: 0.43410995336212393 \n",
      "Precision micro: 0.8413242808147267, Recall micro: 0.7023899959095424, F1 micro: 0.7656050955414012 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [8/10], Step: [2001/2499], Train_loss: 0.04589962888043374\n",
      "Precision macro: 0.5598574696753112, Recall macro: 0.3680554783224967, F1 macro: 0.4242474578742259 \n",
      "Precision micro: 0.843235605793006, Recall micro: 0.6974814468532694, F1 micro: 0.7634642445951132 \n",
      "Epoch: [9/10], Step: [1001/2499], Train_loss: 0.04441705193929374\n",
      "Precision macro: 0.5849245269265194, Recall macro: 0.38477867054511433, F1 macro: 0.4381163978350248 \n",
      "Precision micro: 0.8320605528147598, Recall micro: 0.7194530473908725, F1 micro: 0.7716703227828267 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [9/10], Step: [2001/2499], Train_loss: 0.04490520131960511\n",
      "Precision macro: 0.5860394682510011, Recall macro: 0.38602553508754506, F1 macro: 0.44159207370148557 \n",
      "Precision micro: 0.8429601624308619, Recall micro: 0.703558698065798, F1 micro: 0.7669766849280163 \n",
      "Epoch: [10/10], Step: [1001/2499], Train_loss: 0.044376989495009185\n",
      "Precision macro: 0.5871381078887654, Recall macro: 0.3917602936398964, F1 macro: 0.4478993167314467 \n",
      "Precision micro: 0.8480228348649401, Recall micro: 0.711798048267399, F1 micro: 0.7739619404644662 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [10/10], Step: [2001/2499], Train_loss: 0.044087388730607927\n",
      "Precision macro: 0.5845010547535447, Recall macro: 0.3978662959742522, F1 macro: 0.45297209889031986 \n",
      "Precision micro: 0.8447611179953187, Recall micro: 0.7170572079705487, F1 micro: 0.7756882328771453 \n",
      "Model Saved\n",
      "\n",
      "\n",
      " {'optimizer': 'SWA', 'num_hidden': 2, 'dim_hidden': 120, 'dropout_rate': 0, 'learning_rate': 0.01, 'num_epochs': 10}\n",
      "Epoch: [1/10], Step: [1001/2499], Train_loss: 0.07395461348816752\n",
      "Precision macro: 0.5146175688553305, Recall macro: 0.3018980988757176, F1 macro: 0.35331031822162423 \n",
      "Precision micro: 0.8265828337476239, Recall micro: 0.6606673289312219, F1 micro: 0.7343704329187101 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [1/10], Step: [2001/2499], Train_loss: 0.06114117034338415\n",
      "Precision macro: 0.5896267437517658, Recall macro: 0.3854047713300243, F1 macro: 0.4422961900408742 \n",
      "Precision micro: 0.8334707337180544, Recall micro: 0.7089347279845731, F1 micro: 0.7661751239382361 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [2/10], Step: [1001/2499], Train_loss: 0.044395946126431225\n",
      "Precision macro: 0.6181848501353379, Recall macro: 0.3886043246983155, F1 macro: 0.45473694877315707 \n",
      "Precision micro: 0.8593312711739579, Recall micro: 0.681820837959446, F1 micro: 0.7603531980059302 \n",
      "Epoch: [2/10], Step: [2001/2499], Train_loss: 0.043694807256571946\n",
      "Precision macro: 0.6289185936444923, Recall macro: 0.4769852923340249, F1 macro: 0.5279999903553478 \n",
      "Precision micro: 0.8367940748578231, Recall micro: 0.7394378542628411, F1 micro: 0.7851093531875291 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n",
      "\n",
      "Epoch: [3/10], Step: [1001/2499], Train_loss: 0.04234453810751438\n",
      "Precision macro: 0.6516890260841843, Recall macro: 0.4800706488643533, F1 macro: 0.5267861108362948 \n",
      "Precision micro: 0.8398915415647114, Recall micro: 0.7421258692222287, F1 micro: 0.7879878389278402 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [3/10], Step: [2001/2499], Train_loss: 0.04168704004585743\n",
      "Precision macro: 0.6603816600496363, Recall macro: 0.49618784401024774, F1 macro: 0.5461755369759607 \n",
      "Precision micro: 0.836507413509061, Recall micro: 0.7417752585753521, F1 micro: 0.7862983151635282 \n",
      "Epoch: [4/10], Step: [1001/2499], Train_loss: 0.0399586783926934\n",
      "Precision macro: 0.7031994496628118, Recall macro: 0.4736989371537309, F1 macro: 0.5428589046209477 \n",
      "Precision micro: 0.8271902556619932, Recall micro: 0.7619353707707591, F1 micro: 0.7932230198320963 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [4/10], Step: [2001/2499], Train_loss: 0.04025269797071815\n",
      "Precision macro: 0.6755903420514063, Recall macro: 0.47532756302233353, F1 macro: 0.5289908834127859 \n",
      "Precision micro: 0.8441007569825111, Recall micro: 0.7558581195582306, F1 micro: 0.7975460122699386 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [5/10], Step: [1001/2499], Train_loss: 0.03942647471651435\n",
      "Precision macro: 0.6820396195838697, Recall macro: 0.5140068761771933, F1 macro: 0.5645335651350998 \n",
      "Precision micro: 0.8362989323843416, Recall micro: 0.7690060188161048, F1 micro: 0.8012420469420684 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [5/10], Step: [2001/2499], Train_loss: 0.039305547419935465\n",
      "Precision macro: 0.6842002559955249, Recall macro: 0.47112675935859155, F1 macro: 0.5251683882991542 \n",
      "Precision micro: 0.815240658063727, Recall micro: 0.7789399871442763, F1 micro: 0.7966770260578533 \n",
      "Epoch: [6/10], Step: [1001/2499], Train_loss: 0.03871656736359\n",
      "Precision macro: 0.6890266259456682, Recall macro: 0.5517822553100467, F1 macro: 0.5920261376572271 \n",
      "Precision micro: 0.820226762869096, Recall micro: 0.7905101384912055, F1 micro: 0.8050943283937392 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [6/10], Step: [2001/2499], Train_loss: 0.03865398495830596\n",
      "Precision macro: 0.7051396706775571, Recall macro: 0.5180917743482794, F1 macro: 0.5699694570548125 \n",
      "Precision micro: 0.8474777448071217, Recall micro: 0.7510080056097703, F1 micro: 0.796331866906252 \n",
      "Epoch: [7/10], Step: [1001/2499], Train_loss: 0.03756342059932649\n",
      "Precision macro: 0.7170085853137322, Recall macro: 0.5361387797807988, F1 macro: 0.5873803392067314 \n",
      "Precision micro: 0.8293992070753279, Recall micro: 0.7946005960380997, F1 micro: 0.8116270741315507 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [7/10], Step: [2001/2499], Train_loss: 0.03811917341221124\n",
      "Precision macro: 0.7214202459320833, Recall macro: 0.5350897638565315, F1 macro: 0.5907585170554401 \n",
      "Precision micro: 0.8331451511730021, Recall micro: 0.7761351019692632, F1 micro: 0.8036303131145061 \n",
      "Epoch: [8/10], Step: [1001/2499], Train_loss: 0.03772248519957066\n",
      "Precision macro: 0.743378828128234, Recall macro: 0.500827657424873, F1 macro: 0.567086185854275 \n",
      "Precision micro: 0.84375, Recall micro: 0.7588967451644948, F1 micro: 0.7990770650669128 \n",
      "Epoch: [8/10], Step: [2001/2499], Train_loss: 0.0377651422470808\n",
      "Precision macro: 0.7266255725939458, Recall macro: 0.5325444580972615, F1 macro: 0.592287922945681 \n",
      "Precision micro: 0.8560560156197401, Recall micro: 0.7430023958394203, F1 micro: 0.7955327535506476 \n",
      "Epoch: [9/10], Step: [1001/2499], Train_loss: 0.03675671239942312\n",
      "Precision macro: 0.7241734161264499, Recall macro: 0.5535915043125349, F1 macro: 0.6089470216490578 \n",
      "Precision micro: 0.8321235808672994, Recall micro: 0.7837901010927365, F1 micro: 0.8072339913336543 \n",
      "Epoch: [9/10], Step: [2001/2499], Train_loss: 0.03710351693164557\n",
      "Precision macro: 0.7207336099733065, Recall macro: 0.556873843976915, F1 macro: 0.6085337674596221 \n",
      "Precision micro: 0.8442575960252245, Recall micro: 0.7744989189505055, F1 micro: 0.8078751676216019 \n",
      "Epoch: [10/10], Step: [1001/2499], Train_loss: 0.03662959760986269\n",
      "Precision macro: 0.6798649862374352, Recall macro: 0.5462930490962633, F1 macro: 0.585741339668589 \n",
      "Precision micro: 0.8331086050502574, Recall micro: 0.7943084204990358, F1 micro: 0.8132459840258458 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [10/10], Step: [2001/2499], Train_loss: 0.037039913540706036\n",
      "Precision macro: 0.7179432480545929, Recall macro: 0.5444740417310597, F1 macro: 0.5953134518969909 \n",
      "Precision micro: 0.8194050564170638, Recall micro: 0.7935487640974698, F1 micro: 0.8062696669239446 \n",
      "\n",
      " {'optimizer': 'SWA', 'num_hidden': 2, 'dim_hidden': 120, 'dropout_rate': 0.1, 'learning_rate': 0.001, 'num_epochs': 10}\n",
      "Epoch: [1/10], Step: [1001/2499], Train_loss: 0.13296992290765047\n",
      "Precision macro: 0.1149105474563728, Recall macro: 0.0635280200389416, F1 macro: 0.07290936765793257 \n",
      "Precision micro: 0.7687268584448875, Recall micro: 0.3154327119733536, F1 micro: 0.44731717422829914 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [1/10], Step: [2001/2499], Train_loss: 0.10802244277484715\n",
      "Precision macro: 0.23985741995771653, Recall macro: 0.10490464950762836, F1 macro: 0.11864880397511764 \n",
      "Precision micro: 0.8277789277582281, Recall micro: 0.4673639922865658, F1 micro: 0.5974229691876751 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [2/10], Step: [1001/2499], Train_loss: 0.06905127269402146\n",
      "Precision macro: 0.3465830221292771, Recall macro: 0.15288287309052764, F1 macro: 0.18301453917989782 \n",
      "Precision micro: 0.8390248356464572, Recall micro: 0.5369602056915795, F1 micro: 0.6548369855692143 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [2/10], Step: [2001/2499], Train_loss: 0.06766197198443115\n",
      "Precision macro: 0.35805410711961194, Recall macro: 0.17106394084517107, F1 macro: 0.20427620070525715 \n",
      "Precision micro: 0.8384237317886607, Recall micro: 0.5582305849354292, F1 micro: 0.6702213491423159 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [3/10], Step: [1001/2499], Train_loss: 0.058660153236240145\n",
      "Precision macro: 0.44044911277566373, Recall macro: 0.20437955757760473, F1 macro: 0.24335746361046706 \n",
      "Precision micro: 0.8296284407350935, Recall micro: 0.6041021445684567, F1 micro: 0.699127612091702 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [3/10], Step: [2001/2499], Train_loss: 0.058207625754177574\n",
      "Precision macro: 0.4742819268317191, Recall macro: 0.21103267294275796, F1 macro: 0.25275674846700363 \n",
      "Precision micro: 0.8321516768899865, Recall micro: 0.6104131362122364, F1 micro: 0.7042405447313422 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [4/10], Step: [1001/2499], Train_loss: 0.05294127619080245\n",
      "Precision macro: 0.5370011892852349, Recall macro: 0.2752748978056246, F1 macro: 0.3304403487732417 \n",
      "Precision micro: 0.8337311651499328, Recall micro: 0.653129200023374, F1 micro: 0.7324617451423703 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [4/10], Step: [2001/2499], Train_loss: 0.053410159645602105\n",
      "Precision macro: 0.5274317109812455, Recall macro: 0.2626640929006989, F1 macro: 0.31447272060810294 \n",
      "Precision micro: 0.8338972855101887, Recall micro: 0.6480453456436627, F1 micro: 0.7293173747205051 \n",
      "Epoch: [5/10], Step: [1001/2499], Train_loss: 0.049997546188533304\n",
      "Precision macro: 0.5366228685328724, Recall macro: 0.31951220079449794, F1 macro: 0.37767387740187386 \n",
      "Precision micro: 0.8424927493121143, Recall micro: 0.6620113364109157, F1 micro: 0.7414267015706808 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [5/10], Step: [2001/2499], Train_loss: 0.0504852252183482\n",
      "Precision macro: 0.5406586371960386, Recall macro: 0.3088475205989032, F1 macro: 0.3677268184073696 \n",
      "Precision micro: 0.8414688427299704, Recall micro: 0.6628294279202945, F1 micro: 0.7415421828522866 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [6/10], Step: [1001/2499], Train_loss: 0.04819186414964497\n",
      "Precision macro: 0.532819165902887, Recall macro: 0.3499219405678755, F1 macro: 0.4051293086676202 \n",
      "Precision micro: 0.8441850348027842, Recall micro: 0.6803599602641267, F1 micro: 0.7534703122472092 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [6/10], Step: [2001/2499], Train_loss: 0.04825887863337994\n",
      "Precision macro: 0.5539360850475012, Recall macro: 0.3365911430950694, F1 macro: 0.3947222391493273 \n",
      "Precision micro: 0.8417619466432131, Recall micro: 0.6711272132297084, F1 micro: 0.7468218616900217 \n",
      "Epoch: [7/10], Step: [1001/2499], Train_loss: 0.04712307932041585\n",
      "Precision macro: 0.5901394533739889, Recall macro: 0.3633941987981902, F1 macro: 0.4208004450869067 \n",
      "Precision micro: 0.842809364548495, Recall micro: 0.6921054169344942, F1 micro: 0.760059038696015 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [7/10], Step: [2001/2499], Train_loss: 0.04692826263699681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision macro: 0.5320415806146319, Recall macro: 0.35837132516104037, F1 macro: 0.41340541231071926 \n",
      "Precision micro: 0.8468826847967598, Recall micro: 0.6842166773797698, F1 micro: 0.7569087559391061 \n",
      "Epoch: [8/10], Step: [1001/2499], Train_loss: 0.04532984853908419\n",
      "Precision macro: 0.5801303712826203, Recall macro: 0.38745546143322956, F1 macro: 0.4410293884475637 \n",
      "Precision micro: 0.8389206305500103, Recall micro: 0.7121486589142757, F1 micro: 0.770353982300885 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [8/10], Step: [2001/2499], Train_loss: 0.04558108008094132\n",
      "Precision macro: 0.5888127032532707, Recall macro: 0.3720031592733124, F1 macro: 0.42874037249901653 \n",
      "Precision micro: 0.8470437930300234, Recall micro: 0.697364576637644, F1 micro: 0.7649509646817512 \n",
      "Epoch: [9/10], Step: [1001/2499], Train_loss: 0.04436332703568041\n",
      "Precision macro: 0.5897040072643247, Recall macro: 0.3905062526470875, F1 macro: 0.44839504781241124 \n",
      "Precision micro: 0.8433080192294294, Recall micro: 0.7072985449658155, F1 micro: 0.7693383334392678 \n",
      "Epoch: [9/10], Step: [2001/2499], Train_loss: 0.04438042889162898\n",
      "Precision macro: 0.5946214471197429, Recall macro: 0.3958677382432858, F1 macro: 0.4511622939074598 \n",
      "Precision micro: 0.8507996632996633, Recall micro: 0.7087594226611348, F1 micro: 0.7733112308329879 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [10/10], Step: [1001/2499], Train_loss: 0.0442451742105186\n",
      "Precision macro: 0.5845496680243586, Recall macro: 0.3988793405198987, F1 macro: 0.4545792083685616 \n",
      "Precision micro: 0.8442395674476639, Recall micro: 0.7116811780517736, F1 micro: 0.7723136434256 \n",
      "Epoch: [10/10], Step: [2001/2499], Train_loss: 0.0440568506559357\n",
      "Precision macro: 0.5838202656738928, Recall macro: 0.4065549933743483, F1 macro: 0.4612391035254442 \n",
      "Precision micro: 0.8456977385548814, Recall micro: 0.7167650324314848, F1 micro: 0.7759116930765094 \n",
      "Model Saved\n",
      "\n",
      "\n",
      " {'optimizer': 'SWA', 'num_hidden': 2, 'dim_hidden': 120, 'dropout_rate': 0.1, 'learning_rate': 0.01, 'num_epochs': 10}\n",
      "Epoch: [1/10], Step: [1001/2499], Train_loss: 0.07863697578012943\n",
      "Precision macro: 0.4911936688703285, Recall macro: 0.24553093395900605, F1 macro: 0.28795683950288437 \n",
      "Precision micro: 0.8287245611309616, Recall micro: 0.6234441652544849, F1 micro: 0.7115750158401974 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [1/10], Step: [2001/2499], Train_loss: 0.06449044725205749\n",
      "Precision macro: 0.5950896137290586, Recall macro: 0.36806928636937736, F1 macro: 0.42318054034997926 \n",
      "Precision micro: 0.8222729715206878, Recall micro: 0.7153625898439783, F1 micro: 0.765101090590919 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [2/10], Step: [1001/2499], Train_loss: 0.04577307015284896\n",
      "Precision macro: 0.6052527406454267, Recall macro: 0.3912800250370761, F1 macro: 0.4466338730603112 \n",
      "Precision micro: 0.8470555400502372, Recall micro: 0.7094022088470753, F1 micro: 0.7721418349499125 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [2/10], Step: [2001/2499], Train_loss: 0.045327288727276024\n",
      "Precision macro: 0.591951870123824, Recall macro: 0.4325660556394329, F1 macro: 0.4791309049328603 \n",
      "Precision micro: 0.8331020812685828, Recall micro: 0.7368082744112663, F1 micro: 0.7820019846192012 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [3/10], Step: [1001/2499], Train_loss: 0.04242396965250373\n",
      "Precision macro: 0.651874288800533, Recall macro: 0.44882012942881633, F1 macro: 0.5106112436552963 \n",
      "Precision micro: 0.8367907859433283, Recall micro: 0.74720972360194, F1 micro: 0.789467185281225 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [3/10], Step: [2001/2499], Train_loss: 0.042586237790994345\n",
      "Precision macro: 0.6529000687924393, Recall macro: 0.44757889596608, F1 macro: 0.5059061789755693 \n",
      "Precision micro: 0.8492669832748296, Recall micro: 0.7210307953018174, F1 micro: 0.7799127741609253 \n",
      "Epoch: [4/10], Step: [1001/2499], Train_loss: 0.041004673950374125\n",
      "Precision macro: 0.6381558856952132, Recall macro: 0.4893823490864342, F1 macro: 0.5350875485016661 \n",
      "Precision micro: 0.8344366562824507, Recall micro: 0.7513001811488342, F1 micro: 0.790689093201316 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [4/10], Step: [2001/2499], Train_loss: 0.040999589142389596\n",
      "Precision macro: 0.6447360833137489, Recall macro: 0.48807111430817934, F1 macro: 0.5375417166319006 \n",
      "Precision micro: 0.8298749838896765, Recall micro: 0.7525273184129024, F1 micro: 0.7893107780944499 \n",
      "Epoch: [5/10], Step: [1001/2499], Train_loss: 0.04019931126385927\n",
      "Precision macro: 0.6945060837075386, Recall macro: 0.47823551397710173, F1 macro: 0.5336881419825809 \n",
      "Precision micro: 0.8344730619288042, Recall micro: 0.762987202711389, F1 micro: 0.7971306471306472 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [5/10], Step: [2001/2499], Train_loss: 0.04008514874894172\n",
      "Precision macro: 0.6684792475211927, Recall macro: 0.4788889390387918, F1 macro: 0.5352028545001193 \n",
      "Precision micro: 0.8496210070384407, Recall micro: 0.7335943434815637, F1 micro: 0.7873561416162314 \n",
      "Epoch: [6/10], Step: [1001/2499], Train_loss: 0.039592590203508735\n",
      "Precision macro: 0.6775970627483657, Recall macro: 0.4986452592652802, F1 macro: 0.5554760678202763 \n",
      "Precision micro: 0.8412883197516492, Recall micro: 0.7601238824285631, F1 micro: 0.7986492709132771 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [6/10], Step: [2001/2499], Train_loss: 0.03948963234852999\n",
      "Precision macro: 0.7211741558401554, Recall macro: 0.49481057529378253, F1 macro: 0.5527955414267748 \n",
      "Precision micro: 0.837071791246224, Recall micro: 0.7610588441535675, F1 micro: 0.7972575905974535 \n",
      "Epoch: [7/10], Step: [1001/2499], Train_loss: 0.038540112433955075\n",
      "Precision macro: 0.7039093257752711, Recall macro: 0.5022927738046846, F1 macro: 0.55570270148914 \n",
      "Precision micro: 0.850826887169912, Recall micro: 0.7455735405831824, F1 micro: 0.7947304494067085 \n",
      "Epoch: [7/10], Step: [2001/2499], Train_loss: 0.03894350464548916\n",
      "Precision macro: 0.6874200867552537, Recall macro: 0.5110879945007566, F1 macro: 0.5563127773043742 \n",
      "Precision micro: 0.8192183403451009, Recall micro: 0.7851341085724303, F1 micro: 0.8018141672137017 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [8/10], Step: [1001/2499], Train_loss: 0.03901655741780996\n",
      "Precision macro: 0.6832990584461826, Recall macro: 0.5213809715348178, F1 macro: 0.5733692470766836 \n",
      "Precision micro: 0.8406395048994327, Recall micro: 0.7619938058785718, F1 micro: 0.7993869731800766 \n",
      "Epoch: [8/10], Step: [2001/2499], Train_loss: 0.0387424283940345\n",
      "Precision macro: 0.7126412802394881, Recall macro: 0.5268887582932987, F1 macro: 0.5761848233547486 \n",
      "Precision micro: 0.8288142954644164, Recall micro: 0.7805761701630339, F1 micro: 0.8039723141739393 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [9/10], Step: [1001/2499], Train_loss: 0.03797239049524069\n",
      "Precision macro: 0.6934486160475066, Recall macro: 0.5290704213095178, F1 macro: 0.5795368323626366 \n",
      "Precision micro: 0.8264392324093817, Recall micro: 0.7927306725880909, F1 micro: 0.8092340730136006 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [9/10], Step: [2001/2499], Train_loss: 0.03804354140534997\n",
      "Precision macro: 0.7051401284370789, Recall macro: 0.5260582345438221, F1 macro: 0.5795444223130257 \n",
      "Precision micro: 0.8218337933149341, Recall micro: 0.7830304446911704, F1 micro: 0.8019630139445807 \n",
      "Epoch: [10/10], Step: [1001/2499], Train_loss: 0.037895947897806766\n",
      "Precision macro: 0.6943540108061126, Recall macro: 0.514056324416565, F1 macro: 0.5677127685594422 \n",
      "Precision micro: 0.8337896701929061, Recall micro: 0.7829720095833577, F1 micro: 0.8075821957026188 \n",
      "Epoch: [10/10], Step: [2001/2499], Train_loss: 0.03804855483025312\n",
      "Precision macro: 0.7394550795414495, Recall macro: 0.5143260056761462, F1 macro: 0.5703385700250886 \n",
      "Precision micro: 0.837641866330391, Recall micro: 0.7763104072927015, F1 micro: 0.8058108149091682 \n",
      "\n",
      " {'optimizer': 'SWA', 'num_hidden': 2, 'dim_hidden': 120, 'dropout_rate': 0.2, 'learning_rate': 0.001, 'num_epochs': 10}\n",
      "Epoch: [1/10], Step: [1001/2499], Train_loss: 0.1358352915123105\n",
      "Precision macro: 0.11807097077487283, Recall macro: 0.05262534957467095, F1 macro: 0.062274918779892725 \n",
      "Precision micro: 0.7748925501432665, Recall micro: 0.25284871150587274, F1 micro: 0.3812838701149932 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [1/10], Step: [2001/2499], Train_loss: 0.11032385820150375\n",
      "Precision macro: 0.21726406004590854, Recall macro: 0.10252180147018276, F1 macro: 0.11794329243031187 \n",
      "Precision micro: 0.8223946319983225, Recall micro: 0.45836498568339856, F1 micro: 0.588645829424787 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [2/10], Step: [1001/2499], Train_loss: 0.06934506922960282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision macro: 0.3416159999972966, Recall macro: 0.1545569755550397, F1 macro: 0.18014687074848001 \n",
      "Precision micro: 0.8161688086141021, Recall micro: 0.549231578332262, F1 micro: 0.656606937021901 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [2/10], Step: [2001/2499], Train_loss: 0.06783419903181494\n",
      "Precision macro: 0.3592409143457006, Recall macro: 0.1707717704229251, F1 macro: 0.20072529438250972 \n",
      "Precision micro: 0.8305707450444293, Recall micro: 0.5680476830479753, F1 micro: 0.6746712010271715 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [3/10], Step: [1001/2499], Train_loss: 0.05867591248638928\n",
      "Precision macro: 0.43617174711177886, Recall macro: 0.21329681896388664, F1 macro: 0.2497680082421527 \n",
      "Precision micro: 0.8323818585474152, Recall micro: 0.6134517618185006, F1 micro: 0.7063414634146341 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [3/10], Step: [2001/2499], Train_loss: 0.05874686063732952\n",
      "Precision macro: 0.44135220391550667, Recall macro: 0.20846369435731021, F1 macro: 0.24470418881779388 \n",
      "Precision micro: 0.8231010180109632, Recall micro: 0.6142114182200666, F1 micro: 0.7034768932168792 \n",
      "Epoch: [4/10], Step: [1001/2499], Train_loss: 0.053451984133571384\n",
      "Precision macro: 0.5204868105481988, Recall macro: 0.283861803984907, F1 macro: 0.3372265698966992 \n",
      "Precision micro: 0.8292969323352415, Recall micro: 0.6603167182843452, F1 micro: 0.7352223559647354 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [4/10], Step: [2001/2499], Train_loss: 0.05375679463520646\n",
      "Precision macro: 0.5032891512104544, Recall macro: 0.25425728601101805, F1 macro: 0.302155442494432 \n",
      "Precision micro: 0.8397734326505276, Recall micro: 0.6324431718576521, F1 micro: 0.7215092830238992 \n",
      "Epoch: [5/10], Step: [1001/2499], Train_loss: 0.05049484004825354\n",
      "Precision macro: 0.5445634286536618, Recall macro: 0.2940849118974822, F1 macro: 0.3511985092357443 \n",
      "Precision micro: 0.8435955056179776, Recall micro: 0.6580961841874599, F1 micro: 0.7393887667005877 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [5/10], Step: [2001/2499], Train_loss: 0.05054107809811831\n",
      "Precision macro: 0.5598907930859114, Recall macro: 0.3155179900406455, F1 macro: 0.37326611152524153 \n",
      "Precision micro: 0.8367735324257063, Recall micro: 0.6680301525156314, F1 micro: 0.7429406986190089 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [6/10], Step: [1001/2499], Train_loss: 0.048404280345886945\n",
      "Precision macro: 0.5579483526962883, Recall macro: 0.3401708264677647, F1 macro: 0.39961427443298964 \n",
      "Precision micro: 0.8402668196815378, Recall micro: 0.6845672880266465, F1 micro: 0.7544678795685074 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [6/10], Step: [2001/2499], Train_loss: 0.048502124965190886\n",
      "Precision macro: 0.5336212049188918, Recall macro: 0.3407803357502257, F1 macro: 0.3997342231080179 \n",
      "Precision micro: 0.8421547360809833, Recall micro: 0.6805937006953778, F1 micro: 0.7528035419965744 \n",
      "Epoch: [7/10], Step: [1001/2499], Train_loss: 0.04642679541930556\n",
      "Precision macro: 0.5833568102103706, Recall macro: 0.35384908501562884, F1 macro: 0.4113752497241307 \n",
      "Precision micro: 0.8435543540125213, Recall micro: 0.6928650733360603, F1 micro: 0.7608200455580865 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [7/10], Step: [2001/2499], Train_loss: 0.04695045426208526\n",
      "Precision macro: 0.58618332486257, Recall macro: 0.3604938240737414, F1 macro: 0.4185129111862452 \n",
      "Precision micro: 0.8424400933060012, Recall micro: 0.6964296149126395, F1 micro: 0.762507997440819 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [8/10], Step: [1001/2499], Train_loss: 0.045626067796722056\n",
      "Precision macro: 0.5791508753600032, Recall macro: 0.3794904020416947, F1 macro: 0.4328111885606811 \n",
      "Precision micro: 0.8365668060601906, Recall micro: 0.7130836206392801, F1 micro: 0.7699053627760253 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [8/10], Step: [2001/2499], Train_loss: 0.04561785587854683\n",
      "Precision macro: 0.5794842135550171, Recall macro: 0.37262290493791245, F1 macro: 0.4283560013331391 \n",
      "Precision micro: 0.8426887454392366, Recall micro: 0.7018056448314147, F1 micro: 0.7658217758648175 \n",
      "Epoch: [9/10], Step: [1001/2499], Train_loss: 0.044482066182419656\n",
      "Precision macro: 0.5841517420134955, Recall macro: 0.3904940084287467, F1 macro: 0.4433589558304382 \n",
      "Precision micro: 0.837574186506583, Recall micro: 0.7174662537252381, F1 micro: 0.7728817827017499 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [9/10], Step: [2001/2499], Train_loss: 0.0447403893135488\n",
      "Precision macro: 0.5845924145985258, Recall macro: 0.3871703431712479, F1 macro: 0.44212135597785945 \n",
      "Precision micro: 0.8380926356059571, Recall micro: 0.7168819026471104, F1 micro: 0.772763062580706 \n",
      "Epoch: [10/10], Step: [1001/2499], Train_loss: 0.04423460271768272\n",
      "Precision macro: 0.5939822913065267, Recall macro: 0.3977876899453927, F1 macro: 0.4521323994022612 \n",
      "Precision micro: 0.8460422710319104, Recall micro: 0.7157716355986676, F1 micro: 0.7754740274128706 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [10/10], Step: [2001/2499], Train_loss: 0.04408727825526148\n",
      "Precision macro: 0.5934035816245583, Recall macro: 0.40233988363162326, F1 macro: 0.45276119237480883 \n",
      "Precision micro: 0.8396931015752308, Recall micro: 0.722666978320575, F1 micro: 0.776797211142866 \n",
      "Model Saved\n",
      "\n",
      "\n",
      " {'optimizer': 'SWA', 'num_hidden': 2, 'dim_hidden': 120, 'dropout_rate': 0.2, 'learning_rate': 0.01, 'num_epochs': 10}\n",
      "Epoch: [1/10], Step: [1001/2499], Train_loss: 0.07734234580211341\n",
      "Precision macro: 0.47728798245700743, Recall macro: 0.26232780708576664, F1 macro: 0.30981475876508946 \n",
      "Precision micro: 0.8238442099004014, Recall micro: 0.6476947349967861, F1 micro: 0.7252265515097982 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [1/10], Step: [2001/2499], Train_loss: 0.06352537182345987\n",
      "Precision macro: 0.5877715584965816, Recall macro: 0.3873893923185069, F1 macro: 0.44160125395841326 \n",
      "Precision micro: 0.8441161849300476, Recall micro: 0.6945596914626307, F1 micro: 0.7620696287747643 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [2/10], Step: [1001/2499], Train_loss: 0.0447158284932375\n",
      "Precision macro: 0.5875056931701447, Recall macro: 0.4220623014308263, F1 macro: 0.46874863149209484 \n",
      "Precision micro: 0.8372578040904198, Recall micro: 0.7272249167299714, F1 micro: 0.778371954842543 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [2/10], Step: [2001/2499], Train_loss: 0.04465228732954711\n",
      "Precision macro: 0.621917583848242, Recall macro: 0.4351091127481821, F1 macro: 0.4800920273579816 \n",
      "Precision micro: 0.8350357166700046, Recall micro: 0.7309063285221761, F1 micro: 0.7795089118783497 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [3/10], Step: [1001/2499], Train_loss: 0.04216448395512998\n",
      "Precision macro: 0.6587593043791061, Recall macro: 0.45723985971388165, F1 macro: 0.5173075684890954 \n",
      "Precision micro: 0.8518209619127051, Recall micro: 0.7161806813533571, F1 micro: 0.7781340274911908 \n",
      "Epoch: [3/10], Step: [2001/2499], Train_loss: 0.04172538932412863\n",
      "Precision macro: 0.6785252792449648, Recall macro: 0.45395745811558386, F1 macro: 0.5120199839873759 \n",
      "Precision micro: 0.8583251507925376, Recall micro: 0.7151288494127271, F1 micro: 0.7802110229192567 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [4/10], Step: [1001/2499], Train_loss: 0.04138456333987415\n",
      "Precision macro: 0.6436276529826039, Recall macro: 0.495595526442545, F1 macro: 0.5305685586252163 \n",
      "Precision micro: 0.8126923550412409, Recall micro: 0.771518728452054, F1 micro: 0.7915704907221439 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [4/10], Step: [2001/2499], Train_loss: 0.04081781239248812\n",
      "Precision macro: 0.7020630803640519, Recall macro: 0.4941806301056299, F1 macro: 0.546652508024615 \n",
      "Precision micro: 0.8245797672557108, Recall micro: 0.7825629638286683, F1 micro: 0.8030221262817054 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [5/10], Step: [1001/2499], Train_loss: 0.03961471828073263\n",
      "Precision macro: 0.6847754317983804, Recall macro: 0.46744332349908435, F1 macro: 0.5243656983024628 \n",
      "Precision micro: 0.8123078814705521, Recall micro: 0.7721030795301818, F1 micro: 0.7916953773330537 \n",
      "Epoch: [5/10], Step: [2001/2499], Train_loss: 0.039595645237714056\n",
      "Precision macro: 0.6883752999237608, Recall macro: 0.4884309873164103, F1 macro: 0.5409467154218723 \n",
      "Precision micro: 0.8261248366419814, Recall micro: 0.7757260562145737, F1 micro: 0.8001326020131396 \n",
      "Epoch: [6/10], Step: [1001/2499], Train_loss: 0.038774768771603706\n",
      "Precision macro: 0.6806801508321187, Recall macro: 0.47840344011791314, F1 macro: 0.5304527438804878 \n",
      "Precision micro: 0.8270638727594042, Recall micro: 0.7657336527785894, F1 micro: 0.7952180113481203 \n",
      "Epoch: [6/10], Step: [2001/2499], Train_loss: 0.03869219935964793\n",
      "Precision macro: 0.7073781513848616, Recall macro: 0.5104123837453343, F1 macro: 0.5657667311569446 \n",
      "Precision micro: 0.8441683212707359, Recall micro: 0.7701747209723602, F1 micro: 0.8054757685021084 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Saved\n",
      "\n",
      "Epoch: [7/10], Step: [1001/2499], Train_loss: 0.03881788587197661\n",
      "Precision macro: 0.7141912485768067, Recall macro: 0.494685846873231, F1 macro: 0.5624084684537679 \n",
      "Precision micro: 0.8605500792720755, Recall micro: 0.7295038859346695, F1 micro: 0.7896268184693233 \n",
      "Epoch: [7/10], Step: [2001/2499], Train_loss: 0.03877784068416804\n",
      "Precision macro: 0.682189289855683, Recall macro: 0.5376806839471797, F1 macro: 0.5801318519448745 \n",
      "Precision micro: 0.8197691982357561, Recall micro: 0.7928475428037165, F1 micro: 0.8060836501901142 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [8/10], Step: [1001/2499], Train_loss: 0.03782598140835762\n",
      "Precision macro: 0.755464903756047, Recall macro: 0.5092463763480808, F1 macro: 0.5757316625977802 \n",
      "Precision micro: 0.8496861579121242, Recall micro: 0.7514754864722726, F1 micro: 0.7975688414785412 \n",
      "Epoch: [8/10], Step: [2001/2499], Train_loss: 0.03786924143135548\n",
      "Precision macro: 0.7270303946167099, Recall macro: 0.5439452082314756, F1 macro: 0.6004014305173666 \n",
      "Precision micro: 0.8220762788455745, Recall micro: 0.7972886109974873, F1 micro: 0.8094927321269653 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [9/10], Step: [1001/2499], Train_loss: 0.03794107466563582\n",
      "Precision macro: 0.7233390823299699, Recall macro: 0.5008496730232613, F1 macro: 0.5632322210042262 \n",
      "Precision micro: 0.842289794097023, Recall micro: 0.7721030795301818, F1 micro: 0.805670731707317 \n",
      "Epoch: [9/10], Step: [2001/2499], Train_loss: 0.03777898093219847\n",
      "Precision macro: 0.7307701733594929, Recall macro: 0.5376884662896652, F1 macro: 0.5961465367244388 \n",
      "Precision micro: 0.84402908905333, Recall micro: 0.7731549114708116, F1 micro: 0.8070389459879839 \n",
      "Epoch: [10/10], Step: [1001/2499], Train_loss: 0.03729017952643335\n",
      "Precision macro: 0.7146020431920127, Recall macro: 0.5472008325318813, F1 macro: 0.5989298181724059 \n",
      "Precision micro: 0.8318754265152926, Recall micro: 0.7835563606614854, F1 micro: 0.806993259508907 \n",
      "Epoch: [10/10], Step: [2001/2499], Train_loss: 0.03721572226472199\n",
      "Precision macro: 0.7465419441211282, Recall macro: 0.536790706236144, F1 macro: 0.5984859338680185 \n",
      "Precision micro: 0.8294908149426704, Recall micro: 0.7863028107286858, F1 micro: 0.8073196340182991 \n",
      "\n",
      " {'optimizer': 'SWA', 'num_hidden': 3, 'dim_hidden': 40, 'dropout_rate': 0, 'learning_rate': 0.001, 'num_epochs': 10}\n",
      "Epoch: [1/10], Step: [1001/2499], Train_loss: 0.14789174176752568\n",
      "Precision macro: 0.05522251665394585, Recall macro: 0.0389344342332233, F1 macro: 0.045449378306628166 \n",
      "Precision micro: 0.7622441940676018, Recall micro: 0.19371238239934552, F1 micro: 0.3089180877830584 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [1/10], Step: [2001/2499], Train_loss: 0.12155672757327557\n",
      "Precision macro: 0.15281827400452516, Recall macro: 0.07488184351681168, F1 macro: 0.08234847294897817 \n",
      "Precision micro: 0.7903079121735741, Recall micro: 0.35546076082510375, F1 micro: 0.490366787585651 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [2/10], Step: [1001/2499], Train_loss: 0.08039278985932469\n",
      "Precision macro: 0.19742188746102887, Recall macro: 0.11375058354347503, F1 macro: 0.13185022562446214 \n",
      "Precision micro: 0.8351937657961247, Recall micro: 0.46344884006310993, F1 micro: 0.5961140967341877 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [2/10], Step: [2001/2499], Train_loss: 0.07849759459123015\n",
      "Precision macro: 0.24259706433337677, Recall macro: 0.12024103627428948, F1 macro: 0.13616842937467571 \n",
      "Precision micro: 0.8292659306604687, Recall micro: 0.5003798282007831, F1 micro: 0.624148110353876 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [3/10], Step: [1001/2499], Train_loss: 0.06833370584249497\n",
      "Precision macro: 0.3092367985997467, Recall macro: 0.14229448159748667, F1 macro: 0.1589135258807374 \n",
      "Precision micro: 0.8169538488180795, Recall micro: 0.5513352422135219, F1 micro: 0.6583629893238435 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [3/10], Step: [2001/2499], Train_loss: 0.06831693127751351\n",
      "Precision macro: 0.2959639073219772, Recall macro: 0.1517049476182324, F1 macro: 0.17350638040414168 \n",
      "Precision micro: 0.8258920724204606, Recall micro: 0.5491147081166364, F1 micro: 0.659646906040504 \n",
      "Model Saved\n",
      "\n",
      "Epoch: [4/10], Step: [1001/2499], Train_loss: 0.0628766146376729\n",
      "Precision macro: 0.34714822948432633, Recall macro: 0.1852771820679111, F1 macro: 0.2170290735428474 \n",
      "Precision micro: 0.8313584779706275, Recall micro: 0.5821889791386665, F1 micro: 0.6848128673059078 \n",
      "Model Saved\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-cb0862ede5d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;31m# train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mmodel_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"_\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mmetrics_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwiki_loaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-36-4fae397f4911>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(wiki_loaders, model, criterion, optimizer, num_epochs, device, model_name)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mrunnin_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwiki_loaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"train\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mdata_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/topic-modeling/topic-modeling/baseline/preprocess.py\u001b[0m in \u001b[0;36mpad_collate_fn\u001b[0;34m(batch, word_to_index)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mpad_token\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_to_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'<pad>'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m     \u001b[0minput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_list_of_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_token\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m     \u001b[0mlength_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mtarget_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/topic-modeling/topic-modeling/baseline/preprocess.py\u001b[0m in \u001b[0;36mpad_list_of_tensors\u001b[0;34m(list_of_tensors, pad_token)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mpadded_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpad_token\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_length\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mpadded_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mpadded_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpadded_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpadded_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# results_df = pd.DataFrame(columns=[\n",
    "#     \"optimizer\", \"num_hidden\", \"dim_hidden\", \"dropout_rate\", \"learning_rate\", \"num_epochs\", \n",
    "#     'precision_macro', 'recall_macro', 'f1_macro', \n",
    "#     'precision_micro', 'recall_micro', 'f1_micro'\n",
    "# ])\n",
    "\n",
    "\n",
    "for num_hidden, dim_hidden, dropout_rate, lr in itertools.product(range_num_hidden, range_dim_hidden, range_dropout, range_lr):\n",
    "    # model\n",
    "    options = {\n",
    "        \"VOCAB_SIZE\": len(index_to_word),\n",
    "        \"dim_e\": weights_matrix_ve.shape[1],\n",
    "        \"pretrained_embeddings\": weights_matrix_ve,\n",
    "        \"num_layers\": num_hidden,\n",
    "        \"num_classes\": len(classes),\n",
    "        \"mid_features\": dim_hidden,\n",
    "        \"dropout_rate\": dropout_rate,\n",
    "        \"activation\": nn.ReLU()\n",
    "    }\n",
    "    num_epochs = 10\n",
    "    \n",
    "    result = {\n",
    "        \"optimizer\": \"SWA\", \n",
    "        \"num_hidden\": num_hidden,\n",
    "        \"dim_hidden\": dim_hidden,\n",
    "        \"dropout_rate\": dropout_rate,\n",
    "        \"learning_rate\": lr,\n",
    "        \"num_epochs\": num_epochs\n",
    "    }\n",
    "    print(\"\\n\", result)\n",
    "    \n",
    "    model = FinalModel(options)\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        model = model.to(device)\n",
    "    \n",
    "    # Criterion and Optimizer\n",
    "    criterion = torch.nn.BCEWithLogitsLoss()\n",
    "    # optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    base_opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    optimizer = SWA(base_opt) \n",
    "    \n",
    "    # train the model\n",
    "    model_name = \"_\".join([str(key) + \"_\" + str(value) for key, value in result.items()])\n",
    "    metrics_dict = train_model(wiki_loaders, model, criterion, optimizer, num_epochs=num_epochs, model_name=model_name)\n",
    "    result.update(metrics_dict)\n",
    "    \n",
    "    results_df = results_df.append(result, ignore_index=True)\n",
    "    results_df.to_csv(\"results/results_tuning_2_3_layers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results_df.to_csv(\"results_tuning.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

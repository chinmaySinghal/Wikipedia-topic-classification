{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import wiki_dataset\n",
    "\n",
    "import importlib\n",
    "importlib.reload(wiki_dataset)\n",
    "\n",
    "\n",
    "from preprocess import pad_collate_fn\n",
    "\n",
    "import training\n",
    "importlib.reload(training)\n",
    "from training import get_train_val_loader, ClassifierLearner\n",
    "\n",
    "import model\n",
    "\n",
    "from model import FinalModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english vocab size is: 741334\n",
      "russian vocab size is: 858845\n",
      "hindi vocab size is: 441314\n",
      "Order: dict_keys(['english', 'russian', 'hindi'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 151/30000 [00:00<00:19, 1497.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined train size: 30000 \n",
      "Combined val size: 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [00:11<00:00, 2531.09it/s]\n",
      "100%|██████████| 10000/10000 [00:03<00:00, 2618.55it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 2619.19it/s]\n",
      "100%|██████████| 30000/30000 [00:08<00:00, 3623.46it/s]\n",
      "100%|██████████| 10000/10000 [00:02<00:00, 3497.81it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 3590.54it/s]\n",
      "100%|██████████| 30000/30000 [00:03<00:00, 9730.70it/s] \n",
      "100%|██████████| 10000/10000 [00:01<00:00, 9382.64it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 10460.03it/s]\n",
      "100%|██████████| 30000/30000 [00:11<00:00, 2705.63it/s]\n",
      "100%|██████████| 3000/3000 [00:00<00:00, 3615.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings matrix shape: torch.Size([2041495, 300]), \n",
      "Vocab size: 2041495\n"
     ]
    }
   ],
   "source": [
    "(index_to_word, word_to_index,\n",
    "     dict_wiki_tensor_dataset,\n",
    "     weights_matrix_ve, classes) = wiki_dataset.get_mixed_datasets(LANGUAGES_LIST=[\"english\", \"russian\", \"hindi\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['monolingual_train_en', 'multilingual_train_en', 'val_en', 'monolingual_train_ru', 'multilingual_train_ru', 'val_ru', 'monolingual_train_hi', 'multilingual_train_hi', 'val_hi', 'train', 'val'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_wiki_tensor_dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " {'optimizer': 'Adam', 'num_hidden': 2, 'dim_hidden': 150, 'dropout_rate': 0.2, 'learning_rate': 0.01, 'num_epochs': 15}\n"
     ]
    }
   ],
   "source": [
    "SAVE_MODEL = False\n",
    "\n",
    "batch_size = 8\n",
    "lr = 0.01\n",
    "num_epochs = 15\n",
    "\n",
    "options = {\n",
    "    \"VOCAB_SIZE\": len(index_to_word),\n",
    "    \"dim_e\": weights_matrix_ve.shape[1],\n",
    "    \"pretrained_embeddings\": weights_matrix_ve,\n",
    "    \"num_layers\": 2,\n",
    "    \"num_classes\": len(classes),\n",
    "    \"mid_features\": 150,\n",
    "    \"dropout_rate\": 0.2,\n",
    "    \"activation\": nn.ReLU(),\n",
    "}\n",
    "    \n",
    "result = {\n",
    "    \"optimizer\": \"Adam\", \n",
    "    \"num_hidden\": options[\"num_layers\"],\n",
    "    \"dim_hidden\": options[\"mid_features\"],\n",
    "    \"dropout_rate\": options[\"dropout_rate\"],\n",
    "    \"learning_rate\": lr,\n",
    "    \"num_epochs\": num_epochs\n",
    "}\n",
    "\n",
    "\n",
    "print(\"\\n\", result)\n",
    "model_name = \"mixed_en_hi_ru_\" + \"_\".join([str(key) + \"_\" + str(value) for key, value in result.items()])\n",
    "\n",
    "learner = ClassifierLearner(options, model_name, device=device)\n",
    "\n",
    "\n",
    "val_keys = [\"val_en\", \"val_ru\", \"val_hi\", \"val\"]\n",
    "train_loader, dict_val_loader = get_train_val_loader(\n",
    "    dict_wiki_tensor_dataset[\"train\"], \n",
    "    [dict_wiki_tensor_dataset[key] for key in val_keys], \n",
    "    collate_fn=partial(pad_collate_fn, pad_token=word_to_index[\"<pad>\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_val_loader = {\n",
    "   key : val_loader \n",
    "   for key, val_loader in zip(val_keys, dict_val_loader)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "learner.set_loaders(train_loader, dict_val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 epoch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/mz2476/miniconda3/envs/my_base/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision macro: 0.5616, Recall macro: 0.3511, F1 macro: 0.4065 \n",
      "Precision micro: 0.8054, Recall micro: 0.5656, F1 micro: 0.6646 \n",
      "1 epoch\n",
      "Precision macro: 0.6751, Recall macro: 0.4115, F1 macro: 0.478 \n",
      "Precision micro: 0.8034, Recall micro: 0.6141, F1 micro: 0.6961 \n",
      "2 epoch\n",
      "Precision macro: 0.7063, Recall macro: 0.4547, F1 macro: 0.5222 \n",
      "Precision micro: 0.8079, Recall micro: 0.6146, F1 micro: 0.6981 \n",
      "3 epoch\n",
      "Precision macro: 0.7177, Recall macro: 0.482, F1 macro: 0.5516 \n",
      "Precision micro: 0.8094, Recall micro: 0.6348, F1 micro: 0.7116 \n",
      "4 epoch\n",
      "Precision macro: 0.7161, Recall macro: 0.4426, F1 macro: 0.5251 \n",
      "Precision micro: 0.8354, Recall micro: 0.597, F1 micro: 0.6963 \n",
      "5 epoch\n",
      "Precision macro: 0.6904, Recall macro: 0.4862, F1 macro: 0.5498 \n",
      "Precision micro: 0.7993, Recall micro: 0.6445, F1 micro: 0.7136 \n",
      "6 epoch\n",
      "Precision macro: 0.7285, Recall macro: 0.5163, F1 macro: 0.5818 \n",
      "Precision micro: 0.8188, Recall micro: 0.6367, F1 micro: 0.7164 \n",
      "7 epoch\n",
      "Precision macro: 0.7588, Recall macro: 0.4931, F1 macro: 0.5736 \n",
      "Precision micro: 0.7763, Recall micro: 0.65, F1 micro: 0.7076 \n",
      "8 epoch\n",
      "Precision macro: 0.7359, Recall macro: 0.525, F1 macro: 0.5897 \n",
      "Precision micro: 0.8169, Recall micro: 0.6527, F1 micro: 0.7256 \n",
      "9 epoch\n",
      "Precision macro: 0.7235, Recall macro: 0.5488, F1 macro: 0.6025 \n",
      "Precision micro: 0.7964, Recall micro: 0.6746, F1 micro: 0.7305 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'precision_macro': 0.7235292772710287,\n",
       "  'recall_macro': 0.548840485433408,\n",
       "  'f1_macro': 0.6025189506395687,\n",
       "  'precision_micro': 0.7964105440269209,\n",
       "  'recall_micro': 0.6745843230403801,\n",
       "  'f1_micro': 0.7304526748971193},\n",
       " 9)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.train_model(num_epochs=10, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import results_analysis\n",
    "importlib.reload(results_analysis)\n",
    "from results_analysis import plot_errorbars_by_model, get_mean_std_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_to_mean_std = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'monolingual_train_en': return TextData(self.input_tensors[idx], self.input_len[idx], self.target_tensors[idx]),\n",
       " 'multilingual_train_en': return TextData(self.input_tensors[idx], self.input_len[idx], self.target_tensors[idx]),\n",
       " 'val_en': return TextData(self.input_tensors[idx], self.input_len[idx], self.target_tensors[idx]),\n",
       " 'monolingual_train_ru': return TextData(self.input_tensors[idx], self.input_len[idx], self.target_tensors[idx]),\n",
       " 'multilingual_train_ru': return TextData(self.input_tensors[idx], self.input_len[idx], self.target_tensors[idx]),\n",
       " 'val_ru': return TextData(self.input_tensors[idx], self.input_len[idx], self.target_tensors[idx]),\n",
       " 'train': return TextData(self.input_tensors[idx], self.input_len[idx], self.target_tensors[idx]),\n",
       " 'val': return TextData(self.input_tensors[idx], self.input_len[idx], self.target_tensors[idx])}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_wiki_tensor_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/mz2476/miniconda3/envs/my_base/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'val_hi'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-b62d173d5024>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m model_to_mean_std[model_name] = get_mean_std_k(\n\u001b[1;32m      5\u001b[0m     \u001b[0mlearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_wiki_tensor_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict_wiki_tensor_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     metric_name=metric_name)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mpath_to_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"results/{metric_name}_scores/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/topic-modeling/topic-modeling/baseline/results_analysis.py\u001b[0m in \u001b[0;36mget_mean_std_k\u001b[0;34m(learner, num_splits, dict_wiki_tensor_dataset, metric_name, keys)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_wiki_tensor_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mcur_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_test_metrics_kfold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_splits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mmean_k\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'val_hi'"
     ]
    }
   ],
   "source": [
    "model_name = \"en_ru\"\n",
    "metric_name='f1_micro'\n",
    "\n",
    "model_to_mean_std[model_name] = get_mean_std_k(\n",
    "    learner, num_splits=5, dict_wiki_tensor_dataset=dict_wiki_tensor_dataset,\n",
    "    metric_name=metric_name)\n",
    "\n",
    "path_to_scores = Path(f\"results/{metric_name}_scores/\")\n",
    "path_to_scores.mkdir(exist_ok=True)\n",
    "\n",
    "torch.save({model_name : model_to_mean_std[model_name]},\n",
    "           path_to_scores/f\"{model_name}_mean_std.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model_name in model_to_mean_std.keys():\n",
    "#     torch.save({model_name : model_to_mean_std[model_name]}, f\"results/f1_micro_scores/{model_name}_mean_std.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load\n",
    "model_to_mean_std = {}\n",
    "path_to_scores = Path(f\"results/{metric_name}_scores/\")\n",
    "[model_to_mean_std.update(torch.load(fname)) for fname in path_to_scores.iterdir()]\n",
    "\n",
    "mean_mk = np.array([mean_std[0] for mean_std in model_to_mean_std.values()])\n",
    "std_mk  = np.array([mean_std[1] for mean_std in model_to_mean_std.values()])\n",
    "\n",
    "axis = plot_errorbars_by_model(np.array(mean_mk), np.array(std_mk), labels_m=model_to_mean_std.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/mz2476/miniconda3/envs/my_base/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/scratch/mz2476/miniconda3/envs/my_base/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>precision_micro</th>\n",
       "      <th>recall_micro</th>\n",
       "      <th>f1_micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.601943</td>\n",
       "      <td>0.474778</td>\n",
       "      <td>0.501424</td>\n",
       "      <td>0.806897</td>\n",
       "      <td>0.659155</td>\n",
       "      <td>0.725581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.581520</td>\n",
       "      <td>0.475961</td>\n",
       "      <td>0.501708</td>\n",
       "      <td>0.798276</td>\n",
       "      <td>0.685926</td>\n",
       "      <td>0.737849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.601665</td>\n",
       "      <td>0.457821</td>\n",
       "      <td>0.497679</td>\n",
       "      <td>0.795041</td>\n",
       "      <td>0.668056</td>\n",
       "      <td>0.726038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision_macro  recall_macro  f1_macro  precision_micro  recall_micro  \\\n",
       "0         0.601943      0.474778  0.501424         0.806897      0.659155   \n",
       "1         0.581520      0.475961  0.501708         0.798276      0.685926   \n",
       "2         0.601665      0.457821  0.497679         0.795041      0.668056   \n",
       "\n",
       "   f1_micro  \n",
       "0  0.725581  \n",
       "1  0.737849  \n",
       "2  0.726038  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0,  5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80,\n",
       "        85, 90, 95]),\n",
       " array([ 1,  6, 11, 16, 21, 26, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81,\n",
       "        86, 91, 96]),\n",
       " array([ 2,  7, 12, 17, 22, 27, 32, 37, 42, 47, 52, 57, 62, 67, 72, 77, 82,\n",
       "        87, 92, 97]),\n",
       " array([ 3,  8, 13, 18, 23, 28, 33, 38, 43, 48, 53, 58, 63, 68, 73, 78, 83,\n",
       "        88, 93, 98]),\n",
       " array([ 4,  9, 14, 19, 24, 29, 34, 39, 44, 49, 54, 59, 64, 69, 74, 79, 84,\n",
       "        89, 94, 99])]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.arange(start, 100, num_splits) for start in range(num_splits)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/mz2476/miniconda3/envs/my_base/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/scratch/mz2476/miniconda3/envs/my_base/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>precision_micro</th>\n",
       "      <th>recall_micro</th>\n",
       "      <th>f1_micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.651972</td>\n",
       "      <td>0.482795</td>\n",
       "      <td>0.534985</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.680304</td>\n",
       "      <td>0.734841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.651972</td>\n",
       "      <td>0.482795</td>\n",
       "      <td>0.534985</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.680304</td>\n",
       "      <td>0.734841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision_macro  recall_macro  f1_macro  precision_micro  recall_micro  \\\n",
       "0         0.651972      0.482795  0.534985         0.798883      0.680304   \n",
       "1         0.651972      0.482795  0.534985         0.798883      0.680304   \n",
       "\n",
       "   f1_micro  \n",
       "0  0.734841  \n",
       "1  0.734841  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = np.arange(500)\n",
    "indices = np.arange(500, 1000)\n",
    "\n",
    "dict_of_metrics = learner.get_test_metrics(\n",
    "    data.Subset(learner.val_loader.dataset, indices), device=learner.device)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame([dict_of_metrics, dict_of_metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "model_name = \"mixed_en_hi_ru_\" + \"_\".join([str(key) + \"_\" + str(value) for key, value in result.items()])\n",
    "print(model_name)\n",
    "metrics_dict = train_model(train_loader, val_loader, model, criterion, optimizer, options, device,\n",
    "                num_epochs=10, model_name=\"model\", save_model=False)\n",
    "result.update(metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.param_groups[0][\"lr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " {'optimizer': 'Adam', 'num_hidden': 2, 'dim_hidden': 150, 'dropout_rate': 0.2, 'learning_rate': 0.01, 'num_epochs': 15}\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.28 GiB (GPU 0; 7.93 GiB total capacity; 6.85 GiB already allocated; 626.56 MiB free; 6.49 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-bf531e03e2ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# Criterion and Optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mz2476/miniconda3/envs/my_base/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_backward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mz2476/miniconda3/envs/my_base/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mz2476/miniconda3/envs/my_base/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mz2476/miniconda3/envs/my_base/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    228\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mz2476/miniconda3/envs/my_base/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.28 GiB (GPU 0; 7.93 GiB total capacity; 6.85 GiB already allocated; 626.56 MiB free; 6.49 MiB cached)"
     ]
    }
   ],
   "source": [
    "# loaders = create_data_loaders_for_model(wiki_loaders[\"train\"], wiki_loaders[\"val\"])\n",
    "# # create dataloader\n",
    "# wiki_loaders = {}\n",
    "\n",
    "\n",
    "# for split, wiki_dataset in dict_wiki_tensor_dataset.items():\n",
    "#     wiki_loaders[split] = DataLoader(\n",
    "#         wiki_dataset, \n",
    "#         batch_size=batch_size, \n",
    "#         shuffle=True, \n",
    "#         collate_fn=partial(pad_collate_fn, word_to_index=word_to_index)\n",
    "#     )\n",
    "\n",
    "\n",
    "# train_model(\n",
    "#     wiki_loaders, model, criterion, optimizer, options=options, num_epochs=num_epochs, \n",
    "#     model_name=model_name, save_model=SAVE_MODEL\n",
    "# )\n",
    "\n",
    "# results_df = results_df.append(result, ignore_index=True)\n",
    "#     results_df.to_csv(\"results/results_tuning_2_3_layers_maxlen_500.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

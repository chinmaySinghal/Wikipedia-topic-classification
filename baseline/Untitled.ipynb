{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import partial\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import wiki_dataset\n",
    "\n",
    "import importlib\n",
    "importlib.reload(wiki_dataset)\n",
    "\n",
    "\n",
    "from preprocess import pad_collate_fn\n",
    "\n",
    "import training\n",
    "importlib.reload(training)\n",
    "from training import get_train_val_loader, ClassifierLearner\n",
    "\n",
    "import model\n",
    "\n",
    "from model import FinalModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda:0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "english vocab size is: 741334\n",
      "russian vocab size is: 858845\n",
      "Order: dict_keys(['english', 'russian'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 183/30000 [00:00<00:16, 1829.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined train size: 20000 \n",
      "Combined val size: 2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30000/30000 [00:16<00:00, 1819.41it/s]\n",
      "100%|██████████| 10000/10000 [00:04<00:00, 2345.81it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 2523.85it/s]\n",
      "100%|██████████| 30000/30000 [00:08<00:00, 3519.95it/s]\n",
      "100%|██████████| 10000/10000 [00:02<00:00, 3460.02it/s]\n",
      "100%|██████████| 1000/1000 [00:00<00:00, 3562.10it/s]\n",
      "100%|██████████| 20000/20000 [00:11<00:00, 1721.92it/s]\n",
      "100%|██████████| 2000/2000 [00:00<00:00, 2951.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings matrix shape: torch.Size([1600181, 300]), \n",
      "Vocab size: 1600181\n"
     ]
    }
   ],
   "source": [
    "(index_to_word, word_to_index,\n",
    "     dict_wiki_tensor_dataset,\n",
    "     weights_matrix_ve, classes) = wiki_dataset.get_mixed_datasets(LANGUAGES_LIST=[\"english\", \"russian\", \"hindi\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['monolingual_train_en', 'multilingual_train_en', 'val_en', 'monolingual_train_ru', 'multilingual_train_ru', 'val_ru', 'train', 'val'])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_wiki_tensor_dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " {'optimizer': 'Adam', 'num_hidden': 2, 'dim_hidden': 150, 'dropout_rate': 0.2, 'learning_rate': 0.01, 'num_epochs': 15}\n"
     ]
    }
   ],
   "source": [
    "SAVE_MODEL = False\n",
    "\n",
    "batch_size = 8\n",
    "lr = 0.01\n",
    "num_epochs = 15\n",
    "\n",
    "options = {\n",
    "    \"VOCAB_SIZE\": len(index_to_word),\n",
    "    \"dim_e\": weights_matrix_ve.shape[1],\n",
    "    \"pretrained_embeddings\": weights_matrix_ve,\n",
    "    \"num_layers\": 2,\n",
    "    \"num_classes\": len(classes),\n",
    "    \"mid_features\": 150,\n",
    "    \"dropout_rate\": 0.2,\n",
    "    \"activation\": nn.ReLU(),\n",
    "}\n",
    "    \n",
    "result = {\n",
    "    \"optimizer\": \"Adam\", \n",
    "    \"num_hidden\": options[\"num_layers\"],\n",
    "    \"dim_hidden\": options[\"mid_features\"],\n",
    "    \"dropout_rate\": options[\"dropout_rate\"],\n",
    "    \"learning_rate\": lr,\n",
    "    \"num_epochs\": num_epochs\n",
    "}\n",
    "\n",
    "\n",
    "print(\"\\n\", result)\n",
    "model_name = \"mixed_en_hi_ru_\" + \"_\".join([str(key) + \"_\" + str(value) for key, value in result.items()])\n",
    "\n",
    "learner = ClassifierLearner(options, model_name, device=device)\n",
    "\n",
    "train_loader, val_loader = get_train_val_loader(\n",
    "    dict_wiki_tensor_dataset[\"train\"], dict_wiki_tensor_dataset[\"val\"], \n",
    "    collate_fn=partial(pad_collate_fn, pad_token=word_to_index[\"<pad>\"])\n",
    ")\n",
    "learner.set_loaders(train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 epoch\n",
      "Epoch: [1/10], Step: [101/2500], Train_loss: 0.051098767798393965\n",
      "Epoch: [1/10], Step: [201/2500], Train_loss: 0.05297128468751908\n",
      "Epoch: [1/10], Step: [301/2500], Train_loss: 0.052081931177526714\n",
      "Epoch: [1/10], Step: [401/2500], Train_loss: 0.05274732842110098\n",
      "Epoch: [1/10], Step: [501/2500], Train_loss: 0.05261435093544423\n",
      "Epoch: [1/10], Step: [601/2500], Train_loss: 0.052777229566127064\n",
      "Epoch: [1/10], Step: [701/2500], Train_loss: 0.052392029876687694\n",
      "Epoch: [1/10], Step: [801/2500], Train_loss: 0.052475630169501526\n",
      "Precision macro: 0.7629, Recall macro: 0.5558, F1 macro: 0.6178 \n",
      "Precision micro: 0.8093, Recall micro: 0.6874, F1 micro: 0.7434 \n",
      "Epoch: [1/10], Step: [901/2500], Train_loss: 0.052535915191595756\n",
      "Epoch: [1/10], Step: [1001/2500], Train_loss: 0.052455345075577496\n",
      "Epoch: [1/10], Step: [1101/2500], Train_loss: 0.05241974746639078\n",
      "Epoch: [1/10], Step: [1201/2500], Train_loss: 0.05260625978155682\n",
      "Epoch: [1/10], Step: [1301/2500], Train_loss: 0.052561224875971674\n",
      "Epoch: [1/10], Step: [1401/2500], Train_loss: 0.052594231122971645\n",
      "Epoch: [1/10], Step: [1501/2500], Train_loss: 0.0529528561749806\n",
      "Epoch: [1/10], Step: [1601/2500], Train_loss: 0.052865517152822575\n",
      "Precision macro: 0.7456, Recall macro: 0.5392, F1 macro: 0.6027 \n",
      "Precision micro: 0.8235, Recall micro: 0.6796, F1 micro: 0.7447 \n",
      "Epoch: [1/10], Step: [1701/2500], Train_loss: 0.0527115002970266\n",
      "Epoch: [1/10], Step: [1801/2500], Train_loss: 0.052652923125877146\n",
      "Epoch: [1/10], Step: [1901/2500], Train_loss: 0.05262494782574083\n",
      "Epoch: [1/10], Step: [2001/2500], Train_loss: 0.05250530151929706\n",
      "Epoch: [1/10], Step: [2101/2500], Train_loss: 0.052573654748322\n",
      "Epoch: [1/10], Step: [2201/2500], Train_loss: 0.05264608595350927\n",
      "Epoch: [1/10], Step: [2301/2500], Train_loss: 0.052806028472664565\n",
      "Epoch: [1/10], Step: [2401/2500], Train_loss: 0.05283874083465586\n",
      "Precision macro: 0.739, Recall macro: 0.586, F1 macro: 0.6288 \n",
      "Precision micro: 0.7901, Recall micro: 0.7152, F1 micro: 0.7508 \n",
      "1 epoch\n",
      "Epoch: [2/10], Step: [101/2500], Train_loss: 0.04962062795646489\n",
      "Epoch: [2/10], Step: [201/2500], Train_loss: 0.050971579034812746\n",
      "Epoch: [2/10], Step: [301/2500], Train_loss: 0.050718496941650905\n",
      "Epoch: [2/10], Step: [401/2500], Train_loss: 0.050888535613194105\n",
      "Epoch: [2/10], Step: [501/2500], Train_loss: 0.05112729102559388\n",
      "Epoch: [2/10], Step: [601/2500], Train_loss: 0.05099296488488714\n",
      "Epoch: [2/10], Step: [701/2500], Train_loss: 0.05120897363605244\n",
      "Epoch: [2/10], Step: [801/2500], Train_loss: 0.0515210264432244\n",
      "Precision macro: 0.7469, Recall macro: 0.5933, F1 macro: 0.6366 \n",
      "Precision micro: 0.8154, Recall micro: 0.681, F1 micro: 0.7422 \n",
      "Epoch: [2/10], Step: [901/2500], Train_loss: 0.051352541260421276\n",
      "Epoch: [2/10], Step: [1001/2500], Train_loss: 0.05154104478098452\n",
      "Epoch: [2/10], Step: [1101/2500], Train_loss: 0.05171355178918351\n",
      "Epoch: [2/10], Step: [1201/2500], Train_loss: 0.051545301928805805\n",
      "Epoch: [2/10], Step: [1301/2500], Train_loss: 0.05159750515021957\n",
      "Epoch: [2/10], Step: [1401/2500], Train_loss: 0.05157308841323746\n",
      "Epoch: [2/10], Step: [1501/2500], Train_loss: 0.05154555153350036\n",
      "Epoch: [2/10], Step: [1601/2500], Train_loss: 0.0516939304897096\n",
      "Precision macro: 0.7671, Recall macro: 0.539, F1 macro: 0.6085 \n",
      "Precision micro: 0.8131, Recall micro: 0.6914, F1 micro: 0.7474 \n",
      "Epoch: [2/10], Step: [1701/2500], Train_loss: 0.05171792842886027\n",
      "Epoch: [2/10], Step: [1801/2500], Train_loss: 0.05167649906335606\n",
      "Epoch: [2/10], Step: [1901/2500], Train_loss: 0.05167432130020308\n",
      "Epoch: [2/10], Step: [2001/2500], Train_loss: 0.05183739127870649\n",
      "Epoch: [2/10], Step: [2101/2500], Train_loss: 0.05179659731907859\n",
      "Epoch: [2/10], Step: [2201/2500], Train_loss: 0.05200406088959426\n",
      "Epoch: [2/10], Step: [2301/2500], Train_loss: 0.05206365365575513\n",
      "Epoch: [2/10], Step: [2401/2500], Train_loss: 0.05198598398012109\n",
      "Precision macro: 0.7575, Recall macro: 0.5715, F1 macro: 0.6295 \n",
      "Precision micro: 0.8154, Recall micro: 0.6694, F1 micro: 0.7352 \n",
      "2 epoch\n",
      "Epoch: [3/10], Step: [101/2500], Train_loss: 0.052714611813426016\n",
      "Epoch: [3/10], Step: [201/2500], Train_loss: 0.04874914530664683\n",
      "Epoch: [3/10], Step: [301/2500], Train_loss: 0.04862042315925161\n",
      "Epoch: [3/10], Step: [401/2500], Train_loss: 0.049072975453455\n",
      "Epoch: [3/10], Step: [501/2500], Train_loss: 0.049390763415023686\n",
      "Epoch: [3/10], Step: [601/2500], Train_loss: 0.049327890037869415\n",
      "Epoch: [3/10], Step: [701/2500], Train_loss: 0.0495639515694763\n",
      "Epoch: [3/10], Step: [801/2500], Train_loss: 0.04938017867971212\n",
      "Precision macro: 0.7359, Recall macro: 0.5653, F1 macro: 0.6164 \n",
      "Precision micro: 0.8163, Recall micro: 0.6829, F1 micro: 0.7437 \n",
      "Epoch: [3/10], Step: [901/2500], Train_loss: 0.04969791076870428\n",
      "Epoch: [3/10], Step: [1001/2500], Train_loss: 0.04996482811868191\n",
      "Epoch: [3/10], Step: [1101/2500], Train_loss: 0.050137619832530615\n",
      "Epoch: [3/10], Step: [1201/2500], Train_loss: 0.05005382265662774\n",
      "Epoch: [3/10], Step: [1301/2500], Train_loss: 0.05024647838650988\n",
      "Epoch: [3/10], Step: [1401/2500], Train_loss: 0.050331239549310076\n",
      "Epoch: [3/10], Step: [1501/2500], Train_loss: 0.05053079616154234\n",
      "Epoch: [3/10], Step: [1601/2500], Train_loss: 0.05084697429556399\n",
      "Precision macro: 0.7353, Recall macro: 0.5781, F1 macro: 0.6321 \n",
      "Precision micro: 0.8007, Recall micro: 0.7159, F1 micro: 0.756 \n",
      "Epoch: [3/10], Step: [1701/2500], Train_loss: 0.05083590337020509\n",
      "Epoch: [3/10], Step: [1801/2500], Train_loss: 0.05095062218244291\n",
      "Epoch: [3/10], Step: [1901/2500], Train_loss: 0.05108047192965291\n",
      "Epoch: [3/10], Step: [2001/2500], Train_loss: 0.05108030886948109\n",
      "Epoch: [3/10], Step: [2101/2500], Train_loss: 0.05099368525846373\n",
      "Epoch: [3/10], Step: [2201/2500], Train_loss: 0.051020325994627046\n",
      "Epoch: [3/10], Step: [2301/2500], Train_loss: 0.05105090198835925\n",
      "Epoch: [3/10], Step: [2401/2500], Train_loss: 0.051117785089105985\n",
      "Precision macro: 0.7516, Recall macro: 0.6262, F1 macro: 0.6675 \n",
      "Precision micro: 0.8216, Recall micro: 0.7036, F1 micro: 0.758 \n",
      "3 epoch\n",
      "Epoch: [4/10], Step: [101/2500], Train_loss: 0.05025793880224228\n",
      "Epoch: [4/10], Step: [201/2500], Train_loss: 0.04925382507033646\n",
      "Epoch: [4/10], Step: [301/2500], Train_loss: 0.04949584175522129\n",
      "Epoch: [4/10], Step: [401/2500], Train_loss: 0.04925718935206533\n",
      "Epoch: [4/10], Step: [501/2500], Train_loss: 0.04867914585582912\n",
      "Epoch: [4/10], Step: [601/2500], Train_loss: 0.049252094975672664\n",
      "Epoch: [4/10], Step: [701/2500], Train_loss: 0.04899319095670113\n",
      "Epoch: [4/10], Step: [801/2500], Train_loss: 0.0490288542653434\n",
      "Precision macro: 0.723, Recall macro: 0.6037, F1 macro: 0.6453 \n",
      "Precision micro: 0.8027, Recall micro: 0.7219, F1 micro: 0.7601 \n",
      "Epoch: [4/10], Step: [901/2500], Train_loss: 0.04897180401823587\n",
      "Epoch: [4/10], Step: [1001/2500], Train_loss: 0.04888126257341355\n",
      "Epoch: [4/10], Step: [1101/2500], Train_loss: 0.04938187450170517\n",
      "Epoch: [4/10], Step: [1201/2500], Train_loss: 0.049741485548826556\n",
      "Epoch: [4/10], Step: [1301/2500], Train_loss: 0.04989843300758646\n",
      "Epoch: [4/10], Step: [1401/2500], Train_loss: 0.050151407093341864\n",
      "Epoch: [4/10], Step: [1501/2500], Train_loss: 0.05022530430058638\n",
      "Epoch: [4/10], Step: [1601/2500], Train_loss: 0.050036190456012264\n",
      "Precision macro: 0.7784, Recall macro: 0.5859, F1 macro: 0.6451 \n",
      "Precision micro: 0.8196, Recall micro: 0.6865, F1 micro: 0.7472 \n",
      "Epoch: [4/10], Step: [1701/2500], Train_loss: 0.04998200439081034\n",
      "Epoch: [4/10], Step: [1801/2500], Train_loss: 0.04996966843855464\n",
      "Epoch: [4/10], Step: [1901/2500], Train_loss: 0.05010229725096571\n",
      "Epoch: [4/10], Step: [2001/2500], Train_loss: 0.05017570509109646\n",
      "Epoch: [4/10], Step: [2101/2500], Train_loss: 0.05039663673112435\n",
      "Epoch: [4/10], Step: [2201/2500], Train_loss: 0.05069399432321502\n",
      "Epoch: [4/10], Step: [2301/2500], Train_loss: 0.05078113035987253\n",
      "Epoch: [4/10], Step: [2401/2500], Train_loss: 0.050841324541252106\n",
      "Precision macro: 0.7243, Recall macro: 0.5954, F1 macro: 0.6393 \n",
      "Precision micro: 0.8145, Recall micro: 0.6957, F1 micro: 0.7504 \n",
      "4 epoch\n",
      "Epoch: [5/10], Step: [101/2500], Train_loss: 0.04937014004215598\n",
      "Epoch: [5/10], Step: [201/2500], Train_loss: 0.048458140837028624\n",
      "Epoch: [5/10], Step: [301/2500], Train_loss: 0.04935422492523988\n",
      "Epoch: [5/10], Step: [401/2500], Train_loss: 0.049113341635093094\n",
      "Epoch: [5/10], Step: [501/2500], Train_loss: 0.04889717611670494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [5/10], Step: [601/2500], Train_loss: 0.048767547979950907\n",
      "Epoch: [5/10], Step: [701/2500], Train_loss: 0.04932345809814121\n",
      "Epoch: [5/10], Step: [801/2500], Train_loss: 0.049367504116380585\n",
      "Precision macro: 0.7681, Recall macro: 0.58, F1 macro: 0.6456 \n",
      "Precision micro: 0.8304, Recall micro: 0.686, F1 micro: 0.7513 \n",
      "Epoch: [5/10], Step: [901/2500], Train_loss: 0.0494891801652395\n",
      "Epoch: [5/10], Step: [1001/2500], Train_loss: 0.04949380831792951\n",
      "Epoch: [5/10], Step: [1101/2500], Train_loss: 0.04915062618357214\n",
      "Epoch: [5/10], Step: [1201/2500], Train_loss: 0.04928388985572383\n",
      "Epoch: [5/10], Step: [1301/2500], Train_loss: 0.049432447385042905\n",
      "Epoch: [5/10], Step: [1401/2500], Train_loss: 0.049546134027519395\n",
      "Epoch: [5/10], Step: [1501/2500], Train_loss: 0.04962042938110729\n",
      "Epoch: [5/10], Step: [1601/2500], Train_loss: 0.049673761433805336\n",
      "Precision macro: 0.765, Recall macro: 0.58, F1 macro: 0.6332 \n",
      "Precision micro: 0.8163, Recall micro: 0.6905, F1 micro: 0.7482 \n",
      "Epoch: [5/10], Step: [1701/2500], Train_loss: 0.04970626182799392\n",
      "Epoch: [5/10], Step: [1801/2500], Train_loss: 0.049663475612178445\n",
      "Epoch: [5/10], Step: [1901/2500], Train_loss: 0.04960035219396416\n",
      "Epoch: [5/10], Step: [2001/2500], Train_loss: 0.049662333901505915\n",
      "Epoch: [5/10], Step: [2101/2500], Train_loss: 0.04962261742734838\n",
      "Epoch: [5/10], Step: [2201/2500], Train_loss: 0.04973615998444571\n",
      "Epoch: [5/10], Step: [2301/2500], Train_loss: 0.049922645703039094\n",
      "Epoch: [5/10], Step: [2401/2500], Train_loss: 0.05009051340748556\n",
      "Precision macro: 0.7227, Recall macro: 0.5716, F1 macro: 0.6255 \n",
      "Precision micro: 0.8156, Recall micro: 0.6838, F1 micro: 0.7439 \n",
      "5 epoch\n",
      "Epoch: [6/10], Step: [101/2500], Train_loss: 0.0515795305557549\n",
      "Epoch: [6/10], Step: [201/2500], Train_loss: 0.04998249116819352\n",
      "Epoch: [6/10], Step: [301/2500], Train_loss: 0.05032102922908962\n",
      "Epoch: [6/10], Step: [401/2500], Train_loss: 0.04902092366828583\n",
      "Epoch: [6/10], Step: [501/2500], Train_loss: 0.04852533617895097\n",
      "Epoch: [6/10], Step: [601/2500], Train_loss: 0.049083429106976835\n",
      "Epoch: [6/10], Step: [701/2500], Train_loss: 0.0490161536866799\n",
      "Epoch: [6/10], Step: [801/2500], Train_loss: 0.049458961486234326\n",
      "Precision macro: 0.7455, Recall macro: 0.6017, F1 macro: 0.6379 \n",
      "Precision micro: 0.8199, Recall micro: 0.6888, F1 micro: 0.7487 \n",
      "Epoch: [6/10], Step: [901/2500], Train_loss: 0.04947743617774298\n",
      "Epoch: [6/10], Step: [1001/2500], Train_loss: 0.04961604566359892\n",
      "Epoch: [6/10], Step: [1101/2500], Train_loss: 0.04942027054007419\n",
      "Epoch: [6/10], Step: [1201/2500], Train_loss: 0.049525154238799586\n",
      "Epoch: [6/10], Step: [1301/2500], Train_loss: 0.049635642078848415\n",
      "Epoch: [6/10], Step: [1401/2500], Train_loss: 0.04955258274883298\n",
      "Epoch: [6/10], Step: [1501/2500], Train_loss: 0.04974207435299953\n",
      "Epoch: [6/10], Step: [1601/2500], Train_loss: 0.04977786970906891\n",
      "Precision macro: 0.7316, Recall macro: 0.5737, F1 macro: 0.6206 \n",
      "Precision micro: 0.8044, Recall micro: 0.7081, F1 micro: 0.7532 \n",
      "Epoch: [6/10], Step: [1701/2500], Train_loss: 0.04971663878682782\n",
      "Epoch: [6/10], Step: [1801/2500], Train_loss: 0.04983797869024177\n",
      "Epoch: [6/10], Step: [1901/2500], Train_loss: 0.0497854241155284\n",
      "Epoch: [6/10], Step: [2001/2500], Train_loss: 0.049667358283419165\n",
      "Epoch: [6/10], Step: [2101/2500], Train_loss: 0.04966808863072878\n",
      "Epoch: [6/10], Step: [2201/2500], Train_loss: 0.04958843593273989\n",
      "Epoch: [6/10], Step: [2301/2500], Train_loss: 0.049687062849736084\n",
      "Epoch: [6/10], Step: [2401/2500], Train_loss: 0.04975727997138165\n",
      "Precision macro: 0.746, Recall macro: 0.5742, F1 macro: 0.6254 \n",
      "Precision micro: 0.8181, Recall micro: 0.6995, F1 micro: 0.7542 \n",
      "6 epoch\n",
      "Epoch: [7/10], Step: [101/2500], Train_loss: 0.04200602914206684\n",
      "Epoch: [7/10], Step: [201/2500], Train_loss: 0.04639340974856168\n",
      "Epoch: [7/10], Step: [301/2500], Train_loss: 0.047387948936472336\n",
      "Epoch: [7/10], Step: [401/2500], Train_loss: 0.04816092893015593\n",
      "Epoch: [7/10], Step: [501/2500], Train_loss: 0.048144802721217274\n",
      "Epoch: [7/10], Step: [601/2500], Train_loss: 0.04812898278857271\n",
      "Epoch: [7/10], Step: [701/2500], Train_loss: 0.048440446565592925\n",
      "Epoch: [7/10], Step: [801/2500], Train_loss: 0.04852756575040985\n",
      "Precision macro: 0.7384, Recall macro: 0.5917, F1 macro: 0.6434 \n",
      "Precision micro: 0.8157, Recall micro: 0.696, F1 micro: 0.7511 \n",
      "Epoch: [7/10], Step: [901/2500], Train_loss: 0.04835283785075363\n",
      "Epoch: [7/10], Step: [1001/2500], Train_loss: 0.04862822798034176\n",
      "Epoch: [7/10], Step: [1101/2500], Train_loss: 0.048803485540080474\n",
      "Epoch: [7/10], Step: [1201/2500], Train_loss: 0.048672231359329694\n",
      "Epoch: [7/10], Step: [1301/2500], Train_loss: 0.04865071193064348\n",
      "Epoch: [7/10], Step: [1401/2500], Train_loss: 0.04857088803147365\n",
      "Epoch: [7/10], Step: [1501/2500], Train_loss: 0.04880251060705632\n",
      "Epoch: [7/10], Step: [1601/2500], Train_loss: 0.04881745553022483\n",
      "Precision macro: 0.747, Recall macro: 0.6199, F1 macro: 0.6652 \n",
      "Precision micro: 0.8055, Recall micro: 0.7081, F1 micro: 0.7536 \n",
      "Epoch: [7/10], Step: [1701/2500], Train_loss: 0.0486767960583572\n",
      "Epoch: [7/10], Step: [1801/2500], Train_loss: 0.048845699430288124\n",
      "Epoch: [7/10], Step: [1901/2500], Train_loss: 0.04897137930200092\n",
      "Epoch: [7/10], Step: [2001/2500], Train_loss: 0.04896499769692309\n",
      "Epoch: [7/10], Step: [2101/2500], Train_loss: 0.04895987698387\n",
      "Epoch: [7/10], Step: [2201/2500], Train_loss: 0.04895563653818416\n",
      "Epoch: [7/10], Step: [2301/2500], Train_loss: 0.04909404281951973\n",
      "Epoch: [7/10], Step: [2401/2500], Train_loss: 0.04924937779103251\n",
      "Precision macro: 0.718, Recall macro: 0.5767, F1 macro: 0.6259 \n",
      "Precision micro: 0.7949, Recall micro: 0.6979, F1 micro: 0.7432 \n",
      "7 epoch\n",
      "Epoch: [8/10], Step: [101/2500], Train_loss: 0.04323180606588721\n",
      "Epoch: [8/10], Step: [201/2500], Train_loss: 0.045839337268844246\n",
      "Epoch: [8/10], Step: [301/2500], Train_loss: 0.04695070414803922\n",
      "Epoch: [8/10], Step: [401/2500], Train_loss: 0.046750592787284405\n",
      "Epoch: [8/10], Step: [501/2500], Train_loss: 0.046870388248935344\n",
      "Epoch: [8/10], Step: [601/2500], Train_loss: 0.04724359330100318\n",
      "Epoch: [8/10], Step: [701/2500], Train_loss: 0.04699852984731219\n",
      "Epoch: [8/10], Step: [801/2500], Train_loss: 0.047205852532642895\n",
      "Precision macro: 0.7355, Recall macro: 0.5983, F1 macro: 0.6458 \n",
      "Precision micro: 0.812, Recall micro: 0.7112, F1 micro: 0.7583 \n",
      "Epoch: [8/10], Step: [901/2500], Train_loss: 0.04722661748787181\n",
      "Epoch: [8/10], Step: [1001/2500], Train_loss: 0.047641079063992946\n",
      "Epoch: [8/10], Step: [1101/2500], Train_loss: 0.04789934064896608\n",
      "Epoch: [8/10], Step: [1201/2500], Train_loss: 0.04770113879543108\n",
      "Epoch: [8/10], Step: [1301/2500], Train_loss: 0.04775131990595792\n",
      "Epoch: [8/10], Step: [1401/2500], Train_loss: 0.04787199078027957\n",
      "Epoch: [8/10], Step: [1501/2500], Train_loss: 0.04791684626073887\n",
      "Epoch: [8/10], Step: [1601/2500], Train_loss: 0.048070778501278257\n",
      "Precision macro: 0.7396, Recall macro: 0.5854, F1 macro: 0.6346 \n",
      "Precision micro: 0.8137, Recall micro: 0.6962, F1 micro: 0.7504 \n",
      "Epoch: [8/10], Step: [1701/2500], Train_loss: 0.04822257489486433\n",
      "Epoch: [8/10], Step: [1801/2500], Train_loss: 0.04813727153594502\n",
      "Epoch: [8/10], Step: [1901/2500], Train_loss: 0.04820376943625314\n",
      "Epoch: [8/10], Step: [2001/2500], Train_loss: 0.04832993138744496\n",
      "Epoch: [8/10], Step: [2101/2500], Train_loss: 0.04837080935836725\n",
      "Epoch: [8/10], Step: [2201/2500], Train_loss: 0.048488065100232645\n",
      "Epoch: [8/10], Step: [2301/2500], Train_loss: 0.04849410317048592\n",
      "Epoch: [8/10], Step: [2401/2500], Train_loss: 0.04874799151691453\n",
      "Precision macro: 0.7501, Recall macro: 0.6117, F1 macro: 0.6594 \n",
      "Precision micro: 0.8107, Recall micro: 0.7078, F1 micro: 0.7558 \n",
      "8 epoch\n",
      "Epoch: [9/10], Step: [101/2500], Train_loss: 0.04523960331454873\n",
      "Epoch: [9/10], Step: [201/2500], Train_loss: 0.04621525060385465\n",
      "Epoch: [9/10], Step: [301/2500], Train_loss: 0.04671926910057664\n",
      "Epoch: [9/10], Step: [401/2500], Train_loss: 0.046851141625083983\n",
      "Epoch: [9/10], Step: [501/2500], Train_loss: 0.047460291214287284\n",
      "Epoch: [9/10], Step: [601/2500], Train_loss: 0.04803048969246447\n",
      "Epoch: [9/10], Step: [701/2500], Train_loss: 0.048165081207241334\n",
      "Epoch: [9/10], Step: [801/2500], Train_loss: 0.048201616640435534\n",
      "Precision macro: 0.7279, Recall macro: 0.6022, F1 macro: 0.626 \n",
      "Precision micro: 0.7879, Recall micro: 0.7192, F1 micro: 0.752 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [9/10], Step: [901/2500], Train_loss: 0.04818352428264916\n",
      "Epoch: [9/10], Step: [1001/2500], Train_loss: 0.04824481031578034\n",
      "Epoch: [9/10], Step: [1101/2500], Train_loss: 0.04814784950068728\n",
      "Epoch: [9/10], Step: [1201/2500], Train_loss: 0.048224744687322525\n",
      "Epoch: [9/10], Step: [1301/2500], Train_loss: 0.04811946978434347\n",
      "Epoch: [9/10], Step: [1401/2500], Train_loss: 0.04836931677002992\n",
      "Epoch: [9/10], Step: [1501/2500], Train_loss: 0.04828503145029148\n",
      "Epoch: [9/10], Step: [1601/2500], Train_loss: 0.04824558042222634\n",
      "Precision macro: 0.7587, Recall macro: 0.607, F1 macro: 0.6535 \n",
      "Precision micro: 0.8127, Recall micro: 0.6846, F1 micro: 0.7432 \n",
      "Epoch: [9/10], Step: [1701/2500], Train_loss: 0.0482743944205782\n",
      "Epoch: [9/10], Step: [1801/2500], Train_loss: 0.04825415132360326\n",
      "Epoch: [9/10], Step: [1901/2500], Train_loss: 0.04820851642834513\n",
      "Epoch: [9/10], Step: [2001/2500], Train_loss: 0.04829257850442082\n",
      "Epoch: [9/10], Step: [2101/2500], Train_loss: 0.04827512942077149\n",
      "Epoch: [9/10], Step: [2201/2500], Train_loss: 0.048198198635469786\n",
      "Epoch: [9/10], Step: [2301/2500], Train_loss: 0.04823225797680409\n",
      "Epoch: [9/10], Step: [2401/2500], Train_loss: 0.04819456551029968\n",
      "Precision macro: 0.7349, Recall macro: 0.6016, F1 macro: 0.6417 \n",
      "Precision micro: 0.8127, Recall micro: 0.714, F1 micro: 0.7601 \n",
      "9 epoch\n",
      "Epoch: [10/10], Step: [101/2500], Train_loss: 0.05003363866358995\n",
      "Epoch: [10/10], Step: [201/2500], Train_loss: 0.047727491180412474\n",
      "Epoch: [10/10], Step: [301/2500], Train_loss: 0.04617324631350736\n",
      "Epoch: [10/10], Step: [401/2500], Train_loss: 0.046443950589746236\n",
      "Epoch: [10/10], Step: [501/2500], Train_loss: 0.0466942693348974\n",
      "Epoch: [10/10], Step: [601/2500], Train_loss: 0.046680236582954726\n",
      "Epoch: [10/10], Step: [701/2500], Train_loss: 0.04740995838572937\n",
      "Epoch: [10/10], Step: [801/2500], Train_loss: 0.047675217237556355\n",
      "Precision macro: 0.7313, Recall macro: 0.6136, F1 macro: 0.6497 \n",
      "Precision micro: 0.8055, Recall micro: 0.7071, F1 micro: 0.7531 \n",
      "Epoch: [10/10], Step: [901/2500], Train_loss: 0.047845956361335186\n",
      "Epoch: [10/10], Step: [1001/2500], Train_loss: 0.04754623330011964\n",
      "Epoch: [10/10], Step: [1101/2500], Train_loss: 0.047304939360103826\n",
      "Epoch: [10/10], Step: [1201/2500], Train_loss: 0.047220168344986935\n",
      "Epoch: [10/10], Step: [1301/2500], Train_loss: 0.04716175600241583\n",
      "Epoch: [10/10], Step: [1401/2500], Train_loss: 0.04724651096721313\n",
      "Epoch: [10/10], Step: [1501/2500], Train_loss: 0.04719679654482752\n",
      "Epoch: [10/10], Step: [1601/2500], Train_loss: 0.04728256313566817\n",
      "Precision macro: 0.7523, Recall macro: 0.6009, F1 macro: 0.6484 \n",
      "Precision micro: 0.8027, Recall micro: 0.714, F1 micro: 0.7558 \n",
      "Epoch: [10/10], Step: [1701/2500], Train_loss: 0.04748215685461593\n",
      "Epoch: [10/10], Step: [1801/2500], Train_loss: 0.04761113641499024\n",
      "Epoch: [10/10], Step: [1901/2500], Train_loss: 0.04767194858041445\n",
      "Epoch: [10/10], Step: [2001/2500], Train_loss: 0.047938402142375706\n",
      "Epoch: [10/10], Step: [2101/2500], Train_loss: 0.04803754180714133\n",
      "Epoch: [10/10], Step: [2201/2500], Train_loss: 0.048084421129473906\n",
      "Epoch: [10/10], Step: [2301/2500], Train_loss: 0.04799734368596388\n",
      "Epoch: [10/10], Step: [2401/2500], Train_loss: 0.0479654026524319\n",
      "Precision macro: 0.7585, Recall macro: 0.6041, F1 macro: 0.6516 \n",
      "Precision micro: 0.8223, Recall micro: 0.7055, F1 micro: 0.7594 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'precision_macro': 0.7348728965850972,\n",
       "  'recall_macro': 0.6016352310348781,\n",
       "  'f1_macro': 0.6417220680035143,\n",
       "  'precision_micro': 0.8126520681265207,\n",
       "  'recall_micro': 0.7140142517814727,\n",
       "  'f1_micro': 0.7601466683525098},\n",
       " 8)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.train_model(num_epochs=10, lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "import results_analysis\n",
    "importlib.reload(results_analysis)\n",
    "from results_analysis import plot_errorbars_by_model, get_mean_std_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_to_mean_std = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'monolingual_train_en': return TextData(self.input_tensors[idx], self.input_len[idx], self.target_tensors[idx]),\n",
       " 'multilingual_train_en': return TextData(self.input_tensors[idx], self.input_len[idx], self.target_tensors[idx]),\n",
       " 'val_en': return TextData(self.input_tensors[idx], self.input_len[idx], self.target_tensors[idx]),\n",
       " 'monolingual_train_ru': return TextData(self.input_tensors[idx], self.input_len[idx], self.target_tensors[idx]),\n",
       " 'multilingual_train_ru': return TextData(self.input_tensors[idx], self.input_len[idx], self.target_tensors[idx]),\n",
       " 'val_ru': return TextData(self.input_tensors[idx], self.input_len[idx], self.target_tensors[idx]),\n",
       " 'train': return TextData(self.input_tensors[idx], self.input_len[idx], self.target_tensors[idx]),\n",
       " 'val': return TextData(self.input_tensors[idx], self.input_len[idx], self.target_tensors[idx])}"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_wiki_tensor_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/mz2476/miniconda3/envs/my_base/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'val_hi'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-119-b62d173d5024>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m model_to_mean_std[model_name] = get_mean_std_k(\n\u001b[1;32m      5\u001b[0m     \u001b[0mlearner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_splits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict_wiki_tensor_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdict_wiki_tensor_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     metric_name=metric_name)\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mpath_to_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"results/{metric_name}_scores/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/topic-modeling/topic-modeling/baseline/results_analysis.py\u001b[0m in \u001b[0;36mget_mean_std_k\u001b[0;34m(learner, num_splits, dict_wiki_tensor_dataset, metric_name, keys)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict_wiki_tensor_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mcur_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_test_metrics_kfold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_splits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mmean_k\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcur_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'val_hi'"
     ]
    }
   ],
   "source": [
    "model_name = \"en_ru\"\n",
    "metric_name='f1_micro'\n",
    "\n",
    "model_to_mean_std[model_name] = get_mean_std_k(\n",
    "    learner, num_splits=5, dict_wiki_tensor_dataset=dict_wiki_tensor_dataset,\n",
    "    metric_name=metric_name)\n",
    "\n",
    "path_to_scores = Path(f\"results/{metric_name}_scores/\")\n",
    "path_to_scores.mkdir(exist_ok=True)\n",
    "\n",
    "torch.save({model_name : model_to_mean_std[model_name]},\n",
    "           path_to_scores/f\"{model_name}_mean_std.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for model_name in model_to_mean_std.keys():\n",
    "#     torch.save({model_name : model_to_mean_std[model_name]}, f\"results/f1_micro_scores/{model_name}_mean_std.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load\n",
    "model_to_mean_std = {}\n",
    "path_to_scores = Path(f\"results/{metric_name}_scores/\")\n",
    "[model_to_mean_std.update(torch.load(fname)) for fname in path_to_scores.iterdir()]\n",
    "\n",
    "mean_mk = np.array([mean_std[0] for mean_std in model_to_mean_std.values()])\n",
    "std_mk  = np.array([mean_std[1] for mean_std in model_to_mean_std.values()])\n",
    "\n",
    "axis = plot_errorbars_by_model(np.array(mean_mk), np.array(std_mk), labels_m=model_to_mean_std.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/mz2476/miniconda3/envs/my_base/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/scratch/mz2476/miniconda3/envs/my_base/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>precision_micro</th>\n",
       "      <th>recall_micro</th>\n",
       "      <th>f1_micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.601943</td>\n",
       "      <td>0.474778</td>\n",
       "      <td>0.501424</td>\n",
       "      <td>0.806897</td>\n",
       "      <td>0.659155</td>\n",
       "      <td>0.725581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.581520</td>\n",
       "      <td>0.475961</td>\n",
       "      <td>0.501708</td>\n",
       "      <td>0.798276</td>\n",
       "      <td>0.685926</td>\n",
       "      <td>0.737849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.601665</td>\n",
       "      <td>0.457821</td>\n",
       "      <td>0.497679</td>\n",
       "      <td>0.795041</td>\n",
       "      <td>0.668056</td>\n",
       "      <td>0.726038</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision_macro  recall_macro  f1_macro  precision_micro  recall_micro  \\\n",
       "0         0.601943      0.474778  0.501424         0.806897      0.659155   \n",
       "1         0.581520      0.475961  0.501708         0.798276      0.685926   \n",
       "2         0.601665      0.457821  0.497679         0.795041      0.668056   \n",
       "\n",
       "   f1_micro  \n",
       "0  0.725581  \n",
       "1  0.737849  \n",
       "2  0.726038  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 0,  5, 10, 15, 20, 25, 30, 35, 40, 45, 50, 55, 60, 65, 70, 75, 80,\n",
       "        85, 90, 95]),\n",
       " array([ 1,  6, 11, 16, 21, 26, 31, 36, 41, 46, 51, 56, 61, 66, 71, 76, 81,\n",
       "        86, 91, 96]),\n",
       " array([ 2,  7, 12, 17, 22, 27, 32, 37, 42, 47, 52, 57, 62, 67, 72, 77, 82,\n",
       "        87, 92, 97]),\n",
       " array([ 3,  8, 13, 18, 23, 28, 33, 38, 43, 48, 53, 58, 63, 68, 73, 78, 83,\n",
       "        88, 93, 98]),\n",
       " array([ 4,  9, 14, 19, 24, 29, 34, 39, 44, 49, 54, 59, 64, 69, 74, 79, 84,\n",
       "        89, 94, 99])]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[np.arange(start, 100, num_splits) for start in range(num_splits)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/mz2476/miniconda3/envs/my_base/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/scratch/mz2476/miniconda3/envs/my_base/lib/python3.7/site-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>precision_micro</th>\n",
       "      <th>recall_micro</th>\n",
       "      <th>f1_micro</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.651972</td>\n",
       "      <td>0.482795</td>\n",
       "      <td>0.534985</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.680304</td>\n",
       "      <td>0.734841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.651972</td>\n",
       "      <td>0.482795</td>\n",
       "      <td>0.534985</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.680304</td>\n",
       "      <td>0.734841</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   precision_macro  recall_macro  f1_macro  precision_micro  recall_micro  \\\n",
       "0         0.651972      0.482795  0.534985         0.798883      0.680304   \n",
       "1         0.651972      0.482795  0.534985         0.798883      0.680304   \n",
       "\n",
       "   f1_micro  \n",
       "0  0.734841  \n",
       "1  0.734841  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices = np.arange(500)\n",
    "indices = np.arange(500, 1000)\n",
    "\n",
    "dict_of_metrics = learner.get_test_metrics(\n",
    "    data.Subset(learner.val_loader.dataset, indices), device=learner.device)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame([dict_of_metrics, dict_of_metrics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "model_name = \"mixed_en_hi_ru_\" + \"_\".join([str(key) + \"_\" + str(value) for key, value in result.items()])\n",
    "print(model_name)\n",
    "metrics_dict = train_model(train_loader, val_loader, model, criterion, optimizer, options, device,\n",
    "                num_epochs=10, model_name=\"model\", save_model=False)\n",
    "result.update(metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.param_groups[0][\"lr\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " {'optimizer': 'Adam', 'num_hidden': 2, 'dim_hidden': 150, 'dropout_rate': 0.2, 'learning_rate': 0.01, 'num_epochs': 15}\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.28 GiB (GPU 0; 7.93 GiB total capacity; 6.85 GiB already allocated; 626.56 MiB free; 6.49 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-bf531e03e2ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;31m# Criterion and Optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mz2476/miniconda3/envs/my_base/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    430\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 432\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_backward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mz2476/miniconda3/envs/my_base/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mz2476/miniconda3/envs/my_base/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mz2476/miniconda3/envs/my_base/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    228\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/mz2476/miniconda3/envs/my_base/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    428\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.28 GiB (GPU 0; 7.93 GiB total capacity; 6.85 GiB already allocated; 626.56 MiB free; 6.49 MiB cached)"
     ]
    }
   ],
   "source": [
    "# loaders = create_data_loaders_for_model(wiki_loaders[\"train\"], wiki_loaders[\"val\"])\n",
    "# # create dataloader\n",
    "# wiki_loaders = {}\n",
    "\n",
    "\n",
    "# for split, wiki_dataset in dict_wiki_tensor_dataset.items():\n",
    "#     wiki_loaders[split] = DataLoader(\n",
    "#         wiki_dataset, \n",
    "#         batch_size=batch_size, \n",
    "#         shuffle=True, \n",
    "#         collate_fn=partial(pad_collate_fn, word_to_index=word_to_index)\n",
    "#     )\n",
    "\n",
    "\n",
    "# train_model(\n",
    "#     wiki_loaders, model, criterion, optimizer, options=options, num_epochs=num_epochs, \n",
    "#     model_name=model_name, save_model=SAVE_MODEL\n",
    "# )\n",
    "\n",
    "# results_df = results_df.append(result, ignore_index=True)\n",
    "#     results_df.to_csv(\"results/results_tuning_2_3_layers_maxlen_500.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
